<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
  <a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
  <ul class="icons">
    <li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
    <li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
    <li><a href="https://www.linkedin.com/organization/1500316/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
    <li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
  </ul>
</header>

    	        <section>
	<div class="content">

	<h3>The API Evangelist Blog</h3>
	<p>This blog is dedicated to understanding the world of APIs, exploring a wide range of topics from design to deprecation, and spanning the technology, business, and politics of APIs. <a href="https://github.com/kinlane/api-evangelist" target="_blank">All of this runs on Github, so if you see a mistake, you can either fix by submitting a pull request, or let us know by submitting a Github issue for the repository</a>.</p>
	<center><hr style="width: 75%;" /></center>
	
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/05/an-api-change-log-and-road-map-visualization/">An API Change Log And Road Map Visualization</a></h3>
        <span class="post-date">05 Jul 2017</span>
        <p><a href="https://api-insights.qlik.com/#/overview-page"><img src="https://s3.amazonaws.com/kinlane-productions/qlik/qlik-api-insights.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I saw a blog post come across my feeds from the analysis and visualizaiton API provider Qlik, <a href="https://branch-blog.qlik.com/qlik-sense-api-insights-3e84b61602bd">about their Qlik Sense API Insights</a>. It is a pretty interesting approach to trying visualize the change log and road map for an API. I like it because it is an analysis and visualization API provider who has used their own platform to help visualize the evolution of their API.</p>

<p>I find the visualization for Qlik Sense API Insights to be a little busy, and not as interactive as I’d like to see it be, but I like where they are headed. It tries to capture a ton of data, showing the road map and changes across multiple versions of sixteen APIs, something that can’t be easy to wrap your head around, let alone capture in a single visualization. I really like the direction they are going with this, even though it doesn’t fully bring it home for me.</p>

<p><a href="https://api-insights.qlik.com/#/overview-page">Qlik Sense API Insights</a> is the first approach I’ve seen like this to attempt to try and quantify the API road map and change log–it makes sense that it is something being done by a visualization platform provider. With a little usage and user experience (UX) love I think the concept of analysis, visualizaitons, and hopefully insights around the road map, change log, and even open issues and status could be significantly improved upon. I could see something like this expand and begin to provide an interesting view into the forever changing world of APIs, and keep consumers better informed, and in sync with what is going on.</p>

<p>In a world where many API providers still do not even share a road map or change log I’m always looking for examples of providers going the extra mile to provide more details, especially if they are innovating thike Qlik is with visualizations. I see a lot of conversations about how to version an API, but very few conversations about how to communicate each version of your API. It is something I’d like to keep evangelizing, helping API providers understand they should at least be offering the essentials like a roadmap, issues, change log, and status page, but the possibility for innovation and pushing the conversation forward is within reach too!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/05/an-api-change-log-and-road-map-visualization/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/05/bringing-the-api-deployment-landscape-into-focus/">Bringing The API Deployment Landscape Into Focus</a></h3>
        <span class="post-date">05 Jul 2017</span>
        <p><a href="http://deployment.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-api-deployment.png" align="right" width="30%" style="padding: 15px;" /></a></p>
<p>I am finally getting the time to invest more into the rest of my API industry guides, which involves deep dives into core areas of my research like API <a href="http://definitions.apievangelist.com/">definitions</a>, <a href="http://design.apievangelist.com/">design</a>, and now <a href="http://deployment.apievangelist.com/">deployment</a>. The outline for my API deployment research has begun to come into focus and looks like it will rival my API management research in size.</p>

<p>With this release, I am looking to help onboard some of my less technical readers with API deployment. Not the technical details, but the big picture, so I wanted to start with some simple questions, to help prime the discussion around API development.</p>

<ul>
  <li>Where? - Where are APIs being deployed. On-premise, and in the clouds. Traditional website hosting, and even containerized and serverless API deployment.</li>
  <li>How? - What technologies are being used to deploy APIs? From using spreadsheets, document and file stores, or the central database. Also thinking smaller with microservices, containes, and serverless.</li>
  <li>Who? - Who will be doing the deployment? Of course, IT and developers groups will be leading the charge, but increasingly business users are leveraging new solutions to play a significant role in how APIs are deployed.</li>
</ul>

<p><strong>The Role Of API Definitions</strong>
While not every deployment will be auto-generated using an API definition like OpenAPI, API definitions are increasingly playing a lead role as the contract that doesn’t just deploy an API, but sets the stage for API documentation, testing, monitoring, and a number of other stops along the API lifecycle. I want to make sure to point out in my API deployment research that API definitions aren’t just overlapping with deploying APIs, they are essential to connect API deployments with the rest of the API lifecycle.</p>

<p><strong>Using Open Source Frameworks</strong>
Early on in this research guide I am focusing on the most common way for developers to deploy an API, using an open source API framework. This is how I deploy my APIs, and there are an increasing number of open source API frameworks available out there, in a variety of programming languages. In this round I am taking the time to highlight at least six separate frameworks in the top programming languages where I am seeing sustained deployment of APIs using a framework. I don’t take a stance on any single API framework, but I do keep an eye on which ones are still active, and enjoying usag bey developers.</p>

<p><strong>Deployment In The Cloud</strong>
After frameworks, I am making sure to highlight some of the leading approaches to deploying APIs in the cloud, going beyond just a server and framework, and leveraging the next generation of API deployment service providers. I want to make sure that both developers and business users know that there are a growing number of service providers who are willing to assist with deployment, and with some of them, no coding is even necessary. While I still like hand-rolling my APIs using my peferred framework, when it comes to some simpler, more utility APIs, I prefer offloading the heavy lifting to a cloud service, and save me the time getting my hands dirty.</p>

<p><strong>Essential Ingredients for Deployment</strong>
Whether in the cloud, on-premise, or even on device and even the network, there are some essential ingredients to deploying APIs. In my API deployment guide I wanted to make sure and spend some time focusing on the essential ingredients every API provider will have to think about.</p>

<p>-Compute - The base ingredient for any API, providing the compute under the hood. Whether its baremetal, cloud instances, or serverless, you will need a consistent compute strategy to deploy APIs at any scale.
-Storage - Next, I want to make sure my readers are thinking about a comprehensive storage strategy that spans all API operations, and hopefully multiple locations and providers.
-DNS - Then I spend some time focusing on the frontline of API deployment–DNS. In todays online environment DNS is more than just addressing for APIs, it is also security.
-Encryption - I also make sure encryption is baked in to all API deployment by default in both transit, and storage.</p>

<p><strong>Some Of The Motivations Behind Deploying APIs</strong>
In previous API deployment guides I usually just listed the services, tools, and other resources I had been aggregating as part of my monitoring of the API space. Slowly I have begun to organize these into a variety of buckets that help speak to many of the motivations I encounter when it comes to deploying APIs. While not a perfect way to look at API deployment, it helps me thinking about the many reasons people are deploying APIs, and craft a narrative, and provide a guide for others to follow, that is potentially aligned with their own motivations.</p>

<ul>
  <li>Geographic - Thinking about the increasing pressure to deploy APIs in specific geographic regions, leveraging the expansion of the leading cloud providers.</li>
  <li>Virtualization - Considering the fact that not all APIs are meant for production and there is a lot to be learned when it comes to mocking and virtualizing APIs.</li>
  <li>Data - Looking at the simplest of Create, Read, Update, and Delete (CRUD) APIs, and how data is being made more accessible by deploying APIs.</li>
  <li>Database - Also looking at how APIs are beign deployed from relational, noSQL, and other data sources–providing the most common way for APIs to be deployed.</li>
  <li>Spreadsheet - I wanted to make sure and not overlook the ability to deploy APIs directly from a spreadsheet making APIs are within reach of business users.</li>
  <li>Search - Looking at how document and content stores are being indexed and made searchable, browsable, and accessible using APIs.</li>
  <li>Scraping - Another often overlooked way of deploying an API, from the scraped content of other sites–an approach that is alive and well.</li>
  <li>Proxy - Evolving beyond early gateways, using a proxy is still a valid way to deploy an API from existing services.</li>
  <li>Rogue - I also wanted to think more about some of the rogue API deployments I’ve seen out there, where passionate developers reverse engineer mobile apps to deploy a rogue API.</li>
  <li>Microservices - Microservices has provided an interesting motivation for deploying APIs–one that potentially can provide small, very useful and focused API deployments.</li>
  <li>Containers - One of the evolutions in compute that has helped drive the microservices conversation is the containerization of everything, something that compliments the world of APis very well.</li>
  <li>Serverless - Augmenting the microservices and container conversation, serverless is motivating many to think differently about how APIs are being deployed.</li>
  <li>Real Time - Thinking briefly about real time approaches to APIs, something I will be expanding on in future releases, and thinking more about HTTP/2 and evented approaches to API deployment.</li>
  <li>Devices - Considering how APis are beign deployed on device, when it comes to Internet of Things, industrial deployments, as well as even at the network level.</li>
  <li>Marketplaces - Thinking about the role API marketplaces like Mashape (now RapidAPI) play in the decision to deploy APIs, and how other cloud providers like AWS, Google, and Azure will play in this discussion.</li>
  <li>Webhooks - Thinking of API deployment as a two way street. Adding webhooks into the discussion and making sure we are thinking about how webhooks can alleviate the load on APIs, and push data and content to external locations.</li>
  <li>Orchestration - Considering the impact of continous integration and deployment on API deploy specifically, and looking at it through the lens of the API lifecycle.</li>
</ul>

<p>I feel like API deployment is still all over the place. The mandate for API management was much better articulated by API service providers like Mashery, 3Scale, and Apigee. Nobody has taken the lead when it came to API deployment. Service providers like DreamFactory and Restlet have kicked ass when it comes to not just API management, but making sure API deployment was also part of the puzzle. Newer API service providers like Tyk are also pusing the envelope, but I still don’t have the number of API deployment providers I’d like, when it comes to referring my readers. It isn’t a coincidence that DreamFactory, Restlet, and Tyk are API Evangelist partners, it is because they have the services I want to be able to recommend to my readers.</p>

<p>This is the first time I have felt like <a href="http://deployment.apievangelist.com/">my API deployment research</a> has been in any sort of focus. I carved this layer of my research of <a href="http://management.apievangelist.com/">my API management research</a> some years ago, but I really couldn’t articulate it very well beyond just open source frameworks, and the emerging cloud service providers. After I publish this edition of my API deployment guide I’m going to spend some time in the 17 areas of my research listed above. All these areas are heavily focused on API deployment, but I also think they are all worth looking at individually, so that I can better understand where they also intersect with other areas like management, testing, monitoring, security, and other stops along the API lifecycle.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/05/bringing-the-api-deployment-landscape-into-focus/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/the-growing-importance-of-geographic-regions-in-the-api-economy/">The Growing Importance of Geographic Regions In API Operations</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><a href="https://cloud.google.com/about/locations/"><img src="https://s3.amazonaws.com/kinlane-productions/3D-Printing/regions/api-regions-global-map-from-google.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I have been revisiting <a href="http://apievangelist.com/2015/10/31/how-are-we-going-to-create-the-standard-and-poors-and-moodys-for-the-api-economy/">my earlier work on an API rating system</a>. One area that keeps coming up as I’m working is around the availability of APIs in a variety of regions, and the cloud platforms that are driving them. <a href="http://apievangelist.com/2011/02/04/launch-region-specific-apis/">I have talked about regional availability of APIs</a> for some time now, keeping an eye on <a href="http://apievangelist.com/2016/01/05/your-api-access-replicated-into-multiple-regions-around-the-globe-for-additional-charge/">how API providers are supporting multiple regions</a>, as well as <a href="http://apievangelist.com/2017/05/08/regional-availability-when-it-comes-to-api-access/">the expanding world of cloud computing</a> that is powering these regional examples of providing and consuming APIs.</p>

<p>I have been watching <a href="http://docs.aws.amazon.com/general/latest/gr/rande.html">Amazon rapidly expand their available regions</a>, as well as <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones">Google</a> and <a href="https://azure.microsoft.com/en-us/regions/">Microsoft</a> racing to catch up. But I am starting to see API providers <a href="https://developers.digitalocean.com/documentation/v2/#regions">like Digital Ocean providing APIs for getting at geographic region information</a>, and <a href="http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRegions.html">Amazon provides API methods for getting the available regions for Amazon EC2 compute</a>–I will have to check if this is standard across all services. <a href="https://www.twilio.com/docs/api/client/regions">Twilio has regions for their API client</a>, and <a href="https://www.runscope.com/docs/api/regions">Runscope has a region API for managing how you run API tests from a variety of regions</a>. The role of geographic regions when it comes to providing APIs, as well as consuming APIs is increasingly part of the conversation when you visit the most mature API platforms, and something that keeps coming up on my radar.</p>

<p>We are still far from the average company being able to easily deploy, deprecate, and migrate APIs seamlessly across cloud providers and geographic regions, but as APIs become smaller and more modular, and cloud providers add more regions, and APIs to support automation around these regions, we will begin to see more decisions being made at deploy and run time regarding where you want to deploy or consume your API resources. To be able to do this we are going to need a lot more data and common schema regarding the what geographic regions are available for deployment, what services operate in which regions, and other key considerations about exactly where our resources should operate. This is why I’m revisiting this work, to see what I can do to get API service providers to share more data from either the API provider or consumer side of the equation.</p>

<p>I am considering adding an area of my research dedicated to API regions, aggregating examples of how geographic regions are playing a role in API operations. I’m thinking region availability will be playing just as significant role as <a href="http://performance.apievangelist.com">performance</a>, <a href="http://plans.apievangelist.com">plans</a>, <a href="http://security.apievangelist.com">security</a>, <a href="http://reliablity.apievangelist.com">reliability</a>, and other areas of the API lifecycle when it comes to deciding where you deploy or consume your APIs. It feels like another one of the aspects of API operations that will overlap with many stops along the API lifecycle–not just <a href="http://deployment.apievangelist.com">deployment</a>. One of the areas of the API lifecycle I’m increasingly thinking about that will affect geographic API decisions is <a href="http://regulation.apievangelist.com">regulations</a>, and how governments are dictating what is acceptable when it comes to the storage, transmission, and access of digital resources. It feels like early notions of what the World Wide Web has been for the last 25 years is about to be blown out of the water, with the influences of digital nationalism, regulation, or even the Internet moving off planet, and increasingly driven by satellite infrastructure.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/the-growing-importance-of-geographic-regions-in-the-api-economy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api.-markdown/">Electronic Submission of Injury and Illness Records to OSHA</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><a href="https://www.osha.gov/injuryreporting/"><img src="https://s3.amazonaws.com/kinlane-productions/osha/osha-work-injury-form.jpg" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://www.osha.gov/injuryreporting/">I recently learned that Occupational Safety and Health Administration (OSHA) has issued guidance regarding the electronic submission of injury and illness records via an API, from an announcement that they has postponed the availability of electronic submissions for another six months</a>. Regardless of the delay, it is good to see them migrating towards an API-focused approach to allowing businesses to be compliant with safety regulations and reporting guidelines.</p>

<p>Here are the details of the OSHA guidance, broken down into some interesting buckets of guidance:</p>

<ul>
  <li><strong>Who</strong>: Establishments with 250 or more employees that are currently required to keep OSHA injury and illness records, and establishments with 20-249 employees that are classified in certain industries with historically high rates of occupational injuries and illnesses.</li>
  <li><strong>What</strong>: Covered establishments with 250 or more employees must electronically submit information from OSHA Forms 300 (Log of Work-Related Injuries and Illnesses), 300A (Summary of Work-Related Injuries and Illnesses), and 301 (Injury and Illness Incident Report). Covered establishments with 20-249 employees must electronically submit information from OSHA Form 300A.</li>
  <li><strong>When</strong>: The requirement becomes effective on January 1, 2017. The new reporting requirements will be phased in over two years. In 2017, all covered establishments must submit information from their completed 2016 Form 300A by July 1, 2017. In 2018, covered establishments with 250 or more employees must submit information from all completed 2017 forms (300A, 300, and 301) by July 1, 2018, and covered establishments with 20-249 employees must submit information from their completed 2017 Form 300A by July 1, 2018. Beginning in 2019 and every year thereafter, covered establishments must submit the information by March 2.</li>
  <li><strong>How</strong>: OSHA will provide a secure website that offers three options for data submission. First, users will be able to manually enter data into a web form. Second, users will be able to upload a CSV file to process single or multiple establishments at the same time. Last, users of automated record-keeping systems will have the ability to transmit data electronically via an API (application programming interface). We will provide status updates and related information here as it becomes available.</li>
</ul>

<p>I think the three options available are interesting. Manual website, and a CSV file upload–which is kind of a gateway to API-land, but they will also be providing the real deal when it comes to submitting forms using an API. All government agencies should be migrating towards this approach to handling forms, and OSHA provides us with one more blueprint to point at when convincing government to be more machine readable when it comes to forms–if there is a web form, or PDF form, there should also be an API for submitting as well.</p>

<p>Now that the federal agency is on my radar I will be keeping an eye out for when their API is ready, and maybe even offer some help when it comes to the portal and presence for the API. I like this example because it is a good reference for APIs being used to deliver government forms, but also because it is a good example of API driven regulatory compliance, which I think we need more of. Not because regulations automatically equal good, but because we need regulations and business compliance to be as observable as we possibly can–APIs will be how we do this.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api.-markdown/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/making-an-account-activity-api-the-default/">Making An Account Activity API The Default</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><a href="https://dev.twitter.com/webhooks/account-activity"><img src="https://s3.amazonaws.com/kinlane-productions/twitter/twitter-account-activity-api-.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://medium.com/@esfand/twitter-account-activity-api-8c59347380be">I was reading an informative post about the Twitter Account Activity API</a>, which seems like something that should be the default for ALL platforms. In today’s cyber insecure environment, we should have the option to subscribe to a handful of events regarding our account or be able to sign up for a service that can subscribe and help us make sense of our account activity.</p>

<p>An account activity API should be the default for ALL the platforms we depend on. There should be a wealth of certified aggregate activity services that can help us audit and understand what is going on with our platform account activity. We should be able to look at, understand, and react to the good and bad activity via our accounts. If there are applications doing things that don’t make sense, we should be able to suspend access, until more is understood.</p>

<p>The Twitter Account Activity API Callback request contains three level of details:</p>

<ul>
  <li>direct_message_events: An array of Direct Message Event objects.</li>
  <li>users: An object containing hydrated user objects keyed by user ID.</li>
  <li>apps: An object containing hydrated application objects keyed by app ID.</li>
</ul>

<p>The Twitter Account Activity API provides a nice blueprint other API providers can follow when thinking about their own solution. While the schema returned will vary between providers, it seems like the API definition, and the webhook driven process can be standardized and shared across providers.</p>

<p><a href="https://dev.twitter.com/webhooks/account-activity">The Twitter Account Activity API is in beta</a>, but I will keep an eye on it. Now that I have the concept in my head, I’ll also look for this type of API available on other platforms. It is one of those ideas I think will be sticky, and if I can kick up enough dust, maybe other API providers will consider. I would love to have this level of control over my accounts, and it is also good to see Twitter still rolling out new APIs like this.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/making-an-account-activity-api-the-default/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org.-markdown/">Shared Publishing Of Data and API Projects, Portals, and Dashboards Using Github</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-github-continous-integration-orchestration.png" align="right" width="30%" style="padding: 15px;" /></p>
<p><a href="http://apievangelist.com/api-lifecycle/">Each one of the 80+ areas of my API Evangelist lifecycle research projects</a> is a single Github repository that I publish JSON or YAML data stores containing the news, organizations, tools, APIs, and patents that I’ve aggregated as part of my research. The home page of each site is a set of UI elements that take the data store and renders it into something that makes the data consumable by a human. I reference each project my storytelling, and it acts as a workbench as I craft my guides, white papers, and API strategy work as a consultant.</p>

<p>The news I have curated is published as a news listing. Organizations and tools are published as a listing with icons, title, description, and links. Listings of my partners, banner logos, and other elements are driven from YAML and JSON files I update as part of my continuous integration with Google Spreadsheets, Feedly, Twitter, Facebook, LinkedIn, and other services I use to manage my operations. I have a variety of manual, and automated processes that are run each day, publishing, syndicated and moving the API Evangelist platform.</p>

<p>All of this is open to anyone else who wants to publish to it via a Github commit, or via the API when you possess valid Github API token like I do. I publish data using a variety of Github accounts depending on which project or organization I am working on. In its simplest form it is collaborative website development. When you combine with YAML and JSON data, and a Jekyll presentation layer it can become collaborate dashboard publishing, with shared ownership of a forkable data engine. Each player can publish the YAML or JSON they are in charge of, and the Github hosted, Jekyll and Github Pages presentation layer displays as a website, dashboard, or even machine readable, static data feeds in YAML, JSON, Atom, CSV, or another format.</p>

<p>I have a variety of Github templates for managing my network of API research sites, as well as forkable projects that anyone can launch to support open data projects like my <a href="http://adopta-agency.github.io/adopta-blueprint/">Adopta.Agency blueprint</a>, or a <a href="http://developer.open.referral.adopta.agency/">human services API developer portal</a>. It’s not just me doing this, you can find [a forkable example of an API and developer over at the <a href="http://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/">General Services Administration(GSA)</a>, providing a baseline API definition that other government agencies can follow when launching an API, and be publishing an API developer portal. Github works well for the continous integration and deployment of open data, and API portals, projects, and dashboards that can be managed in a collaborative fashion out in the open, or behind a curtain with a private repository.</p>

<p>I’m working with a handful of API providers to experiment publishing API industry data in this way. Combining the organizations, news, tools, patents, and other data I aggregate from across the API industry with additional monitoring, search, discovery, security, and other relevant data into single project sites, data and API portals, and industry dashboards. I’m looking to draw out more API service providers and encourage them to share data that could benefit the entire community. I’ve been doing this for a while with API definitions, but will be expanding into other areas of the lifecycle, and hopefully encouraging more sharing, and forcing y’all to come out of your siloes a bit, and learn to work together–whether you like it or not.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org.-markdown/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org/">Shared Publishing To Github Org</a></h3>
        <span class="post-date">29 Jun 2017</span>
        

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api/">Electronic Submission Of Injury And Illness Records To Osha Using Api</a></h3>
        <span class="post-date">29 Jun 2017</span>
        

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/algorithmic-transparency-in-policing/">Algorithmic Observability In Predictive Policing</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope/stories/crypto-machine-bletchley_copper_circuit.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>As I study the world of APIs I am always on the lookout for good examples of APIs in action so that I can tell stories about them, and help influence the way folks do APIs. This is what I do each day. As part of this work, I am investing as much time as I can into better understanding how APIs can be used to help with algorithmic transparency, and helping us see into the black boxes that often are algorithms.</p>

<p>Algorithms are increasingly driving vital aspects of our world from what we see in our Facebook timelines, to whether or not we would commit a crime in the eyes of the legal system. <a href="http://washingtonmonthly.com/magazine/junejulyaugust-2017/code-of-silence/">I am reading about algorithms being used in policing in the Washington Monthly</a>, and I learned about an important example of algorithmic transparency that I would like to highlight and learn more about. A classic argument regarding why algorithms should remain closed is centered around intellectual property and protecting the work that gives you your competitive advantage–if you share your secret algorithm, your competitors will just steal it. While discussing the predictive policing algorithm, Rebecca Wexler explores the competitive landscape:</p>

<blockquote>
  <p>But Perlin’s more transparent competitors appear to be doing just fine. <a href="https://www.cybgen.com/products/casework.shtml">TrueAllele’s</a> main rival, a program called STRmix, which claims a 54 percent U.S. market share, has an official policy of providing defendants access to its source code, subject to a protective order. Its developer, John Buckleton, said that the key to his business success is not the code, but rather the training and support services the company provides for customers. “I’m committed to meaningful defense access,” he told me. He acknowledged the risk of leaks. “But we’re not going to reverse that policy because of it,” he said. “We’re just going to live with the consequences.”</p>
</blockquote>

<blockquote>
  <p>And remember <a href="http://www.predpol.com/">PredPol</a>, the secretive developer of predictive policing software? <a href="https://www.hunchlab.com/">HunchLab</a>, one of PredPol’s key competitors, uses only open-source algorithms and code, reveals all of its input variables, and has shared models and training data with independent researchers. Jeremy Heffner, a HunchLab product manager, and data scientist explained why this makes business sense: only a tiny amount of the company’s time goes into its predictive model. The real value, he said, lies in gathering data and creating a secure, user-friendly interface.</p>
</blockquote>

<p>In my experience, the folks who want to keep their algorithms closed are simply wanting to hide incompetence and shady things going on behind the scenes. If you listen to individual companies like Predpol, it is critical that algorithms stay closed, but if you look at the wider landscape you quickly realize this is not a requirement to stay competitive. There is no reason that all your algorithms can’t be wrapped with APIs, providing access to the inputs and outputs of all the active parts. Then using modern API management approaches these APIs can be opened up to researchers, law enforcement, government, journalists, and even end-users who are being impacted by algorithmic results, in a secure way.</p>

<p>I will be continuing to profile the algorithms being applied as part of predictive policing, and the digital legal system that surrounds it. As with other sectors where algorithms are being applied, and APIs are being put to work, I will work to find positive examples of <a href="http://apievangelist.com/2016/08/04/pushing-for-more-algorithmic-transparency-using-apis/">algorithmic transparency</a> like we are seeing from STRmix and HunchLab. I’d like to learn more about their approach to ensuring observability around these algorithms, and help showcase the benefits of transparency and observability of these types of algorithms that are impacting our worlds–helping make sure everyone knows that black box algorithms are a thing of the past, and the preferred approach of snake oil salesman.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/algorithmic-transparency-in-policing/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/continue-to-explore-restaurant-menu-as-an-analogy-for-api-copyright-and-patents/">Continue To Explore Restaurant Menu as an Analogy for API Copyright and Patents</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><a href="https://portlandfoodcartadventures.com/2013/01/23/burger-guild-food-cart-a-portland-food-cart-review/"><img src="https://s3.amazonaws.com/kinlane-productions/burger-guild-menu1.jpg" align="right" width="35%" style="padding: 15px;" /></a></p>
<p>While working on my feedback to the EFF for the first response to the Oracle v Google API copyright case, <a href="https://apievangelist.com/2014/05/23/restaurant-menus-as-analogy-for-api-copyright/">one of the stories I published used the restaurant menu as an analogy for API copyright</a>. This example was used in the most recent response by Google’s lawyers as they defended themselves in court, and as I’m working on my API patent research, I wanted to revisit this analogy, in the same way, helping focus attention on why API patents are such a bad idea.</p>

<p>Building on my previous analogy, as a restaurant, imagine your restaurant specialty is delivering meat-centric dishes. Your burgers and steaks are da bomb! You literally have several “secret sauces”, some unique preparation processes, as well as some very appealing ways of naming and describing your dishes. Not that different from many API providers, who have some “secret sauces”, some unique process, as well as some very appealing ways of naming and describing the very useful APIs they are offering.</p>

<p>In regards to copyright, why would you want to lock up the naming and ordering of what you are offering? Even if your competitor copies the exact wording on their menu (documentation), their burgers and steaks do not have your secret sauce or unique processes. Also, why would you want to burden food delivery services from aggregating your menu (documentation) alongside other restaurants using copyright? Don’t restrict how the local paper or food rag can reference your menu (documentation), and publish it on and offline–it is unnecessary and will do nothing to protect your business.</p>

<p>In regards to patents, why would you want to lock up the menu to your burgers and steaks alongside your secret sauce(s) and unique process? Could you imagine if McDonalds sued everyone for patent infringement because they had a burger section on their menu? Someone comes up with a unique burger, and now nobody can have a specific meat dish sections on their menu? The menu and the ingredients of your recipe shouldn’t be included in your patent. If your process is truly that unique, and remarkable, then patent that, you shouldn’t be locking up the ingredients, and the ways of naming, describing, and providing a menu (documentation) for your dish (APIs).</p>

<p>I am not anti-patent (well almost), but am 100% anti API patent. APIs are not your secret sauce or process. The URL, parameters, headers, body, response, and other elements of your API are no more patentable than hamburger, buns, mustard and ketchup are for your killer burger. The reason we have so many API patents is that we have very greedy, short-sighted companies who are just racing to get a piece of the action, and they have been taught that patents are how you make a grab for all the digital dishes on the table, or even might possibly be on the table in the future. They see things moving in a particular direction, and rather than doing those things well, they focus on locking up the doing of that thing.</p>

<p>If you are in the business of patenting your companies technology, please focus on patenting your secret sauce and truly unique processes, not the method for exchanging, selling, and baking your solution into other systems and applications. APIs should not be patented. APIs, no matter how unique they might be, are not the thing you should be defending. You should be making them accessible, and defending the unique and valuable thing you do behind them. Stop including API in your patent filings please, it goes against everything that makes API even works.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/continue-to-explore-restaurant-menu-as-an-analogy-for-api-copyright-and-patents/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/api-preparation-at-the-bureau-for-the-2020-census/">API Preparation At The Bureau For The 2020 Census</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><a href="https://data.census.gov/cedsci/landing"><img src="https://s3.amazonaws.com/kinlane-productions/census/census-2020-mobile-preparation.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I was reading about what <a href="https://gcn.com/articles/2017/06/16/census-open-data.aspx">the Census is doing to prepare for the 2020 census over at GCN</a>. I’ve been <a href="https://apievangelist.com/2013/08/22/delivering-value-for-developers-is-first-when-it-comes-to-the-census-bureau-apis/">invested in what they are doing at Census for some time now</a>, so it makes me happy to see where they are headed with their preparation for the 2020 census. From what I’ve read, and what I’ve seen with their existing API efforts, they have really taken API to heart and are working to bake APIs into everything they do.</p>

<p>According to GCN: Through the site’s application programming interface, users will be able to download and manipulate the data to serve their own purposes; ensuring that the API can drive all of data.census.gov’s core functions means outside users will have more power as well. “The more that we make this API capable, then we can serve our customers better by providing them with ways to extend the API in their own platforms for their customer base” – said Census Bureau Chief Data Officer Zach Whitman. Continuing to show that the folks at Census get APIs.</p>

<p>The Census Bureau is the most important API out there for helping us understand the people of the United States, and how the economy is working, or not working for us. <a href="https://data.census.gov/cedsci/landing">When you look at the landing page there are working on in preparation of the 2020 Census you can tell they continue to work hard to find new ways of exploring and visualization the huge amount of data they have gathered through the censuses of the past</a>. I’m glad the Census Bureau has been on their API journey for several years now, as what they have learned will go a long way towards making the 2020 census make a more meaningful impact.</p>

<p>APIs are not just about providing access to data. They are also about allowing many 3rd parties to add, update, as well as access and put to use data. Having the infrastructure and practice will contribute to a more collaborative and interactive census in 2020. Allowing local and regional players to actively play a role in the census as it plays out. What the Census teams have learned over the last couple of years operating their API platform will improve the results and the reach of the 2020 census in a way that will make it inclusive and relevant for the average citizen across the country.</p>

<p>I’ve met the Census data and API teams, I’m not worried about their preparation for the 2020 census. I do worry about whether or not they will have the resources they need to get the job done. With current discussions around funding the agency, as well as supporting the proper leadership at the agency. Like every other API effort I’ve come across it, the success of the 2020 census won’t just be a technical thing, it will also be about having the right business and political platform to ensure APIs are done right and are serving all stakeholders–which in the case of the 2020 Census includes every citizen in the United States.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/api-preparation-at-the-bureau-for-the-2020-census/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/i-have-two-interesting-apis-and-i-am-not-a-developer-what-do-i-do/">I Have Two APIs I Am Interested In And I Am Not A Developer--What Do I Do?</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/api-documentation-unistats.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>My friend David Kernohan (<a href="https://twitter.com/dkernohan">@dkernohan</a>) emailed me the other day asking me for some advice on where to get started working with some data APIs he had been introduced to. This is such a common question for me, and surprisingly seven years into API Evangelist they are questions I still do not have easy answers for. Partly because I spend the majority of my time writing about providing APIs, but also because API consumption is often times inconsistent, and just hard.</p>

<p>David provided me with two sources of data he wanted to work, which I think help articulate the differences between APIs, that can make things hard to work with when you are just getting started with any API. Let’s break down the two APIs he wants to work with:</p>

<ul>
  <li><strong>UNISTATS</strong>
    <ul>
      <li>Description: Compare official course data from universities and colleges.</li>
      <li>URL: <a href="http://dataportal.unistats.ac.uk/Pages/ApiDocumentation">http://dataportal.unistats.ac.uk/Pages/ApiDocumentation </a></li>
      <li>Details: It is an API with 8 separate paths to get what you need.</li>
      <li>Resources: Institution, Course, Stages, Accreditations, Locations, Statistics</li>
      <li>Data Type: XML &amp; JSON</li>
      <li>Authentication: Basic Auth</li>
    </ul>
  </li>
  <li><strong>Higher Education Funding Council for England (HEFCE) Register of Higher Education Providers</strong>
    <ul>
      <li>Description: The HEFCE Register is a searchable tool that shows how the Government regulates higher education providers in England.</li>
      <li>URL: <a href="http://www.hefce.ac.uk/reg/register/data/">http://www.hefce.ac.uk/reg/register/data/</a></li>
      <li>Details: Downloadable files with 6 urls available.</li>
      <li>Resources: Providers, Courses</li>
      <li>Data Type: XML, CSV</li>
      <li>Authentication: Auth: NONE</li>
    </ul>
  </li>
</ul>

<p>Here you have two sources of data that overlap. One is actually an API, which you can change paths, parameters, and get different JSON or XML results. The other is just a download of an XML or CSV file. One has authentication using <a href="https://en.wikipedia.org/wiki/Basic_access_authentication">BasicAuth</a>, which is a standard way of logging into websites, which often is reappropriated for accessing web APIs. You can start to see why API consumption can become pretty overwhelming, pretty quickly.</p>

<p><strong>CSV Is Easier</strong>
So where do we start? Well with the HEFCE downloads you get the results in CSV, something you can quickly upload into a spreadsheet and get to work. This is pretty straightforward data 101 stuff, making CSV and the spreadsheet still number one when it comes to working with data–a wide audience. However, the core dataset David wanted to work with from UNISTATS is an API, with JSON and XML returned. I know us API folk like to think of APIs as opening up access to data, but this chasm is one that many folks aren’t going to be able to step over.</p>

<p>XML is Harder
Let’s begin with the pulling a list of institutions in XML. Before I can get at the data <a href="http://dataportal.unistats.ac.uk/Account/Register">I need to sign up for an account</a>. After signing up I am given a key which I can use to authenticate the first time I try to load the URL <a href="http://data.unistats.ac.uk/api/v3/KIS/Institutions.xml">http://data.unistats.ac.uk/api/v3/KIS/Institutions.xml</a>–there are <a href="http://dataportal.unistats.ac.uk/Pages/ApiAuthentication">more details about authentication</a> as part of their documentation. As soon as I download this file, I double click on it to see which application will try to load it–Microsoft Word happily steps forward to assume the responsibility. However, it does me little good, and just loads a big XML blog in a documentation–what do I do with that? Next, I try with Microsoft Excel with the same results. Google Drive gives me the same response, uploads as XML, and loads as a blog with no recognition by Google Docs or Spreadsheet. So what now?</p>

<p>We have a set of CSV files, and potentially a set of XML files, after making our way through each available path of the UNISTATS API. We need to get the XML into Google Sheets, or Microsoft Excel. The CSV is easy, the XML is hard–we will need to convert from XML to CSV. We could accomplish this with the <a href="https://support.google.com/docs/answer/3093342?hl=en">Google Sheets importXML function</a>, but because the API requires authentication it would need some programming–I wanted to keep this code free if possible for now. We are able to authentication with the UNISTATS API via our browser and download the XML with this API, so writing code, even a Google Script seems over the top.</p>

<p><strong>XML To CSV Conversion</strong>
I recommend using a simple tool like <a href="http://www.convertcsv.com/xml-to-csv.htm">XML To CSV Converter</a>, and not overengineering this time. You can just download the XML returned from the UNISTATS API, save to desktop and upload to the XML to CSV Converter to get the CSV edition. Then the data from the UNISTATS API and the HEFCE downloads, all CSV format now can be uploaded to Google Sheets, or imported into Microsoft Excel for working with. This process can be repeated as necessary, whenever the data is updated on each of the sites–no coding necessary.</p>

<p><strong>Reusing This Process For Future APIs</strong>
This process worked with these two APIs. Next time you are working on a project the APIs could have different types of paths available, returning XML, JSON, CSV, or other configuration. They might have different types of authentication requiring API keys as a parameter, or maybe even OAuth–raising the bar even higher when it comes to connecting. Most importantly, sometimes the data returned might not be neat columns and rows, and not be compatible with working within a spreadsheet. Many APIs return “flat” data like we encountered this round, but an increasing number of APIs are returning much more structured forms of data that won’t simply import into a spreadsheet.</p>

<p>For this API exercise, we were able to take care of business using the browser. We were able to download the CSV, and the XML from the API using the browser as a client–no coding necessary. This is a really important element of understanding APIs. Websites return HTML for browsers to show to humans, and web APIs return XML, JSON, CSV, or another machine readable format for use in ANY application–in this case, it was a spreadsheet that will help us take things to the next level and figuring out what we want to do next with this data, to make sense of things.</p>

<p><strong>Look At Leading API Clients – No Code Necessary</strong>
For future API projects, I recommend taking a look at the <a href="https://www.getpostman.com/">Postman</a>, or <a href="https://restlet.com/modules/client/">Restlet API client</a>. Which will help act as a client for working with simple, and more complex APIs–helping you with authentication, headers, and other aspects of consuming a diverse range of APIs. These clients allow you to connect to APIs, and work with the XML, JSON, CSV, and other responses you will receive. Of course you will still have to download, convert, and upload resulting data into whatever application you intend to work with data within. These are simply clients, not applications that will help you transform, analyze, visualize, and make sense your data–it is up to you to do this.</p>

<p><strong>Some Final Thoughts On API Consumption</strong>
Despite almost 17 years of evolution web API consumption is still hard, and in the realm of programmers. Google Sheets and Microsoft Excel have tools to help you pull in data from APIs, but authentication and complex data structures will always be an obstacle in this environment. For more complex API integrations I recommend adopting an API client like Postman or Restlet, which will augment Google and Excel spreadsheets in your toolbox. Beyond that, I encourage using Github for publishing CSV, JSON, or YAML that is returned from APIs, and telling stories around the data using Github Pages. Github has been working hard to build in features for working with CSV, JSON, and YAML data, again making it possible to work with data returned form APIs with no, or minimal coding–Github employs <a href="https://jekyllrb.com/">Jekyll</a>, which in turn uses <a href="https://help.shopify.com/themes/liquid/filters/string-filters">Liquid</a> + HTML, but is something totally still within the realm of non-programmers.</p>

<p>Learning how to consume APIs is a journey, not a destination. APIs come in many shapes and sizes, but if you grasp the basic of the web, and have some of the right tools in your toolbox, you can navigate them and put them to work. I’m going to work on some more Google Spreadsheet examples, as well as some Postman and Restlet examples, using some of the most common APIs out there like Twitter, Flickr, and others. I’ll check back with David in a couple weeks to see how he is doing when it comes to onboarding with the APIs he has targeted for this project, and see where I can help him in his journey.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/i-have-two-interesting-apis-and-i-am-not-a-developer-what-do-i-do/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/the-open-service-broker-api/">The Open Service Broker API</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><a href="https://openservicebrokerapi.org/"><img src="https://s3.amazonaws.com/kinlane-productions/open-service-broker-api/osbapi_logo_concept3_wtm.png" align="right" width="40%" style="padding: 20px;" /></a></p>
<p>Jerome Louvel <a href="http://apis.how/5ytnitnakm">from Restlet</a> introduced me to <a href="https://openservicebrokerapi.org/">the Open Service Broker API</a> the other day, a “project allows developers, ISVs, and SaaS vendors a single, simple, and elegant way to deliver services to applications running within cloud-native platforms such as Cloud Foundry, OpenShift, and Kubernetes. The project includes individuals from Fujitsu, Google, IBM, Pivotal, RedHat and SAP.”</p>

<p>Honestly, I only have so much cognitive capacity to understand everything I come across, so I pasted the link into my super secret Slack group for API super heroes to get additional opinions. My friend James Higginbotham (<a href="https://twitter.com/launchany">@launchany</a>) quickly responded with, “if I understand correctly, this is a standard that would be equiv to Heroku’s Add-On API? Or am I misunderstanding? The Open Service Broker API is a clean abstraction that allows ‘services’ to expose a catalog of capabilities, as well as the ability to create, use and delete those services. Sounds like add-on support to me, but I could be wrong[…]But seems very much like vendor-to-vendor. Will be interesting to track.”</p>

<p>At first glance, I thought it was more of an aggregation and/or discovery solution, but I think James is right. It is an API scaffolding that SaaS platforms can plug into their platforms to broker other 3rd party API services. It allows any platform to offer <a href="https://devcenter.heroku.com/categories/extending-heroku">an environment for extending your platform like Heroku does</a>, as James points out. It is something that adds an API discovery dimension to the concept of offering up plugins, or I guess what could be an embedded API marketplace within your platform. Opening up <a href="http://apievangelist.com/2014/01/30/what-will-it-take-to-sell-my-api-as-a-wholesale-resource/">wholesale</a> and private label opportunities for API providers to sell their warez directly on other people’s platforms.</p>

<p>The concept really isn’t anything new. I remember developing document print plugins for Box back when I worked with the Mimeo print API in 2011. <a href="https://openservicebrokerapi.org/">The Open Service Broker API</a> is just looking to standardize this approach so hat  API provider could bake in a set of 3rd party partner APIs directly into their platform. <a href="http://plugin.apievangelist.com/">I’ve recently added a plugin area to my API research</a>. I will add the Open Service Broker API as an organization within this research. I’m probably also going to add it to my <a href="http://discovery.apievangelist.com/">API discovery research</a>, and I’m even considering expanding it into an API marketplace section of my research.  I can see add-on, plugin, marketplace, and <a href="http://apievangelist.com/2014/10/10/exploring-the-possibilities-of-being-an-api-broker/">API brokering like this grow into its own discipline</a>, with a growing number of definitions, services, and tools to support.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/the-open-service-broker-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/api-environment-portabiity/">API Environment Portability</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><a href="https://blog.runscope.com/posts/tutorial-copying-runscope-environments-using-runscope-api"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/runscope/1-runscope-env.jpg" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I was reading <a href="https://blog.runscope.com/posts/tutorial-copying-runscope-environments-using-runscope-api">the post from Runscope on copying environments using their new API</a>. I was looking through the request and response structure for their API, it looks like a pretty good start when it comes to what I’d call API environment portability. I’m talking about allowing us to define, share, replicate, and reuse the definitions for our API environments across the services and tools we are depending on.</p>

<p>If our API environment definitions shared a common schema, <a href="https://www.runscope.com/docs/api/environments">and API like Runscope provides</a>, I could take my Runscope environment settings, and use them in my Stoplight, <a href="https://restlet.com/modules/client/">Restlet Client</a>, Postman, and other API services and tooling. It would also help me templatize and standardize my development, staging, production, and other environments across the services I use. Assisting me in keeping my environment house in order, and also something that I can use to audit and turn over my environments to help out with security.</p>

<p>It is just a thought. An API environment API, possessing an evolving but common schema just seems like one of those things that would make the entire API space work a little smoother. Making our API environments exportable, importable, and portable just seems like it would help us think through when it comes setting up, configuring, managing, and evolving our API environments–who knows maybe someday we’ll have API service providers who help us manage our API environments, dictating how they are used across the growing number of API services we are depending on.</p>

<p><strong>Disclosure:</strong> Runscope and Restlet are API Evangelist partners.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/api-environment-portabiity/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/patent-number-us-20170153932-adapting-legacy-endpoints-to-modern-apis/">Patent #US 20170153932: Adapting Legacy Endpoints To Modern APIs</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/jetpack-patent.jpg" align="right" width="35%" style="padding: 15px;" /></p>
<p><a href="http://patents.apievangelist.com/#Patents">I made my API patent inventory a little more explorable this week</a>, allowing me to more easily discover new and interesting patents that will affect the world of APIs, which I can include in my research. An interesting patent from eBay quickly floated up to the top as a questionable idea for a patent.</p>

<p><a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;S1=09576314&amp;OS=09576314&amp;RS=09576314"><strong>Adapting legacy endpoints to modern APIs:</strong></a></p>

<p>Example methods and systems are directed to adapting legacy endpoints to modern application protocol interfaces (APIs). A legacy endpoint may provide a powerful and complex API. A modern application may desire access to the legacy endpoint. One or more layers may be added between the modern application and the legacy endpoint. Each layer may provide a different API. These layers of APIs may transform the interface from a powerful and complex interface to a more limited but simpler and easier to use interface. In some example embodiments, a proxy layer, an adapter layer, a facade layer, and a service layer may be used.</p>

<p>Pub Date: 2016/27/06
Number: 09576314
Owner: eBay Inc.
Location: San Jose, US
Details: <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;S1=09576314&amp;OS=09576314&amp;RS=09576314">Visit USPTO</a></p>

<p>Adapting legacy endpoints to modern APIs is a fundamental aspect of doing APIs in the first place. It is something that is useful and completely obvious. This is one of those patents that makes me question the competency of folks reviewing patents at the USPTO. If you at all are acquainted with the concept of web APIs, you know that this is something that is already done, and not worthy of the non-obvious aspect of being a patent.</p>

<p>APIs have no place in patents. I think this patent pretty clearly shows the system is broken, and the reasons why many companies are filing patents have reached an unhealthy level, as well as how broken the USPTO is. If they are approving a patent for adapting legacy endpoints to modern APIs in 2016 and 2017, they are pretty out of touch with the digital world that is unfolding around us.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/patent-number-us-20170153932-adapting-legacy-endpoints-to-modern-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/i-published-60k-patents-to-github-as-part-of-my-api-patent-research/">I Published 60K Patents To Github As Part Of My API Patent Research</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><a href="http://patents.apievangelist.com/#Patents"><img src="https://s3.amazonaws.com/kinlane-productions/patents/api-evangelist-patent-listing-screenshot.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I’ve been migrating from my own homebrew CMS system over the last couple of weeks, ditching it for a variety of existing services, balancing my operations across a diverse set of platforms I’ve identified as useful. I’m using Github and Jekyll to manage my content system, storing thinks like blog, news, notes, and patents there. Github repos are well suited for storing this type data for free (if it is public), and Jekyll is well suited for helping me manage small to large repositories of content I need to use across my platform.</p>

<p>This last week I migrated 60K patents I had filtered out of all the <a href="http://patents.reedtech.com/pgrbft.php">XML dumps of patents I downloaded</a>, between the years of 2005 and 2016. I filtered out any patent with API or application programming interface in the title, abstract, or body of the patent. Once done importing, I clean up the body a little bit and publish each one as a Jekyll post within a Github repo. I had to break them down by year, as Github started getting wonky after 10K file, but the Jekyll structure works well for managing up to 10K patents. Once committed, I find the Jekyll post and data structure pretty easy to navigate and use for some API storytelling.</p>

<p><a href="http://patents.apievangelist.com/#Patents">I like having the full listing of title and abstract available to search in a single public HTML page</a>. I have also started publishing keyword filters for each area of my research. It is taking me a while to build the index for each JSON API, but it is allowing me to quickly get at <a href="http://patents.apievangelist.com/#Patents">cached searches for machine learning, API management</a>, and other patents that affect the areas of the API lifecycle I’m keeping a close eye on. I will keep adding filters and enhancing the ones that I have, but ultimately it takes me reading a large number of patents and then actually tagging each one, that will help me build a useful API patent catalog.</p>

<p>I feel that these relevant patents help tell an important story about each layer of the API lifecycle. Patents add another dimension to the story of what is going on when it comes to API design, deployment, management, discovery, and other areas that are growing in 2017, and in coming years. The products, services, and tooling I track on from organizations included in <a href="http://apievangelist.com/api-lifecycle/">my API lifecycle research</a> paint a significant part of the picture, but I feel that patents pull back the curtain just a little bit more when it comes to what companies are thinking. I will keep processing new files from the USPTO every couple of weeks, evolving my filters, and tagging patents for better recall in my API patent storytelling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/i-published-60k-patents-to-github-as-part-of-my-api-patent-research/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/three-new-api-industry-groups-on-the-horizon/">Three New API Industry Groups On The Horizon</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/industry/industry-work-group.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>Along with the growth of industry level API events for machine learning, healthcare, and beyond, I’m starting to see the emergence of more API specific working groups, something I’ve been asking for, for some time now. The API universe is expanding and we will need API specialists with domain expertise to help push forward the conversations in leading industries like healthcare, banking, education, transportation, and beyond.</p>

<p>I’ve been keeping an eye out for any movement within industries beyond <a href="https://www.hl7.org/fhir/overview.html">FHIR</a> and <a href="https://ec.europa.eu/info/business-economy-euro/banking-and-finance/consumer-finance-and-payments/payment-services_en">PSD2</a>, and now I”m adding three more efforts to my list:</p>

<ul>
  <li>Artificial Intelligence - <a href="https://www.nttdocomo.co.jp/english/info/media_center/pr/2017/0623_00.html">NTT DOCOMO’s new docomo AI Agent Open Partner Initiative</a> to facilitate collaborative development of all-new offerings implemented with a service-agnostic, device-agnostic speech interface based on AI Agent API, a newly developed artificial intelligence (AI) application programming interface (API) that DOCOMO plans to incorporate into a new AI agent service to be launched in early fiscal 2018.</li>
  <li>Payments - <a href="https://www.nacha.org/content/api-standardization-industry-group">The National Automated Clearing House Association (NACHA) API Industry Standardization Group</a> looking to “help improve the safety and transparency of transactions, increase efficiencies and speed of communications, and enhance support of payments innovations.”</li>
  <li>Hospitality - <a href="http://www.htng.org/?page=ActiveWorkgroups">The Hospitality Technology Next Generation (HTNG) API Registry</a> looking to address a number of inefficiencies in the Hospitality API space, including finding potential technology partners whose products and/or services that could add value to an hotelier’s offerings, by creating a registry of Hospitality API’s to help modernize this space.</li>
</ul>

<p>These three efforts provide some interesting models for how companies and existing industry organizations are stepping up to provide leadership when it comes to API definitions, standards, and discovery in a particular business sector. There are no signs of whether these organizations will get off the ground and become sustainable, or that their stewards understand the wider API space, and have their industries best interest in mind. It does provide us with a glimpse at what is coming though, and the opportunity for companies, organizations, institutions, and government agencies to step up and take the lead when it comes to API standards.</p>

<p><a href="http://org.open.referral.adopta.agency/">I am taking my Open Referral Human Services API work which helps lead the discussion around the 211 API standard</a>, while also looking to help my friend Phil Ashlock move forward <a href="http://www.open311.org/">the Open311 standard</a> in a similar fashion. These are community efforts that are looking to help standardize how municipal agencies and organizations share information. I’m hoping to take this work, and merge with what I’m seeing in other industries and eventually establish a blueprint that anyone looking to start an API standards organization can take and put to work–hopefully, it is something that will forkable and deployable using Github like any API project should be.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/three-new-api-industry-groups-on-the-horizon/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/healthcare-api-interoperability-at-hl7-fhir-dev-days-in-amsterdam/">Healthcare API Interoperability At HL7 FHIR Dev Days In Amsterdam</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><a href="https://www.fhirdevdays.com/"><img src="https://s3.amazonaws.com/kinlane-productions/fhir/fhir-devdays-2017-amsterdam.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://apievangelist.com/2017/06/07/a-conference-focused-on-machine-learning-apis/">I wrote about a machine learning specific API event a couple weeks back</a>, and today I wanted to highlight the growth of conferences dedicated to <a href="https://www.hl7.org/fhir/">FHIR, or the Fast Healthcare Interoperability Resources</a>. FHIR is larger than just it’s API, but it is one very important example of how APIs and open industry API specifications can help move forward the API conversation in large industries.</p>

<p>As part of my healthcare API research, I bookmarked <a href="https://www.fhirdevdays.com/">HL7 FHIR DEVDAYS 2017</a>, a conference dedicated to standardizing healthcare APIs, and increasing interoperability across the global healthcare system. I went through <a href="https://www.fhirdevdays.com/schedule/">the three-day schedule for the conference</a>, following speakers on Twitter, and learning more about what being presented when it came to healthcare interoperability–expanding my awareness of what is going on when it comes to connecting healthcare systems and pushing forward this important API definition.</p>

<p>FHIR is right there with <a href="https://www.eba.europa.eu/regulation-and-policy/payment-services-and-electronic-money/regulatory-technical-standards-on-strong-customer-authentication-and-secure-communication-under-psd2">PSD2 for banking</a>. While not perfect examples, they are the two most significant examples we have when it comes moving forward an API standard for a large industry that are critical to our society. I don’t have the time to become an expert on every detail of FHIR or PSD2, but I do think it is important as an API professional to understand what is going on in these communities. Much like we’ve done with the API sector with the <a href="http://events.linuxfoundation.org/events/apistrat">API Strategy &amp; Practice Conferenc</a>, we are going to need more industry level API-focused conferences to emerge, helping industries come together and hammer out a common API definition, as well as the services and tooling that will be putting these definitions to work on the ground across the API economy.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/healthcare-api-interoperability-at-hl7-fhir-dev-days-in-amsterdam/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/budget-transparency-at-the-county-level-with-open-data-and-apis/">Budget Transparency At The County Level With Open Data And APIs</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><a href="https://socrata.com/blog/douglas-county-open-budget-invites-public-explore-annual-budget/"><img src="https://s3.amazonaws.com/kinlane-productions/socrata/douglas-county-operating-budget-768x485.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>As we find ourselves darker times when it comes to transparency within the federal government in the United States, I’m always on the hunt for any positive signs of transparency at the other levels of government. I can usually depend on my friends <a href="https://socrata.com">over at Socrata</a> to help out, and <a href="https://socrata.com/blog/douglas-county-open-budget-invites-public-explore-annual-budget/">they came through this week with a story on Douglas County, Kansas publishing their budget online</a>.</p>

<p>“This week, Douglas County, Kansas, home to 117,000 residents, launched an <a href="http://budget.douglascountyks.org/">Open Budget site</a>, which provides the public with access to one of the county’s most crucial documents: the annual operating budget.” Jill Jolicoeur, Assistant to the County Administrator stated that “our goal is for Open Budget to replace the time-intensive process of developing and publishing the annual budget in a hard-copy format.” Open data and APIs is one way for resource-strapped companies can open things up, allowing external groups help share the load when it comes to auditing, analysis, visualization, and many other areas county government could use some assistance.</p>

<p>Douglas County provides us with another example of how we can make government more <a href="http://observability.apievangelist.com/">observable</a>. There is no reason that county government can’t open up their budgets like this, and let a little sunlight into the operations. In my experience, the primary reason you want to keep things closed is when you are looking to hide corruption, incompetence, and poor technological and business decisions. I’m concerned with the bar being set by the White House right now when it comes to transparency and observability, but it doesn’t mean we can’t resist at the local level, and leverage open data and APIs to get things done more efficiently–like Douglas County is doing, and <a href="https://socrata.com">Socrata</a> is enabling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/budget-transparency-at-the-county-level-with-open-data-and-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/the-competitive-advantage-of-api-agility-over-any-secret-saurce/">The Competitive Advantage Of API Agility Over Any Secret Sauce</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope/stories/machine-road_blue_circuit_5_bw.jpg" align="right" width="45%" style="padding: 15px" /></p>
<p>I was talking to a VC about one of my favorite API upstarts the other day, and one of the closing questions I received was if the API upstart had a secret sauce that made their position defensible. To which I responded, no…but they are API first, and API definition-driven in everything they do, so they will ultimately move faster than any competitor can.</p>

<p>Agility is one of the classic things you hear people tell companies regarding why they should be doing APIs. The benefit is definitely overused and overstated in situations it shouldn’t be, but when APIs are fully embraced, and done properly, the agility is real. I’ve seen companies be able to shift, pivot, and add new features in a fraction of the time of their competitors, allowing them to in new ways that nobody had intended just months before–APIs allow for the type of shape shifting you need to remain competitive in today’s environment.</p>

<p>APIs do not automagically mean a company, institution, organization, or agency will be agile by default. Organizationally, and culturally the entity behind an API needs to be in sync with the API frontline, or agility will never be fully realized. However, when you can dial all this in I’ve seen something that is more potent than any secret sauce or proprietary approach, allowing you to move more confidently and flexibly. I don’t think API agility is a competitive advantage that all companies or investors fully grasp, but once they see in action, I think they’ll realize APIs are more effective than locking something up and keeping it secret.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/the-competitive-advantage-of-api-agility-over-any-secret-saurce/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/22/i-would-love-to-reference-github-data-across-repos-with-org-data-object/">I Would Love To Reference Github Data Across Repos With [org].data.[object]</a></h3>
        <span class="post-date">22 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-github-icon.png" align="right" width="30%" style="padding: 15px;" /></p>
<p>I am a big fan of Jekyll and Github when it comes to managing data-driven projects. All of my research runs on Github, and I use Jekyll to serve up YAML and JSON representations of my research for a variety of purposes. I store all data that supports my research in the _data folder for each research project’s repository. From there I will create HTML, Atom, and JSON representations for use in my API Evangelist storytelling.</p>

<p>When I am referencing any YAML data store I have in the _data folder I just use site.data.[object] to reference it. From there I can loop through collections, filter and show fields and other elements on the page using Liquid syntax. I love having all the data at my fingertips, but I’m thinking about the next step of data management at scale, as I work to build more data-driven repositories, housed within Github organizations, I want to be able to reach outside of each repo, into other repos stored within a single organization.</p>

<p>I would love it if Github allowed me to reference my data within an organization using [org].data.[object]. This way I could reference my <a href="http://design.apievangelist.com">API design</a> research within my <a href="http://hypermedia.apievangelist.com">hypermedia API</a> research. I have my API industry research segregated by topic for several reasons. Often it is just a logical separator, but sometimes the research is too big to fit into a single repository, and I’ll shard thing by year, topic, or another logical separator. It would be nice if I could reach across the repository line, into other organizations within an organization, or maybe someday reach out into other organizations as well.</p>

<p>Just some thoughts as I’m working with YAML data at scale across hundreds of Github repositories. I handle this cross-repo access using JavaScript currently but would love it if it was natively built into Jekyll, allowing me to publish in a static way. The amount of Liquid YAML and JSON voodoo I could unleash would be pretty huge if I could reach across all my data drive projects and reference in a structured way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/22/i-would-love-to-reference-github-data-across-repos-with-org-data-object/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/22/api-plans-arent-sustainable-for-my-small-business/">API Plans Are Not Sustainable For My Small Business</a></h3>
        <span class="post-date">22 Jun 2017</span>
        <p><a href="https://imageoptim.com/api/pricing"><img src="https://s3.amazonaws.com/kinlane-productions/imageoptim/imageoptim-api-pricing.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="http://apievangelist.com/2017/05/09/pricing-tiers-works-for-saas-but-not-really-for-apis/">I’ve already written about how I just don’t like class pricing tiers for API consumption</a>, but I want to keep beating this drum until service providers hear what I’m singing. I think pricing tiers worked well to onboard the world with SaaS but for an API-driven world we a lot more flexibility and scalability when it comes to t
he business model.</p>

<p>As a small business I just can’t take another monthly payment, without some deep consideration, and bank account consultation. I’m looking at <a href="https://imageoptim.com/api/pricing">the ImageOptim API</a>, which is already a desktop tool I use, but the opportunity to automate my image optimization is very appealing. However, their entry level pricing tier is $9 a month for $1,000.00 calls. I might be able to add another monthly fee, but it damn well better be generating some value, or directly bringing in some new revenue.</p>

<p>My Amazon bill is always around $350.00, and I just downsized my Dropbox from $75 to $15 a month, and my CloudFlare is up to $75, and on and on. I have a whole list of monthly bills for a variety of services I depend on. The pricing tier based services are almost always the first to go when I have to downsize–Dropbox, gone. However, the ones that let me pay for what I use, tend to actually grow and are sustained. Overall I have about $1K a month to spend on SaaS and API solutions, but increasingly I’m favoring utility-based services over plan-based ones.</p>

<p>I think it is easy for API providers to look at their plans and pricing in a silo, exclusively from their perspective, and by itself the structure makes sense, but when you look at in the context of an entire portfolio of services for a small business, it just doesn’t make a lot of sense when you are using tens or hundreds of services. I know that all you business owners are looking for some stability when it comes to your business revenue, but you know what? So am I…</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/22/api-plans-arent-sustainable-for-my-small-business/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/21/patent-api-matchmaking-using-feature-models/">Patent US9639404: API Matchmaking Using Feature Models</a></h3>
        <span class="post-date">21 Jun 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/uspto.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>Here is another patent in my series of API related patents. I’d file this in the category as the other similar one from IBM–<a href="http://apievangelist.com/2017/06/08/patent-automated-assessment-of-terms-of-service-in-an-api-marketplace/">Patent US 8954988: Automated Assessment of Terms of Service in an API Marketplace</a>. It is a good idea. I just don’t feel it is a good patent idea.</p>

<blockquote>
  <p>Title: API matchmaking using feature models
Number: 09454409
Owner: International Business Machines Corporation
Abstract: Software that uses machine logic based algorithms to help determine and/or prioritize an application programming interface’s (API) desirability to a user based on how closely the API’s terms of service (ToS) meet the users’ ToS preferences. The software performs the following steps: (i) receiving a set of API ToS feature information that includes identifying information for at least one API and respectively associated ToS features for each identified API; (ii) receiving ToS preference information that relates to ToS related preferences for a user; and (iii) evaluating a strength of a match between each respective API identified in the API ToS feature information set and the ToS preference information to yield a match value for each API identified in the API ToS feature information set. The ToS features include at least a first ToS field. At least one API includes multiple, alternative values in its first ToS field.</p>
</blockquote>

<p>Honestly, I don’t have a problem with a company turning something like this into a feature, and even charging for it. I just wish IBM would help us solve the problem of making terms of service machine readable, so something like this is even possible. Could you imagine what would be possible if everybody’s terms of service were machine readable, and could be programmatically evaluated? We’d all be better off, and matchmaking services like this would become a viable service.</p>

<p>I just wish more of the energy I see go into these patent would be spent actually doing things in the API space. Providing low cost, innovative API services that businesses can use, <a href="http://apievangelist.com/2017/06/19/the-six-dimensions-of-api-patents-I-dwell-on/">instead of locking up ideas, filing them away with the government, so that they can be used at a later date in litigation and backdoor dealings</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/21/patent-api-matchmaking-using-feature-models/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/21/validating-api-schema-as-part-of-security-process/">Validating My API Schema As Part of My API Security Practices</a></h3>
        <span class="post-date">21 Jun 2017</span>
        <p><a href="https://arstechnica.com/information-technology/2017/06/psa-commenting-on-fcc-net-neutrality-plan-could-make-your-e-mail-public/"><img src="https://s3.amazonaws.com/kinlane-productions/fcc/fcc-makes-net-neutrality-commenters-email-addresses-public-through-api.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://apievangelist.com/2017/06/20/unknown-unknown-with-api-security/">I am spending more time thinking about the unknown unknowns when it comes to API security</a>. This means thinking beyond the usual suspects when thinking about API security like encryption, API keys, and OAuth. As I monitor the API space I’m keeping an eye out for examples of what might be security concerns that not every API provider is thinking about. [I found one recently in ARS Technica, about the Federal Communication Commission (FCC) leaking the email addresses through the <a href="https://arstechnica.com/information-technology/2017/06/psa-commenting-on-fcc-net-neutrality-plan-could-make-your-e-mail-public/">CC API for anyone who submitted feedback as part of any issues like the recent Net Neutrality discussion</a>.</p>

<p>It sounds like the breach with the <a href="https://www.fcc.gov/ecfs/public-api-docs.html">FCC API</a> was unintentional, but it provides a pretty interesting example of a security risk that could probably be mitigated with some basic API testing and monitoring, using common services like <a href="https://www.runscope.com/">Runscope</a>, or <a href="https://restlet.com/">Restlet Client</a>. Adding a testing and monitoring layer to your API operations helps you look beyond just an API being up or down. You should be validating that each endpoint is returning the intended/expected schema. Just this little step of setting up a more detailed monitor can give you that brief moment to think a little more deeply about your schema–the little things like whether or not you should be sharing the email addresses of thousands, or even millions of users.</p>

<p><a href="https://openreferral.github.io/api-specification/definition/">I’m working on a JSON Schema for my Open Referral Human Services API right now</a>. I want to be able to easily validate any API as human services compliant, but I also want to be able to setup testing and monitoring, as well as security checkups by validating the schema. When it comes to human services data I want to be able to validate every field present, ensuring only what is required gets out via the API. I am validating primarily to ensure an API and the resulting schema is compliant with HSDS/A standards but seeing this breach at the FCC has reminded me that taking the time to validate the schema for our APIs can also contribute to API security–for those attacks that don’t come from outside, but from within.</p>

<p><strong>Disclosure:</strong> <a href="https://restlet.com/">Restlet Client</a> and <a href="https://www.runscope.com/">Runscope</a> are API Evangelist partners.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/21/validating-api-schema-as-part-of-security-process/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/21/making-machine-learning-acessible-to-spreadsheet-power-users/">Making Machine Learning Accessible To Spreadsheet Power Users</a></h3>
        <span class="post-date">21 Jun 2017</span>
        <p><a href="https://blog.algorithmia.com/google-sheets-algorithmia-machine-learning-spreadsheets/"><img src="https://s3.amazonaws.com/kinlane-productions/algorithmia/AlgorithmiaSpreadsheets.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>My friends <a href="https://algorithmia.com">over at Algorithmia</a> are up to some good things–<a href="http://blog.algorithmia.com/google-sheets-algorithmia-machine-learning-spreadsheets/">making their algorithms available within a spreadsheet</a>. Algorithmia has created a set of open source scripts and walkthrough to help you inject the algorithms from their marketplace into your Google Spreadsheets.</p>

<p>They have seven useful algorithms to inject into spreadsheets:</p>

<ul>
  <li><a href="https://algorithmia.com/algorithms/timeseries/LinearDetrend">Linear Detrend</a> – removes increasing or decreasing trends in time series</li>
  <li><a href="https://algorithmia.com/algorithms/timeseries/AutoCorrelate">Autocorrelate</a> – used to analyze the seasonality of a time series</li>
  <li><a href="https://algorithmia.com/algorithms/timeseries/OutlierDetection">Outlier Detection</a> – flags unusual data points</li>
  <li><a href="https://algorithmia.com/algorithms/timeseries/Forecast">Forecast</a> – predict a given time series into the future</li>
  <li><a href="https://algorithmia.com/algorithms/nlp/Summarizer">Summarizer</a> – creates a text summary by extracting key topic sentences</li>
  <li><a href="https://algorithmia.com/algorithms/nlp/SocialSentimentAnalysis">Social Sentiment Analysis</a> – assigns sentiment ratings of “positive”, “negative” and “neutral”</li>
  <li><a href="https://algorithmia.com/algorithms/web/ShareCounts">Count Social Shares</a> – returns the number of times that URL has been shared on various social media sites</li>
</ul>

<p><a href="https://github.com/kenburcham/algorithmia-google">The Google scripts are available on Github</a>, thanks to the hard work of Ken Burcham. It provides yet another interesting example of how a spreadsheet can be used as an API client but it also provides an interesting example of how machine learning API providers can get their ML warez in front of the average business user. Developers building applications with your ML APIs is one thing but getting the average business spreadsheet power user to put your ML API to work in their everyday workflow is a whole other world of API integration opportunity.</p>

<p><a href="http://spreadsheets.apievangelist.com/">I have been preaching the spreadsheet to API connection for a while now</a>. I know that many API developers want to do away with the spreadsheet, but I think they would be better off focusing on injecting their API solutions into spreadsheets like Algorithmia is doing. When you are designing your algorithmic-centric APIs, providing access to your machine learning models, make sure you keep your APIs simple and doing one thing well like Algorithmia does, then your ML APIs can be injected into the spreadsheets around the globe that are driving business each day.</p>


        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/21/making-machine-learning-acessible-to-spreadsheet-power-users/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/i-am-working-with-elastic-beam-to-help-define-api-security/">I Am Working With Elastic Beam To Help Define API Security</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><a href="https://www.elasticbeam.com/"><img src="https://s3.amazonaws.com/kinlane-productions/elastic-beam/elasticbeam-vertical.jpg" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>Security is the number one concern companies, organizations, institutions, and government agencies have when I’m talking with them about doing APIs. Strangely it is also one of the most deficient, and underinvested areas of API operations. Companies are just learning to design, deploy, and manage their APIs, and monitoring, testing, and security are still on the future road map for many API providers I know.</p>

<p>Security is one of the important areas I’ve been trying to find more time and resources to invest into my research, and I’ve been on the hunt for interesting providers to partner with when it comes to defining security as it applies to APIs. There are a number of web and infrastructure security companies out there, but there aren’t enough that are only focused on just APIs. With the number of APIs increasing, we need more eyeballs on the problem, and even more services and tools to stay ahead of the curve.</p>

<p>I finally found a worthwhile partner to help explore API security as part of my regular work as the API Evangelist, a new API security focused startup <a href="https://www.elasticbeam.com/product/#api-behavioral">called Elastic Beam</a>. They are a brand new effort exclusively focused on API security, who are hitting all the buzzworthy areas of the tech space (Artificial Intelligence, Machine Learning, etc), while also doing one thing and doing it well–API security. ElasticBeams core products are:</p>

<ul>
  <li><a href="https://www.elasticbeam.com/product/#api-behavioral">API Behavioral Security</a> - Keeping an eye on the unknown unknowns when it comes to API threats.</li>
  <li><a href="https://www.elasticbeam.com/product/#deep">Deep API Insight</a> - Access insights extracted from data ingested across all Elastic Beam implementations.</li>
  <li><a href="https://www.elasticbeam.com/product/#api-security">API Security Enforcer</a> - Actually blocking and providing a smokescreen for threats against an API.</li>
  <li><a href="https://www.elasticbeam.com/product/#hybrid">Hybrid Cloud API Security</a> - Plugs into existing API service and infrastructure providers.</li>
  <li><a href="https://www.elasticbeam.com/product/#secure">Secure MQTT Proxy</a> - Focused on API security when it comes to the Internet of Things.</li>
</ul>

<p><img src="https://s3.amazonaws.com/kinlane-productions/elastic-beam/infographic-products.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’ve seen Elastic Beam in action, and have a copy to play with as I’m exploring a variety of scenarios in alignment with my API security research. Elastic Beam is going to invest in API Evangelist so I can pay attention to API security more, producing stories, guides, and white papers, and I’m going to help translate what it is they are offering, and help keep them focused on API security, and doing it well.</p>

<p><a href="https://www.elasticbeam.com">Elastic Beam is live</a>. If you want to talk to them about security let me know, or just head over <a href="https://www.elasticbeam.com">to their website</a>. Also, if there are any specific areas of my API security research you’d like me to focus on, let me know. I’ve been having weekly calls with their team and advising them on their release. We’ll see where the relationship goes, but I’m stoked to finally have someone I can partner with to focus on API security. It is an area that needs more research, discussion, as well as storytelling, to help bring awareness to API providers–this stuff takes time, and we need more smart people on the case as soon as possible.</p>

<p>From the time I’ve spent with them, the Elastic Beam team seems to get the problem, and have invested in the right technology. I’m looking forward to working with them to continue to map out the API security space, identify and share information on the most common threats facing API providers. Stay tuned for more about API security, thanks to the Elastic Beam team.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/i-am-working-with-elastic-beam-to-help-define-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/internet-as-example-of-markets-working-things-out/">Internet As Example Of Markets Working Things Out</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p>Is this writing?</p>

<p>Rural Broadband
Mobile</p>

<p>Not worth investing</p>

<p>Left behind</p>

<p>Vote in people who make it worst.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/internet-as-example-of-markets-working-things-out/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/tensor-flow-object-recognition/">API Wrappers To Help Bring Machine Learning Into Focus</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/tensorflow/kites_detections_output.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I was taking a look a<a href="https://github.com/tensorflow/models/tree/master/object_detection">t the Tensorflow Object Detection API</a>, and while I am interested in the object detection, the usage of API is something I find more intriguing. It is yet another example of how diverse APIs can be. This is not a web API, but an API on top of a single dimension of <a href="https://www.tensorflow.org/">the machine learning platform TensorFlow</a>.</p>

<p>“The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models.” It is just a specialized code base helping abstract away the complexity of one aspect of using TensorFlow, specifically for detecting objects in images. You could actually wrap this API with another web API and run on any server or within a single container as a proper object recognition API.</p>

<p>For me, it demonstrates one possible way of wrapping a single or cross section of a machine learning implementation to abstract away the complexity and helping you train and deploy ML models in this particular area. This approach to deploying an API on top of ML shows that you can use to APIs to help simplify and abstract ML for developers. This can be done to help satisfy business, regulatory, privacy, security, and other real or perceived concerns when it comes to artificial intelligence, machine learning, or any other digital voodoo that resembles magic.</p>

<p>No matter how complex the inputs and outputs of an algorithm are, you can always craft an API wrapper, or series of API wrappers that help others make sense of those inputs, from a technical, business, or even political perspective. I just wanted to highlight this example of ML being wrapped with an API, even if it isn’t for all the same reasons that I would be doing it. It’s just part of a larger toolbox I’m looking to create to help me make the argument for <a href="http://apievangelist.com/2016/08/04/pushing-for-more-algorithmic-transparency-using-apis/">more algorithmic transparency in the machine learning platforms</a> we are developing.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/tensor-flow-object-recognition/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/tight-coupling-to-our-mobile-phones/">Tightly Coupled To Our Mobile Phones</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-mobile-apps.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>I had ditched my phone last year after being with AT&amp;T for just shy of 20 years. Not having a phone made me realize how much you need a phone number to exist online these days. Facebook, Twitter, Google, all needed me to have a phone number which I can verify from time to time, to keep my accounts active.</p>

<p>In addition to just needing it for an account, I also need it regularly to secure my world via two-factor authentication. Sometimes I need it for SMS, but mostly I just need the authenticator app–both requiring at least having the mobile device in my presence. I’m not very tightly coupled with my phone, but it feels like it increasingly like it is always coupled to me.</p>

<p>I’m guessing that if it isn’t our mobile phones, in the future there will always be at least one device we will be required to have as part of our identity, and be helping us secure both our physical and digital worlds. It isn’t something I enjoy but like pretty everyone else, it is not a cord I am going to be able to cut anytime soon.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/tight-coupling-to-our-mobile-phones/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/unknown-unknown-with-api-security/">The Unknown Unknowns Of API Security</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><a href="http://security.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-security-unknown.png" align="right" width="25%" style="padding: 15px;" /></a></p>
<p>I am trying to wrap my head around the next steps in the evolution of <a href="http://security.apievangelist.com/">API security</a>. I am trying to help separate some of the layers of what we collectively call API security, into some specific building blocks I can reference in my storytelling. I’m ramping up my API security research as I onboard a new API service provider partner, and will have more resources to invest in the API security discussion.</p>

<p>Let’s start with the easy “Known Knowns”:</p>

<ul>
  <li>Encryption - Using encryption across all aspects of API operations from portal to base URL.</li>
  <li>API Keys - Making sure everyone who is accessing an API is keying up and passing along with each request.</li>
  <li>OAuth - Getting more granular with access by applying OAuth when there is access to 3rd party data and content.</li>
  <li>Rate Limiting - Limiting how much of a resource any single API consumer can access using rate limiting.</li>
</ul>

<p>These are the first things that come to mind when the topic of API security is brought up. I’d say most conversation begin with encryption, but as someone progresses on their API journey they begin to understand how they can key things up, using OAuth, rate limiting, and other aspects of API management to secure their API operations.</p>

<p>Next, I want to think about some the “Known Unknowns”, things like:</p>

<ul>
  <li>Freeloaders - People with multiple accounts, and generally aren’t healthy consumers.</li>
  <li>Errors - Errors, misconfigured, and malformed requests, responses, and anything that generally gums up the gears of operations.</li>
  <li>Vulnerabilities - Making sure all known software and hardware vulnerabilities are patched and communicated as part of operations.</li>
  <li>Attacks - Defending against the known attacks, staying in tune with OWASP and other groups who are actively identifying, studying, and sharing attacks.</li>
</ul>

<p>These are the things we might not totally understand or have implemented, but they are known(ish). With the right amount of resources and expertise, any API team should be able to mitigate against these areas of security. There is always a lot of work to turn the unknowns into knowns in this area, but they are doable.</p>

<p>Now I want to think a little about the “Unknown Unknowns”, likes like:</p>

<ul>
  <li>DNS - What is happening at the DNS level as it pertains to my API security?</li>
  <li>Relationship - Relationship between requests, even if they are using different keys, IP addresses, and other elements–where is the overlap?</li>
  <li>Threats - What information is available to me regarding new and emerging threats that I’m only beginning to see, or maybe my partners and others in same space are seeing?</li>
  <li>Sharing - Are there opportunities to share information and see a bigger picture when it comes to vulnerabilities and threats?</li>
</ul>

<p>These are just a handful of my initial thoughts on what the unknown unknowns might be. Things that are currently off the radar of my known API security practices. API management seems to dominate and in some cases terminate the API security conversation, but I have the feeling there are numerous other considerations out there that we are not seeing. I’m just looking to begin defining this new bucket of security considerations so I can keep adding items to it as I’m doing my research.</p>

<p>From your perspective, what are the biggest threats out there for API security that many API providers are completely unaware of? I’m looking to keep expanding on this frontline of API security and turn up the heat beneath <a href="http://security.apievangelist.com">my research</a> while I have the resources to do so. I feel like the API security conversation has kind of stagnated after the last wave of API management growth, leaving many providers thinking they have everything covered.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/unknown-unknown-with-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/the-general-services-administration-api-strategy-considers-how-to-generate-revenue/">The General Services Administration API Strategy Considers How To Generate Revenue</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/gsa/gsa-api-strategy-diagram.png" align="right" width="40%" style="padding: 15px;" /></p>
<p><a href="https://tech.gsa.gov/assets/downloads/GSAAPIStrategy.pdf">The General Services Administration(GSA) has an API strategy</a>, which describes “GSA’s future direction for agency­wide API management including design, development, architecture, operations, and support, and security.” Ok, let’s pause there. I want to point out that this isn’t just an API design guide. That is a portion of it, but it also touches on some of the most obvious (deployment), and the most critical aspects (security) of API operation–important stuff.</p>

<p>The objectives for the GSA crafting an API strategy are:</p>

<p>­* Harness API management to maximize customer value and technical efficiencies.
­* Adopt industry best practices with API design, development, and management.
­* Consider opportunities for revenue through API offerings.</p>

<p>I always enjoy seeing federal agencies talk about efficiencies and best practices, but it gives me hope that all of this might actually work when I see federal agencies actually “considering opportunities for revenue through API offerings”. Especially at the GSA, who provides technical guidance to the other 400+ federal agencies, as well as at the state and municipal level. I am not excited about our government charging money for digital resources, I am excited about our government exploring how it will generate revenue to sustain itself in the future.</p>

<p>I know there are a lot of open data advocates who can’t wrap their mind around this, but this is how the government will generate needed tax revenue to operate in the future–using APIs. Our government currently generates a portion of its revenue from the sale of physical resources like timber, mining, and agriculture, why should things be different when it comes to taxing and regulating digital resources being made available via the web, mobile, and device applications. While there is still lots to figure out on this front, I am glad to see the GSA putting some thought into the role APIs will play in the future of funding the government services we all depend on each day.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/the-general-services-administration-api-strategy-considers-how-to-generate-revenue/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/idks-are-always-first-step-in-api-integration/">IDK Is Always The First Step To API Integration</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-shared.png" align="right" width="35%" style="padding: 15px;" /></p>

<p>I spend a lot of time trying to figure out what technology does. I read press releases, pitch emails, documentation, and marketing materials trying to get an idea of what is possible. While many of the APIs I come across are intuitive, and just make sense there is still a significant portion of them that leave me scratching my head regarding what it even does.</p>

<p>As developers, it can be easy to think about the SDKs you will need to support API integration with your API, but I think you are making a lot of assumptions about your consumers when you focus your initial energy here. The first step in any API integration begins with IDK and not the SDK. When a potential API consumer comes across your API, the first question to be answered is: what does this API do? If the answer is I Don’t Know (IDK), we have a problem. A problem no amount of SDKs will solve, no matter how many languages you create them in.</p>

<p>Every API begins with an IDK. What does the Twilio API do? What does the Stripe API do? The answer to this initial question for your API cannot be IDK! As soon as I read your press release, land on the home page of your developer area, I should know what your API does in 5 seconds or less. If I walk away from our first interaction with an IDK, the chances I’ll be coming back are pretty slim. Make sure you always address the IDK, before you get to work on your SDK, for your API(s).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/idks-are-always-first-step-in-api-integration/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/the-six-dimensions-of-api-patents-I-dwell-on/">The Six Dimensions Of API Patents I Dwell On</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/supreme-court-statues.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>Each story I publish about API patents will usually get a comment, Tweet, LinkedIn, or other comments letting me know that the owner of the patent is only doing it in a defensive pattern. I fully grasp that this is the predominant stance when it comes to defending a patent portfolio, but I prefer seeing six dimensions to this discussion–looking beyond this single position.</p>

<p>When thinking about why a patent exists I see it in six dimensions:</p>

<ul>
  <li><strong>Idea</strong> - That someone has an idea, thinks it is theirs and feels that this should exist as a patent.</li>
  <li><strong>Patent</strong>- That some have the resources to craft the patent application, and file it with the patent office.</li>
  <li><strong>Filing</strong> - That the patent authority thinks an idea is patent-worthy, and something that should be approved.</li>
  <li><strong>Litigation</strong> - When someone wields a patent as part of litigation, either in an offensive, or defensive stance.</li>
  <li><strong>Public Deals</strong> - When patent shows up as part of an acquisition, partnership, and wielded publicly as part of some deal.</li>
  <li><strong>Backroom Deals</strong> - When patents are leveraged as part of backroom deals when negotiating with companies and investors, and sizing up the value on the table.</li>
</ul>

<p>We only have insight into the middle four dimensions. We really don’t have any view into the individual reasons behind a patent, and we do not get access to how they are wielded and leveraged behind closed doors. I think that defending yourself as part of any court case makes sense, but I’m discussing API patents to help shine a light and understand what is happening within the other dimensions.</p>

<p>Overall I find that the existence of patents to speak volumes about a company’s motivations. The way they showcase or do not showcase their API portfolio contributes to this conversation in important ways. Sadly we will never get a full picture of the individual and backroom aspects of how API patents are used. However, I’m confident I can extract enough meaning from the existence of a patent, the information within the application, and any litigation that has occurred to paint a pretty clear picture of the motivations behind having a patent on your API(s).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/the-six-dimensions-of-api-patents-I-dwell-on/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/three-rules-of-my-api-communication-strategy/">Three Rules Of My API Communication Strategy</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><a href="http://communications.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/three-rules-for-a-communication-strategy.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>Communicating effectively around API operations is the number one illness I see across the API space. Engineers are good at writing code and devopping their way to a usable API, but often fall short when it comes to telling the story of what the API does, and consistently beating this drum until people become familiar with what is going on.</p>

<p>An effective API communication strategy is more art than it is science, and I’d like to share three of my rules when it comes to telling stories on the API Evangelist platform.</p>

<ul>
  <li><strong>Honesty</strong> - Be honest with yourself, you’re readers, and those you are writing about. If you can’t find a way to be honest in your writing go find a new job–it won’t be sustainable.</li>
  <li><strong>Consistent</strong> - Communicate every day. Ok, maybe every other day. Regardless of frequency, make sure you are communicating on a consistent basis, setting the tone for what your audience can expect.</li>
  <li><strong>Compelling</strong> - Make it compelling. No, not every single post will be compelling, but make it your primary goal to tell a compelling story that you would read yourself, if it was on someone else’s blog.</li>
</ul>

<p>That is it. Don’t sweat all the technical details. Just write on the blog, spend the time on Twitter, participate in threads on Github, and regularly dive into the bowels of the Slack. Don’t spend all your time worrying about your communication strategy, just make sure you give it a sensible amount of time, and follow these three rules–the rest will come.</p>

<p>As of this moment, there are 2,680 blog posts on API Evangelist, with the first entry in September 2010. These three rules have kept me on track when I was taking money from bigcos like Intel and Mulesoft, and kept me from losing my shit when I was traveling and drinking too heavily. These three rules are what keep me doing this effectively after seven years.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/three-rules-of-my-api-communication-strategy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/i-would-like-to-see-more-api-test-drives/">I Would Like To See More API Test Drives</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><a href="https://azure.microsoft.com/en-us/blog/azure-marketplace-test-drive/?v=17.23h"><img src="https://s3.amazonaws.com/kinlane-productions/c627d90c-1615-4750-b45c-9658b45596bc.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://azure.microsoft.com/en-us/blog/azure-marketplace-test-drive/?v=17.23h">The Azure Marketplace has the ability to test drive anything that is deployed in the Azure Marketplace</a>. As someone who has to sign up for an endless number of new accounts to be able to play with APIs and API services, I’m a big fan of the concept of a test drive–not just for web applications, or backend infrastructure, but specifically for individual APIs and microservices.</p>

<p>From the Azure site:  <em>Test Drives are ready to go environments that allow you to experience a product for free without needing an Azure subscription. An additional benefit with a Test Drive is that it is pre-provisioned - you don’t have to download, set up or configure the product and can instead spend your time on evaluating the user experience, key features, and benefits of the product.</em></p>

<p>I like it. I want more of these. I want to be able to test drive, then deploy any API I want. I don’t want to sign up for an account, enter my credit card details, talk to sales, or signup for 30 day trial–I want to test drive. I want it to have data in it, and be pre-configured for a variety of use cases. Helping me understand what is possible.</p>

<p>I want all the friction between me finding an API (discovery via marketplace) understanding what an API does, test driving, then deployment of the API in any cloud I want. I think we are still a little bit off from this being as frictionless as I envision in my head, but I hope with enough nudging we will get there very soon.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/i-would-like-to-see-more-api-test-drives/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/unknown-unknown-with-api-security/">The Unknown Unknowns Of API Security</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><a href="http://security.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-security-unknown.png" align="right" width="25%" style="padding: 15px;" /></a></p>
<p>I am trying to wrap my head around the next steps in the evolution of <a href="http://security.apievangelist.com/">API security</a>. I am trying to help separate some of the layers of what we collectively call API security, into some specific building blocks I can reference in my storytelling. I’m ramping up my API security research as I onboard a new API service provider partner, and will have more resources to invest in the API security discussion.</p>

<p>Let’s start with the easy “Known Knowns”:</p>

<ul>
  <li>Encryption - Using encryption across all aspects of API operations from portal to base URL.</li>
  <li>API Keys - Making sure everyone who is accessing an API is keying up and passing along with each request.</li>
  <li>OAuth - Getting more granular with access by applying OAuth when there is access to 3rd party data and content.</li>
  <li>Rate Limiting - Limiting how much of a resource any single API consumer can access using rate limiting.</li>
</ul>

<p>These are the first things that come to mind when the topic of API security is brought up. I’d say most conversation begin with encryption, but as someone progresses on their API journey they begin to understand how they can key things up, using OAuth, rate limiting, and other aspects of API management to secure their API operations.</p>

<p>Next, I want to think about some the “Known Unknowns”, things like:</p>

<ul>
  <li>Freeloaders - People with multiple accounts, and generally aren’t healthy consumers.</li>
  <li>Errors - Errors, misconfigured, and malformed requests, responses, and anything that generally gums up the gears of operations.</li>
  <li>Vulnerabilities - Making sure all known software and hardware vulnerabilities are patched and communicated as part of operations.</li>
  <li>Attacks - Defending against the known attacks, staying in tune with OWASP and other groups who are actively identifying, studying, and sharing attacks.</li>
</ul>

<p>These are the things we might not totally understand or have implemented, but they are known(ish). With the right amount of resources and expertise, any API team should be able to mitigate against these areas of security. There is always a lot of work to turn the unknowns into knowns in this area, but they are doable.</p>

<p>Now I want to think a little about the “Unknown Unknowns”, likes like:</p>

<ul>
  <li>DNS - What is happening at the DNS level as it pertains to my API security?</li>
  <li>Relationship - Relationship between requests, even if they are using different keys, IP addresses, and other elements–where is the overlap?</li>
  <li>Threats - What information is available to me regarding new and emerging threats that I’m only beginning to see, or maybe my partners and others in same space are seeing?</li>
  <li>Sharing - Are there opportunities to share information and see a bigger picture when it comes to vulnerabilities and threats?</li>
</ul>

<p>These are just a handful of my initial thoughts on what the unknown unknowns might be. Things that are currently off the radar of my known API security practices. API management seems to dominate and in some cases terminate the API security conversation, but I have the feeling there are numerous other considerations out there that we are not seeing. I’m just looking to begin defining this new bucket of security considerations so I can keep adding items to it as I’m doing my research.</p>

<p>From your perspective, what are the biggest threats out there for API security that many API providers are completely unaware of? I’m looking to keep expanding on this frontline of API security and turn up the heat beneath <a href="http://security.apievangelist.com">my research</a> while I have the resources to do so. I feel like the API security conversation has kind of stagnated after the last wave of API management growth, leaving many providers thinking they have everything covered.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/unknown-unknown-with-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/idks-are-always-first-step-in-api-integration/">IDK Is Always The First Step To API Integration</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><img src="­https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-mark.png" align="right" width="20%" style="padding: 15px;" /></p>
<p>I spend a lot of time trying to figure out what technology does. I read press releases, pitch emails, documentation, and marketing materials trying to get an idea of what is possible. While many of the APIs I come across are intuitive, and just make sense there is still a significant portion of them that leave me scratching my head regarding what it even does.</p>

<p>As developers, it can be easy to think about the SDKs you will need to support API integration with your API, but I think you are making a lot of assumptions about your consumers when you focus your initial energy here. The first step in any API integration begins with IDK and not the SDK. When a potential API consumer comes across your API, the first question to be answered is: what does this API do? If the answer is I Don’t Know (IDK), we have a problem. A problem no amount of SDKs will solve, no matter how many languages you create them in.</p>

<p>Every API begins with an IDK. What does the Twilio API do? What does the Stripe API do? The answer to this initial question for your API cannot be IDK! As soon as I read your press release, land on the home page of your developer area, I should know what your API does in 5 seconds or less. If I walk away from our first interaction with an IDK, the chances I’ll be coming back are pretty slim. Make sure you always address the IDK, before you get to work on your SDK, for your API(s).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/idks-are-always-first-step-in-api-integration/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/data-access-and-api-strategy-in-the-european-union/">Data Access and API Strategy in the European Union</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p>http://dret.typepad.com/dretblog/2017/06/data-access-and-api-strategy-in-the-european-union.html</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/data-access-and-api-strategy-in-the-european-union/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/making-your-api-available-in-marketplaces/">Publishing Your API In The AWS Marketplace</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/box/box-platform-cloud-content-management-apis-aws-marketplace.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’ve been watching the conversation around how APIs are discovered since 2010 and I ave been working to understand where things might be going beyond ProgrammableWeb, to the Mashape Marketplace, and even investing in my own <a href="http://apisjson.org">API discovery format APIs.json</a>. It is a layer of the API space that feels very bipolar to me, with highs and lows, and a lot of meh in the middle. I do not claim to have “the solution” when it comes to API discovery and prefer just watching what is happening, and contributing where I can.</p>

<p>A number interesting signals for API deployment, as well as API discovery,  are coming out of Amazon Marketplace lately. I find myself keeping a closer eye on <a href="https://aws.amazon.com/marketplace/search/results?searchTerms=API&amp;page=1&amp;ref_=nav_search_box">the almost 350 API related solutions in the marketplace</a>, and today <a href="https://aws.amazon.com/marketplace/pp/B06XY1XHGV/?ref=_ptnr_awsblg">I’m specifically taking notice of the Box API availability in the AWS Marketplace</a>. I find this marketplace approach to not just API discovery via an API marketplace, but also API deployment very interesting. AWS isn’t just a marketplace of APIs, where you find what you need and integrate directly with that provider. It is where you find your API(s) and then spin up an instance within your AWS infrastructure that facilitates that API integration–a significant shift.</p>

<p>I’m interested in the coupling between API providers and AWS. AWS and Box have entered into a partnership, but their approach provides a possible blueprint for how this approach to API integration and deployment can scale. How tightly coupled each API provider chooses to be, looser (proxy calling the API), or tighter (deploying API as AMI), will vary from implementation to implementation, but the model is there. The Box AWS Marketplace instance dependencies on the Box platform aren’t evident to me, but I’m sure they can easily be quantified, and something I can get other API providers to make sure and articulate when publishing their API solutions to AWS Marketplace.</p>

<p><a href="http://apievangelist.com/2014/01/30/what-will-it-take-to-sell-my-api-as-a-wholesale-resource/">AWS is moving towards earlier visions I’ve had of selling wholesale editions of an API</a>, helping you <a href="http://apievangelist.com/2017/04/25/your-wholesale-api-for-sale-in-the-major-api-marketplaces/">manage the on-premise and private label API contracts for your platform</a>, and <a href="http://apievangelist.com/2017/01/03/exploring-the-economics-of-wholesale-and-retail-algorithmic-apis/">helping you explore the economics of providing wholesale editions of your platforms</a>, either tightly or loosely coupled with AWS infrastructure. Decompiling your API platform into small deployable units of value that can be deployed within a customer’s existing AWS infrastructure, seamlessly integrating with existing AWS services.</p>

<p><a href="https://developer.box.com/page/box-platform-and-aws">I like where Box is going with their AWS partnership</a>. I like how it is pushing forward the API conversation when it comes to using AWS infrastructure, and specifically the marketplace. I’ll keep an eye on where things are going. Box seems to be making all the right moves lately <a href="http://apievangelist.com/2017/05/22/box-goes-all-in-on-openapi/">by going all in on the OpenAPI Spec</a>, and decompiling their API platform making it deployable and manageable from the cloud, <a href="http://apievangelist.com/2017/06/16/serverless-blueprints-for-your-api/">but also much more modular and usable in a serverless way</a>. Providing us all with one possible blueprint for how we handle the technology and business of our API operations in the clouds.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/making-your-api-available-in-marketplaces/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/serverless-blueprints-for-your-api/">Serverless Blueprints For Your API</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/amazon/lambda_find_box_blue_1.png" width="40%" align="right" style="padding: 15px" /></p>
<p><a href="http://serverless.apievangelist.com/">Serverless</a> is spreading across the API sector, and is something that leading API providers are beginning to embrace as part of their operations. I saw an interesting example of this out of AWS and Box lately, with <a href="https://aws.amazon.com/blogs/aws/box-platform-on-aws-marketplace-lambda-blueprints-sample-code/">the announcement of Lambda blueprints and code for integrating with the Box API via the AWS platform</a>.</p>

<p>The Box serverless blueprints show you how to call the Box APIs and connect a Box webhook to a Lambda function via the Amazon API Gateway–providing some pretty interesting use cases for using Box via serverless functions:</p>

<ul>
  <li><a href="https://medium.com/box-developer-blog/manage-user-authentication-with-box-platform-using-amazon-cognito-8828b5f1d1c9">Manage User Authentication with Box Platform using Amazon Cognito</a> – How to use Amazon Cognito to power a login page for application users.</li>
  <li><a href="https://medium.com/box-developer-blog/add-deep-learning-based-image-recognition-to-your-box-app-with-amazon-rekognition-1878ab148b70">Add Deep Learning-based Image Recognition to your Box App with Amazon Rekognition</a> – How to build an image tagging application that is powered by Amazon Rekognition.</li>
</ul>

<p>They are some pretty basic use cases, but it is the approach that opens up an entirely new door for API integration for me–Serverless Development Kits (SDK). Every API providers should have a whole catalog of open source serverless scripts that are deployable to Lambda, and other serverless platforms. <a href="http://apievangelist.com/2016/09/12/where-is-the-deploy-to-aws-and-google-button/">Of course, there are one-click buttons deploy each individual script to the cloud platform of your choice</a>.</p>

<p>I’m diving into the other side of this story for me, where Box is embracing a tighter coupling with the AWS platform as part of their operations. <a href="https://aws.amazon.com/marketplace/pp/B06XY1XHGV/?ref=_ptnr_awsblg">I am looking at how Box is providing a copy of the Box API for deployment on AWS</a>. This all reflects how I see things working in the future, where you can deploy individual API integration scripts, as well as deploy APIs to a serverless environment like this–empowering anyone to become both API consumer and provider via the AWS, or any other cloud ecosystem.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/serverless-blueprints-for-your-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/github-helping-set-the-bar-for-your-api-community-code-standards/">Github Helping Set The Bar For Your API Community Code Standards</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/github/github-community-standards.png" align="right" width="40%" style="padding: 15px;" /></p>
<p><a href="https://github.com/blog/2380-new-community-tools">Github has released an interesting new feature to help users better manage some of the community elements of the repositories they use to manage code, definitions, data, and content across API operations</a>. For each repository, you now have a community profile tab, where you’ll see a checklist showing how your project compares to Github recommended community standards.</p>

<p>If you are lacking one of these common elements, it gives you an option to quickly add one of the missing pieces. I still have some repositories where I don’t properly have licensing dictated, even a handful without a README (I know). Almost none of my repositories have a code of conduct or contributing agreement. The new feature adds another task to my list of maintenance items I’ll be tackling to help standardize the projects I manage on Github (which is everything I do).</p>

<p>I like where Github is going with this. <a href="http://portal.minimum.apievangelist.com/">It resembles what I am trying to do with API projects by identifying the common building blocks of API deployments, providing a checklist that API providers can follow when publishing their APIs–which is often done using Github</a>. One way that API providers can help standardize these common elements across groups is to create a working API portal prototype that is forkable on Github, <a href="https://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/">similar to what the GSA is doing for the federal government with their working API prototype</a>.</p>

<p>Most of the time API architects and eveloper just need a friendly reminder, or possibly a working example they can follow when it comes to standardizing how we deploy and manage the community elements of our API operations. I hope what Github is doing with their community standards baseline will keep evolving, spreading, and eventually be something that Github organizations can templatize, standardize, and define their own criteria regarding the minimum viable aspects of community operations for the repositories they have on Github.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/github-helping-set-the-bar-for-your-api-community-code-standards/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/15/zooming-out-to-the-100k-level-then-back-to-api-sea-level-with-openapi-and-apis-dot-json/">Zooming Out To The 100K Level Then Back To API Sea Level With OpenAPI And APIs.json</a></h3>
        <span class="post-date">15 Jun 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/drone_control_sunset.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’m wrestling with the different levels of conversations I’m having around <a href="https://openreferral.github.io/api-specification/definition/">my human services API work</a>. Some of my audience are more technical and are pushing for discussion at the granular level, while other parts of my audience are more about the business of things at the 100K. I appreciate these types of projects, but when there are many different conversations going on at many different levels, it is a lot of work to wrestle things into something coherent that everyone involved will appreciate.</p>

<p>One day I’m thinking about which individual fields are required, then next I will considering how multiple human services API integrators will be syndicating and sharing information between clusters of human service API implementations. While I’m relying on Github, and Slack to facilitate conversations that going on, I am ultimately relying on <a href="https://www.openapis.org/">OpenAPI</a> and <a href="http://apisjson.org">APIs.json</a> to help me hammer out the contract that will speak to the developers at the granular level but can also communicate the business and political terms of the API contract.  It will describe which fields are required as well as describe the webhooks I need to define how to syndicate and share between implementations.</p>

<p>OpenAPI is pretty focused on helping me with things happening at API sea level, but I’m exploring using APIs.json to help me organize conversations all the way up to the 100K foot level. Things like, where do I signup for my API keys, access partnership levels of access, find the terms of service, or possibly someone to contact and answer a question. Then using the OpenAPI I can publish documentation for developers to understand the surface area of the API (sea level), and while the APIs.json includes a pointer to this discussion, it also provides pointers to other discussions going on around support, communications, changes, privacy, security, so that I can generate documentation for business and partner stakeholders as well.</p>

<p>I’m working on an example of doing this for <a href="https://openreferral.github.io/api-specification/definition/">my Open Referral Human Services API</a>. An APIs.json + OpenAPI that helps articulate what is happening with any single human services API implementation from sea level to 100K. The trick is I also need to articulate how this will work at scale across clusters of human services API implementations, allowing vendors and partners to syndicate and federate. With everything defined as a machine readable index (using APIs.json and OpenAPI), which can be used to generate very technical API documentation, as well as more business-friendly aspects of operations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/15/zooming-out-to-the-100k-level-then-back-to-api-sea-level-with-openapi-and-apis-dot-json/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/15/a-community-approval-dimension-when-adding-updating-and-deleting-via-api/">A Community Approval Dimension When Adding, Updating, And Deleting Via API</a></h3>
        <span class="post-date">15 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-community-join.png" align="right" width="30%" style="padding: 15px;" /></p>
<p>One of the projects I’m working on as part my <a href="https://openreferral.github.io/api-specification/definition/">Human Services API</a> work is trying to define the layer that allows developers to add, update, and delete data via the API. We ultimately want to empower 3rd party developers, and external stakeholders to help curate and maintain critical human services data within a community, through trusted partners.</p>

<p>The Human Services API allows for the reading and writing of organizations, locations, and services for any given area. I am looking to provide guidance on how API implementors can allow for POST, PUT, PATCH, and DELETE on their API, but require approval before any changing transaction is actually executed. Requiring the approval of an internal system administrator to ultimately give the thumbs up or thumbs down regarding whether or not the change will actually occur.</p>

<p>A process which immediately begs for the ability to have multiple administrators or even possibly involving external actors. How can we allow organizations to have a vote in approving changes to their data? How can multiple data stewards be notified of a change, and given the ability to approve or disprove, logging every step along the way? Allowing any change to be approved, reviewed, audited, and even rolled back. Making public data management a community affair, with observability and transparency built in by default.</p>

<p>I am doing research into different approaches to tackling this, ranging from community approaches like Wikipedia, to publish and subscribe, and other events or webhook models. I am looking for technological solutions to opening up approval to the API request and response structure, with accompanying API and webhook surface area for managing all aspects of the approval of any API changes. If you know of any interesting solutions to this problem I’d love to hear more, so that I can include in my research, future storytelling, and ultimately the specification for <a href="https://openreferral.org/">the Open Referral Human Services Data Specification and API</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/15/a-community-approval-dimension-when-adding-updating-and-deleting-via-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/15/my-api-communication-stack-for-the-human-services-api-specification/">My API Communication Stack For The Human Services API Specification</a></h3>
        <span class="post-date">15 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/open-referral/human-services-data-specification-draft-snapshot.png" align="right" width="40%" style="padding: 15px" /></p>
<p>I’m refining my approach to moving forward the discussion around <a href="https://openreferral.github.io/api-specification/definition/">the Human Services Data Specification and API</a> in an attempt to include more vendors and implementors in the conversation. Part of this work is to streamline how we move forward an increasing number of conversations regarding the schema and API definition.</p>

<p>I am looking help solidify our communication strategy around the human services API, and help make clear which channels participants can tune into:</p>

<ul>
  <li><strong>Github</strong> - Github Issues is where the specific conversation around a variety</li>
  <li><strong>Slack</strong> - A variety of Slack channels for discussing the evolution of API.</li>
  <li><strong>Blog</strong> - Storytelling via API Evangelist, and specific project level blogs.</li>
  <li><strong>GHangouts</strong> - Virtual gatherings to discuss the API via video conferencing.</li>
</ul>

<p>These are the channels where the HSDS/A conversations are occurring. It is spread unevenly across these synchronous and asynchronous digital channels. We are using a variety of signals including Github issues, Slack messaging as well as video conference calls, blog posts, and semi-regular virtual gatherings.</p>

<p>I am heavily using the blog post to organize my ideas, distilling down the explosion of information, ideas, and technical details in smaller, coherent, bite-size chunks. This helps me organize and better communicate what’s going on, which includes having a single URL to share with new players. In fact, this blog post is part of me pulling together my communication around the API communications strategy for the human services API project and will be the most current URL I share with people.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/15/my-api-communication-stack-for-the-human-services-api-specification/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/">The GSA API Standards With A Working Prototype API And Portal</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/"><img src="https://s3.amazonaws.com/kinlane-productions/gsa/gsa-prototype-api-portal.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>One way to help API developers understand API design is to provide them with a design guide, helping set a standard for how APIs should be designed across an organization or group. Another way to help developers follow best practices when it comes to API design is to provide them with a working example they can follow when developing their API(s). In my experience people learn API design best practices through following what they know–emulating what they see.</p>

<p>Hang on to that thought, cause now I’m going to blow your mind. Guess how API providers learn how to provide API design guide and working examples? By showcasing working examples of companies, institutions, and government agencies publishing API design guides, working APIs, and portal prototypes. So that other API providers can learn by example! BOOM! Mind blown. :-) An example of this can be found over at the General Service Administration (GSA), <a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/">with their API standards guide, API prototype, and forkable API portal and documentation</a>–complete with the essential API building blocks.</p>

<p>The GSA’s simple approach to providing a working example of their <a href="https://github.com/GSA/prototype-city-pairs-api/blob/master/standards.md">API standards</a> is refreshing. They have taken an existing GSA data set and launched a prototype API, then they published the API in a complete, working <a href="https://github.com/GSA/api-documentation-template">API developer portal</a> with all the essential building blocks of a basic API presence.</p>

<ul>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/getting_started.html">Getting Started</a> - What you need to get started with the API.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/console/">Documentation</a> - OpenAPI driven interactive API documentation.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/fields.html">Schema</a> - A reference of the fields / schema used for API responses.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/FAQ.html">FAQ</a> - Some basic questions about the API, and more importantly the API prototype.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/contact_us.html">Contact Info</a> - Using Github issues for support, with an accompanying email.</li>
</ul>

<p><a href="https://github.com/GSA/prototype-city-pairs-api-documentation">The whole things runs on Github so it is forkable</a>. What is great, is that they also have <a href="https://github.com/GSA/prototype-city-pairs-api">the source code for the API on Github</a>, essentially providing a working, forkable representation of what is expected in the GSA API design guide. This is how you plant seeds for consistent API design across an organization. An API design guide setting standard, with a working example of what you would like to see as the finished product.</p>

<p>I’m really getting into this approach to defining the API conversation within an organization. <a href="http://drone.prototype.apievangelist.com/">I’m working with a handful of large organizations right now to develop API prototypes</a>, evolve <a href="http://portal.minimum.apievangelist.com/">my current API portal definition</a>, as well as working to influence the GSA’s approach. If you aren’t familiar with the <a href="https://www.gsa.gov">General Services Administration (GSA)</a>, a significant portion of their mission is dedicated to delivering technology services to the over 430 departments, agencies, and sub-agencies in the federal government. The GSA API design guide, prototype, and portal provide a working example other agencies can follow when defining, designing, deploying, and managing their API presence–important stuff.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/the-yes-i-would-like-to-talk-button-signing-up-for-api-platform/">The Yes I Would Like To Talk Button When Signing Up For An API Platform</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><a href="https://www.reprezen.com/"><img src="https://s3.amazonaws.com/kinlane-productions/reprezen/the-yes-id-like-to-talk-button.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>There are never enough hours in the day. I have an ever growing queue of APIs and API related services that I need to play with for the first time, or just make sure and take another look at. I was FINALLY making time to take another look at the <a href="https://www.reprezen.com/">RepreZen API Studio</a> again when I saw that they were now supporting OpenAPI 3.0.</p>

<p>I am still driving it around the block, but I thought the second email I got from them when I was signing up was worth writing about. I had received a pretty standard getting started email from them, but then I got a second email from Miles Daffin, their product manager, reminding me that I can reach out, and providing me with a “Yes I Would Like To Talk Button”. I know, another pretty obvious thing, but you’d be surprised how a little thing like this can actually break us from our regular isolated workspace, and make the people behind an API, or API related service more accessible. The email was pretty concise and simple, but what caught my eye when I scanned was the button.</p>

<p>Anyways, just a small potential building block for your API communication strategy. I’ll be adding the list I am cultivating. I’m not a big hard sell kind of guy, and I appreciate soft outreach like this–leaving it up to me when I want to connect. I’ll keep playing with RepreZen API Studio and report back when I have anything worth sharing. I just wanted to make sure this type of signup email was included in my API communication research.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/the-yes-i-would-like-to-talk-button-signing-up-for-api-platform/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/the-successes-and-mostly-failures-of-a-developer-evangelist/">The Successes And (Mostly) Failures Of A Developer Evangelist</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><a href="https://www.getrevue.co/profile/ashleyintexas"><img src="https://s3.amazonaws.com/kinlane-productions/stitch-data/the-evangelism-compendium.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I am a big fan of companies who share their API journey publicly. The comment I hear from readers, as well as attendees of @APIStrat often, is that they want to hear more honest stories from API practitioners regarding every stop along the API lifecycle from defining to deprecation. I encourage API providers to actively share their stories publicly on their blog, and even semi-privately via email newsletters.</p>

<p>Ash Hathaway (<a href="https://twitter.com/ash_hathaway">@ash_hathaway</a>) over at <a href="https://www.stitchdata.com/">Stich Data</a> asked me what I thought about her doing an evangelism email newsletter based on her experiences–to which I responded with, “hell yeah, it is a great idea!”. So she has launched <a href="https://www.getrevue.co/profile/ashleyintexas">The Evangelism Compendium, the successes and (mostly) failures of a developer evangelist email newsletter</a>. She will be sharing her regular thoughts from the trenches, as she is evangelizing for <a href="https://www.stitchdata.com/">the data integration platform</a>.</p>

<p>Sharing stories from the API trenches like this is a great way to generate content for your operations, while also working through your thoughts on what is working (or not), when it comes to evangelism and outreach for your platform. I think the email newsletter has two audiences 1) data stewards looking to learn more about managing your data in today’s online cloud environment, and 2) other data and API service providers who are looking to learn, and hopefully share thoughts on evangelizing your platform. Many folks think I’m crazy for encouraging this type of real-time transparency into your operations, something that can make some feel vulnerability and exposed, but I find it to the best way to generate honest and compelling content.</p>

<p>API Evangelist is the result of me doing this for the last seven years. Sharing my thoughts as I do my work. I find it is a helpful part of my regular workflow to tell stories in this way, as it helps me refine and articulate my approach. It also generates valuable SEO and SMM exhaust for my platform, while also hopefully helping educate others along the way–even stimulating conversation. I encourage all API providers, and service providers to <a href="https://www.getrevue.co/profile/ashleyintexas">tune into what Ash is doing over at Stitch Data</a>, and make sure you are telling your story via your blog and/or email newsletter–no matter which stops along the API lifecycle you are looking share with the community.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/the-successes-and-mostly-failures-of-a-developer-evangelist/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/proprietary-views-of-your-taxonomy/">Proprietary Views Of Your Taxonomy</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-taxonomy.png" align="right" width="25%" style="padding: 15px" /></p>
<p>I’ve been investing a lot more energy into open data and APIs involved with city government, something I’ve dabbled in as long as I’ve been doing API Evangelist, but is something I’ve ratcheted up pretty significantly over the last couple of years. As part of this work, I’ve increasingly come across some pretty proprietary stances when it comes to data that is part of city operations–<a href="http://apievangelist.com/2011/09/06/every-city-county-and-state-should-have-an-api/">this stuff has been seen as gold, long before Silicon Valley came along, with long lines of folks looking to lock it up and control it</a>.</p>

<p><a href="http://apievangelist.com/2017/04/24/separating-the-licensing-layers-of-your-valuable-data-using-apis/">Helping civic data stakeholders separate the licensing layers around their open data and APIs is something I do as the API Evangelist</a>. Another layer I will be adding to this discussion is around taxonomy. How city data folks are categorizing, organizing, and classifying the valuable data needed to make our cities work. I’ve been coming across more vendors in the city open data world who feel their taxonomy is their secret sauce and falls under intellectual property protection. I don’t have any wisdom regarding why this is a bad idea, but I will keep writing about as part of my wider <a href="http://licensing.apievangelist.com/">API licensing</a> work to help flesh out my ideas, and create a more coherent and precise argument.</p>

<p>I understand that some companies put a lot of work into taxonomies, and the description behind how they organize things, but like API definitions and schema, these are aspects of your open data and API operations you want to be a widely understood, shared, and reusable knowledge within your systems, as well as the 3rd party integration of your partners and customers. Making your taxonomy proprietary isn’t going to help your brand, or get you ahead in the game. I recommend focusing on other aspects of the value you bring to the table and keep your taxonomy as openly licensed as you possibly can, encouraging adoption by others. I’ll work on a more robust argument as I work through a variety of projects that will potentially be hurt by the proprietary views on taxonomy I’m seeing.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/proprietary-views-of-your-taxonomy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/13/weekly-roundups-vs-short-stories/">Weekly Roundups vs Short Stories</a></h3>
        <span class="post-date">13 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-versus.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>I process a lot of stories each week, which I do not think is at all unique. While I tend to read short, medium, and longer form pieces, I notice that people tend to tune into my shorter, more concise pieces. I’m an aggregator, analyst, so people probably are looking to me to understand what is going on and in turn I’m looking for individual API providers and service providers to help me keep in tune with what is going on with their operations–I depend on blog posts, change logs, and other common building blocks to do my work.</p>

<p>One recommendation I have for API providers and service providers when it comes to their communication strategies is to provide short concise blog posts regarding specific goings on. Make your blog posts like your API resources–doing one thing and doing it well. You can still do a round-up at the end of the week providing an executive summary, but don’t cut out the short individual blog posts. In my experience, people tend to read titles, tweets, and don’t have much attention span beyond 300 to 500 words. Personally, if I am busy, the first thing I cut out each week is the lengthy weekly roundups from providers–I will scan, but really do not read much of the detail if something catches my eyes.</p>

<p>This advice isn’t for other aggregators and analysts. Your job is to round up and provide and overview of what is going on. My advice is for individual API providers looking to update everyone with what is going on with their API operations, services, tooling, customers, and other common things you should be evangelizing and communicating as part of your regular operations. This is just some feedback from someone who is passionate about consuming as much information as I possibly can each week. Many short stories are better than just a single round-up, and you tend to get better search and social media bang for your buck when you have well-crafted titles, and a short body, that focuses on a single topic. Think of your API communication strategy similar to your microservices approach and I think you’ll get the reach you are looking for.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/13/weekly-roundups-vs-short-stories/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/13/setting-the-rules-for-api-automation/">Setting The Rules For API Automation</a></h3>
        <span class="post-date">13 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/twitter/twitter-automation-rules.png" align="right" width="40%" style="pading: 15px;" /></p>
<p>Twitter released some automation rules this spring, laying the ground rules when it comes to building bots using the Twitter API. Some of the rules overlap with their existing terms of service, but it provides an interesting evolution in how platform providers need to be providing some direction for API consumers in a bot-driven conversational landscape.</p>

<p>They begin by laying the ground rules for automation using the Twitter API:</p>

<p>Do!</p>

<ul>
  <li>Build solutions that automatically broadcast helpful information in Tweets</li>
  <li>Run creative campaigns that auto-reply to users who engage with your content</li>
  <li>Build solutions that automatically respond to users in Direct Messages</li>
  <li>Try new things that help people (and comply with our rules)</li>
  <li>Make sure your application provides a good user experience and performs well — and confirm that remains the case over time</li>
</ul>

<p>Don’t!</p>

<ul>
  <li>Violate these or other policies. Be extra mindful of our rules about abuse and user privacy!</li>
  <li>Abuse the Twitter API or attempt to circumvent rate limits</li>
  <li>Spam or bother users, or otherwise send them unsolicited messages</li>
</ul>

<p>Twitter is just evolving their operation by providing an automation update to the <a href="https://support.twitter.com/articles/18311">Twitter rules</a> and the <a href="https://dev.twitter.com/overview/terms/agreement-and-policy">developer agreement and policy</a>, outlining what is expected of automated activity when it comes to engaging with users account, when bots are tweeting, direct messages, and other actions you take when it comes to Tweets or Twitter accounts. Providing an interesting look at the shift in API platform terms of service as the definition of what is an application continues to evolve.</p>

<p>While there were may automated aspects to the classic interpretation of web or mobile applications, bots are definitely bringing an entirely new meaning to what automation can bring to a platform. I think any API driven platform that is opening up their resources to automation is going to have to run down their list of available resources and think deeply about the positive and negative consequences of automation in the current landscape. Whether it is bots, voice, iPaaS, CI, CD, or any other type of API driven automation, the business, and politics of API operations are shifting rapidly, and the threats, risks, and stakes are only going to get higher.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/13/setting-the-rules-for-api-automation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  

	<table width="100%" border="1" style="background-color:#FFF; border: 0px #FFF;">
		<tr style="background-color:#FFF; border: 0px #FFF;">
			<td align="left">
				<a href="/blog/page14" class="button"><< Prev</a></li>
			</td>
			<td></td>
			<td align="right">
				<a href="/blog/page16" class="button">Next >></a>
			</td>
		</tr>
	</table>

  </div>
</section>

              
<footer>
  <hr>
  <div class="features">
    
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://www.getpostman.com/" target="_blank"><img src="https://apievangelist.com/images/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://apievangelist.com/images/tyk-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
  </div>
  <hr>
  <p align="center">
    relevant work:
    <a href="http://apievangelist.com">apievangelist.com</a> |
    <a href="http://adopta.agency">adopta.agency</a>
  </p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Homepage</a></li>
    <li><a href="http://101.apievangelist.com/">101</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="http://history.apievangelist.com/">History of APIs</a></li>
    <li><a href="/#api-lifecycle">API Lifecycle</a></li>
    <li><a href="/search/">Search</a></li>
    <li><a href="/newsletters/">Newsletters</a></li>
    <li><a href="/images/">Images</a></li>
    <li><a href="/archive/">Archive</a></li>
  </ul>
</nav>

              <section>
  <div class="mini-posts">
    <header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
    
    
      
        <article style="display: inline;">
          <a href="https://www.getpostman.com/" class="image"><img src="https://apievangelist.com/images/postman-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
      
        <article style="display: inline;">
          <a href="https://tyk.io/" class="image"><img src="https://apievangelist.com/images/tyk-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
  </div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
