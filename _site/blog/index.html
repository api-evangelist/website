<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
  <a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
  <ul class="icons">
    <li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
    <li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
    <li><a href="https://www.linkedin.com/organization/1500316/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
    <li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
  </ul>
</header>

    	        <section>
	<div class="content">

	<h3>The API Evangelist Blog</h3>
	<p>This blog is dedicated to understanding the world of APIs, exploring a wide range of topics from design to deprecation, and spanning the technology, business, and politics of APIs. <a href="https://github.com/kinlane/api-evangelist" target="_blank">All of this runs on Github, so if you see a mistake, you can either fix by submitting a pull request, or let us know by submitting a Github issue for the repository</a>.</p>
	<center><hr style="width: 75%;" /></center>
	
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/31/the-challenges-of-api-discovery-conversations-being-purely-technical/">The Challenges Of API Discovery Conversations Being Purely Technical</a></h3>
        <span class="post-date">31 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/containership-containership-blue-circuit-5.jpg" width="45%" align="right" style="padding: 15px;" />
Ironically one of the biggest challenges facing API discovery on the web, as well as within the enterprise, is that most conversations focus purely on the technical, rather than the human and often business implications of finding and putting APIs to work. The biggest movement in the realm of API discovery in the last couple years has been part of the service mesh evolution of API infrastructure, and how your gateways “discover” and understand the health of APIs or microservices that provide vital services to applications and other systems. Don’t get me wrong, this is super critical, but it is more about satisfying a technical need, which is also being fueled by an investment wave-—it won’t contribute to much to the overall API discovery and search conversation because of it’s limited view of the landscape.</p>

<p>Runtime API discovery is critical, but there are so many other times we need API discovery to effectively operate the enterprise. Striving for technical precision at runtime is a great goal, but enabling all your groups, both technical and business to effectively find, understand, engage, and evolve with existing APIs should also be a priority. It can be exciting to focus on the latest technological trends, but doing the mundane profiling, documentation, and indexing of existing API infrastructure can have a much larger business impact. Defining the technical details of your API Infrastructure using OpenAPI, Postman, and other machine readable formats is just the beginning, ideally you are also working define the business side of things along the way.</p>

<p>I find that defining APIs using OpenAPI and JSON Schema to be grueling work. However, I find documenting the teams and owners behind APIs, the licensing, dependencies (both technical and business), pricing, and other business aspects of an API to be even more difficult. Over the last decade we’ve gotten to work standardizing how define the technical surface area of our APIs, but we’ve done very little work to standardize how we license, price, own, collaborate, and track on the other business implications of delivering APIs. This is one reason Steve Willmott and I created <a href="http://apisjson.org/">the APIs.json format</a>, to help drive this discussion. Providing a machine readable API format to transcend the technical details of APIs, and allow us to better define the operational side of making sure APIs are discoverable.</p>

<p>APIs.json is about defining everything about your APIs that JSON Schema, OpenAPI, and AsyncAPI will not. Where your documentation is, how to find SDKs, what the terms and conditions are, or maybe the licensing behind your API. We designed the API specification to be flexible, and something that can be extended. There are a handful of default property types you can use when applying the format, but ultimately it is about pushing you to define your own using x- extensions. Helping API providers think through what the common building blocks of their API operations are, and provide them with a simple JSON or YAML format for indexing all of these elements for use in your API catalog, or publishing to the root of your developer portal. Helping augment what OpenAPI, JSON Schema, and AsyncAPI have done, but providing a single place for you to hang all of your API artifacts.</p>

<p>I’m working hard to continue refining my catalog of 3K+ APIs.json files. I’m working on better ways to validate or invalidate what I have indexed, and provide a single search interface for them. Once I’ve refreshed the catalog, and synced them with the evolution of the available APIs over at <a href="http://apis.io">APIs.io</a>, I will publish a fresh list of the companies I’m tracking on. I feel like one of the most critical business aspects of API discovery we consistently overlook, ignore, or are in denial of, is whether an API is still active, and anyone is home. This is a rampant illness in the cataloging of public APIs, but also something that you can find all over the enterprise. We need to do a better job of understand where are APIs are, but also be more honest about which APIs are used, do not have an owner, or are straight 404’ing and shouldn’t be listed in any active API catalog.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/31/the-challenges-of-api-discovery-conversations-being-purely-technical/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/31/differences-between-api-observability-over-monitoring-testing-reliability-and-performance/">Differences Between API Observability Over Monitoring, Testing, Reliability, and Performance</a></h3>
        <span class="post-date">31 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/35201856153_61bc075e4b-udnie.jpg" width="45%" align="right" style="padding: 15px;" />
I’ve been watching the API observability coming out of Stripe, as well as Honeycomb for a couple years now. Then observability of systems is not a new concept, but it is one that progressive API providers have embraced to help articulate the overall health and reliability of their systems. In control theory, observability is a measure of how well internal states of a system can be inferred from knowledge of its external outputs. Everyone (except me) focuses only on the modern approaches for monitoring, testing, performance, status, and other common API infrastructure building blocks to define observability. I insist on adding the layers of transparency and communication, which I feel are the critical aspects of observability—-I mean if you aren’t transparent and communicative about your monitoring, testing, performance, and status, does it really matter?</p>

<p>I work to define observability as a handful of key API building blocks that every API provider should be investing in:</p>

<ul>
  <li><strong>Monitoring</strong> - Actively monitoring ALL of your APIs to ensure they are up and running.</li>
  <li><strong>Testing</strong> - Performing tests to ensure APIs aren’t just up but also doing what they are intended to.</li>
  <li><strong>Performance</strong> - Adding an understanding of how well your APIs are delivering to ensure they perform as expected.</li>
  <li><strong>Security</strong> - Actively locking down, scanning, and ensuring all your API infrastructure is secure.</li>
</ul>

<p>Many folks rely on the outputs from these areas to define observability, but there are a couple more ingredients needed to make it observable:</p>

<ul>
  <li><strong>Transparency</strong> - Sharing the practices and results from each of these areas is critical.</li>
  <li><strong>Communication</strong> - If you aren’t talking about these things regularly they do not exist.</li>
  <li><strong>Status</strong> - Providing real time status updates for al these areas is essential.</li>
</ul>

<p>You can be actively observing the outputs from monitoring, testing, performance, and security operations, but if this data isn’t accessible to other people on your team, within or company, partners, and for the public as required, then things aren’t observable. Of course, I’m not talking about making ALL API activity public, but I’m saying, if you are a public API, and you aren’t providing transparency, communication, and status of your monitoring, testing, performance, and security—-then you aren’t observable.</p>

<p>I know many folks will disagree with me on this part, but that is ok. I am used to it. So far, I haven’t seen much embrace of the observability concept, with many providers either not understanding it, or not grasping the meaningful impact it will have on their operations. So I’m not holding my breath that folks will buy into my portion of it. However it is my self appointed role to make sure the bar is high, even if nobody adopts the same set of rules. In the end, API observability isn’t some new trendy buzzword, it is one of a handful of meaningful constructs that exist to help make us all better, but most likely will get lost in the shuffle of doing APIs each day. :-(</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/31/differences-between-api-observability-over-monitoring-testing-reliability-and-performance/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/30/peer-api-design-review-sessions/">Peer API Design Review Sessions</a></h3>
        <span class="post-date">30 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/abe-lincoln-one-smooth-ride-file-00-00-07-91.jpg" width="45%" align="right" style="padding: 15px;" />
Public APIs have always benefitted from something that internal APIs do not always received—-feedback from other people. While the whole public API thing didn’t play out as I originally imagined, there is still a lot of benefit in letting other see, and provide open feedback on your API. It is painful for many developers to receive feedback on their API, and it is something that can be even more painful when it is done publicly. This is why so many of us shy away from establishing feedback loops around our APIs. It is hard work to properly design, develop, and then articulate our API vision to an external audience. It is something I understand well, but still suffer from when it comes to properly accessioning peer review and feedback on my API designs.</p>

<p>I prefer opening up to peer reviews of my API designs while they are still just mocks. I’m less invested in them at this point, and it is easier to receive feedback on them. It is way less painful to engage in an ongoing discussion fo what an API should (and shouldn’t) do early on, then it is to define the vision, deliver an API as code or within a gateway, and then have people comment on your baby that you have given birth to. It hurts to have people question your vision, and what you’ve put forth. Especially for us fragile white men who who aren’t often very good at accepting critical feedback, and want to just be left to our own devices. I’d much prefer just being a coder, but around 2008 through 2010 I saw the benefits to my own personal development when I opened up my work to my peers and let a little sunlight in. I am a better developer because of it.</p>

<p>One tool in my API toolbox that is growing in importance is the peer, and open API design review sessions. Taking an OpenAPI draft, loading it into Swagger Editor, firing up a Zoom or Google Hangout, and inviting others to openly share in the design of an API. I find it isn’t something everyone is equipped to do, but many are open to learning, or at least curious about how it works. Curious is good. It is a start. I think many folks aren’t fluent in the API design process, and are often afraid to appear like they don’t know what they are doing, and having an open discussion throughout the API design process helps them learn out in the open. Using a process that helps everyone involved learn together, and lower their guard a little bit when it comes to new ideas, new ways of doing things, and discussing the overall developer experience (DX) of delivering a quality API.</p>

<p>Peer API Design reviews is something I’d love to see more API design tooling support. If nothing else, more people just doing it with existing tools. You may not have fully embraced a complete API design first approach within your enterprise group, but openly discussing API design patterns is important. It is critical for any API developer to receive feedback on their design from other stakeholders, and other API development peers. It is important that we allow ourselves to open up to this feedback and sometimes criticism of our designs, based upon what others know, sharing potential views on how an API can reduce friction for consumers. Ideally, this process is also made accessible to non-developer stakeholders, and even business owners, but I’m thinking this is another post all by itself—-for right now, I just want to advocate for more peer API design review sessions.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/30/peer-api-design-review-sessions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/30/api-for-processing-common-logging-formats-and-generating-openapi-definitions/">API For Processing Common Logging Formats And Generating OpenAPI Definitions</a></h3>
        <span class="post-date">30 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/abandonedbuildings_blue_circuit.jpg" width="45%" align="right" style="padding: 15px;" />
I’ve invested a lot of time in the last six months into various research, scripts, and tooling to help me with finding APIs within the enterprise. This work is not part my current role, but as a side project to help me get into the mindset of how to help the enterprise understand where their APIs are, and what APIs they are using. Almost every enterprise group I have consulted for has trouble keeping tabs on what APIs are being consumed across the enterprise, and I’m keen on helping understand what the best ways are to help them get their API houses in order.</p>

<p>While there are many ways to trace out how APIs are being consumed across the enterprise, I want to start with some of the basics, or the low hanging when it came to API logging within the enterprise. I’m sure there are a lot of common logging locations to tackle, but my list began with some of the common cloud platforms in use for logging of operations to begin my work—focusing on the following three cloud logging solutions:</p>

<ul>
  <li><strong>Amazon CloudFront</strong> - Beginning with the cloud leader, and looking at how the enterprise is centralizing their logs with CloudFront.</li>
  <li><strong>Google StackDriver</strong> - Next, I found Google’s multi-platform approach interesting and worth evaluating as part of this work.</li>
  <li><strong>Azure Logging</strong> - Of course, I have to include Azure in all of this as they are a fast growing competitor to Amazon in this space.</li>
</ul>

<p>After establishing a short list of cloud platforms logging solutions, I began looking at which of the common web server formats I should be looking for within these aggregate logging locations, trying to map out how the enterprise is logging web traffic. Providing me with a short list of the three most common web server formats I should be looking at when it comes to mapping the enterprise API landscape—-providing artifacts of the APIs that enterprise groups are operating.</p>

<ul>
  <li><strong>Apache Log File</strong> - The most ubiquitous open source web server out there is the default for many API providers.</li>
  <li><strong>NGINX Log File</strong> - The next most ubiquitous open source web server is definitely something I should be looking for.</li>
  <li><strong>IIS Log File</strong> - Then of course, many Microsoft web server folks are still using IIS to serve up their API infrastructure.</li>
</ul>

<p>These three web server logging formats represent a significant slice of the API logging pie. If I can identify these logging formats across common cloud logging locations, I feel that I can provide a pretty significant solution for finding the APIs that are in use across the enterprise. However, I didn’t just want to be looking a the web server logging for understanding what APIs are being served up, I also wanted to look at the exhaust from how APIs are being consume by looking at these two web browser and proxy traffic formats:</p>

<ul>
  <li><strong>HAR File</strong> - Allowing for the discovery of APIs that are used in web and browser applications across common use cases.</li>
  <li><strong>Charles Proxy JSON Session</strong> - Using a common proxy application to reverse engineer web and mobile application API calls.</li>
</ul>

<p>These cloud logging solutions, web server formats, as well as browser and proxy solutions give me a pretty interesting look at the API discovery pie. I have scripts to help identify these common formats, and then automatically produce OpenAPI definitions from them. It is pretty easy to run these scripts in a variety of ways to help automatically produce a catalog of OpenAPI definitions from them, automating the mapping of the API landscape within he enterprise. I have all of these scripts working for me in a variety of capacities, the next step is to further automate them, organize them into more of a usable suite of API tooling, then unleash them on a larger set of enterprise logs.</p>

<p>All of my scripts currently run as APIs, as I’m API-first, but I’m currently exploring ways in which I can better execute them at the command line, and as autonomous solutions that can be installed within the enterprise, without any external connections or dependencies. I have a list of ways in which I want to add more value on top of these API discovery solutions, allowing me to generate revenue from them. However right now, I am more interested in ensuring they help automate the API landscape across the majority of enterprise logging solutions. Once I dial this in, I will be looking for more ways to implement the existing functionality, as well as evolve to cover other platforms and formats. I’m just looking to deliver a basic solution for understanding where the hell all the APIs are in the enterprise, before I look to bake in more advanced features.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/30/api-for-processing-common-logging-formats-and-generating-openapi-definitions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/28/api-storytelling-within-the-enterprise/">API Storytelling Within The Enterprise</a></h3>
        <span class="post-date">28 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/long-factory-uncle-sam.jpg" width="45%" align="right" style="padding: 15px;" />
Storytelling is important. Storytelling within the enterprise is hard. Reaching folks on the open web is hard work to, but there is usually an audience that will eventually tune in, and over time you can develop and cultivate that audience. The tools you have at your disposal within the enterprise are much more prescribed and often times dictated–even controlled. I also find that they aren’t always as effective as they are made out to be, with the perception being one thing, and the reach, engagement, and noise being then much harder realities you face when trying to get a message out.</p>

<p>Email might seem like a good idea, and is definitely a critical tool when reaching specific individuals or groups, but as a general company wide thing, it quickly becomes exponentially ineffective with each person you add on as CC. I’d say that you are better off creating a daily or weekly email newsletter if you are going to be sending across large groups of the enterprise rather than participating in the constant email barrage that occurs on a daily basis. Email is an effective tool when used properly, but I’d say I haven’t perfected the art of using email to reach my intended audience within the enterprise.</p>

<p>My preferred storytelling format is relatively muted within the enterprise — people rarely read blogs in this world. Blog reading is something you do out on the web apparently. This means I have to get pretty creative when it comes to getting your stories out. It doesn’t mean you shouldn’t be using this format of storytelling, but you just can’t count on folks to regularly consume a blog, or subscribe to an RSS feed. You can still have a blog, but you have to find other ways of slipping the links into existing conversations, documentation, and other avenues in which people consume information within the enterprise.</p>

<p>I would say this reality of reading within the enterprise is why I try to write more white papers and guides. I know that many folks across the enterprise prefer to consume their reading materials as a PDF on their laptop, desktop, or tablet. While this is definitely not my preferred way of consuming information, I have to remember that it is the primary way in which enterprise folks can cut through the noise, and find some quiet time to digest 6-8 pages of API blah blah blah during their busy day. While I will keep pumping out short form content on the blog, I will also be investing much more into creating longer form white papers and guides that have a greater opportunity of penetrating the enterprise.</p>

<p>I know that enterprise folks are caught up in the daily shit-storm and can’t always get to my blog, or spend too much time on Twitter. Making content more portable, and something they can email around, download and potentially consume later is important. As I work within the enterprise more I am realizing how critical this is for folks, including myself. I found myself firing back up my Pocket app on my iPad, so that I can queue things up for later. Reminding how difficult it is to tell stories within the enterprise and that I cannot discount tools like the PDF when it comes to reaching my intended audience. You really have to understand your audience, and work to meet them at their level, regardless of the tools you use to get information and be influenced by the deluge of storytelling we are inundated with on a daily basis.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/28/api-storytelling-within-the-enterprise/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/24/apis-and-browser-bookmarklets/">APIs and Browser Bookmarklets</a></h3>
        <span class="post-date">24 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/gears-4882162452-fa3126b38d-b-blue-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
I have quite a few API driven bookmarklets I use to profile APIs. I recently quit using Google Chrome, so I needed to migrate all of them to Firefox. I saw this work as an opportunity to better define and organize them, as they had accumulated over the years without any sort of strategy. When I need some new functionality in my browser I would create a new API, and craft a bookmarklet that would accomplish whatever I needed. I wish I had more browser add-on development skills, something I regular try to invest in, but I find that bookmarklets are the next best thing when it comes to browser and API interactions.</p>

<p>There are a number of tasks I am looking to accomplish when I’m browsing the web pages of an API provider. The first thing I want to do is record their domain, then retrieve as much intelligence about the company behind the domain in a single click of the bookmarklet. This was the first bookmarklet and API I developed. Since then, I’ve made numerous others to record the pricing page, parse the terms of service, OpenAPI, and other valuable API artifacts from across the landscape. Bookmarklets are a great way to provide just a little more context combined with a URL pointer, for harvesting, processing, and possibly some human review. Allowing me to augment, enrich, and automate how I consume information as I’m roaming around the web, researching specific topics, and do what I do.</p>

<p>At this point I am actually glad I didn’t invest a lot of energy into developing Chrome browser extension, because it wouldn’t have easily translated to a Firefox world. Since I have been investing in APIs plus bookmarklets, I can easily import, or copy and paste my bookmarklets over. I”m spending the time to go through them, inventory them, and better organize them for optimal usage, so the migration is a little more work than just import and export. Another aspect of this work that I am thankful for is that I abstracted away is the usage of other 3rd party APIs. My very first bookmarklet which profiles the domain of the website I’m looking at has used several different business intelligence solutions, all of which I have been priced out of using, so I’ve resorted to other ways to obtain the profile information I need–the API continues to work despite the APIs I use under the hood.</p>

<p>Browsers are an area of my API research that is significantly deficient. I am working to invest a little more time here, focusing on the migration and evolution of my API driven bookmarklets, but also playing around with the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Reporting_API">Browser Reporting API</a>, which is some pretty interesting HEADER voodoo. I can’t help but feel like the browsers will continue to play an increasingly important role when it comes to APIs. Not just because of browser APIs like the Reporting API, but also because of the hidden APIs web and mobile applications use, as well as the above the tables APIs we leverage within the browser—-like my bookmarklets. I find the browser a more interesting place to study how APIs are being put to work than with startups these days. I feel like it is where the “innovation” is occurring these days, and sadly, it isn’t the good kind of “innovation” everyone so passionately believes in—-it is the more exploitative ad-driven “innovation” that is pretty invasive in our lives.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/24/apis-and-browser-bookmarklets/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/24/absolutism-around-api-tools-increases-friction-and-failure/">Absolutism Around API Tools Increases Friction And Failure</a></h3>
        <span class="post-date">24 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/legal-statue-legalstatue-smoking-cigarette.jpg" width="45%" align="right" style="padding: 15px;" />
I know you believe your tools are the best. I mean, from your vantage point, they are. I also know that when you are building a new API tool, your investors want you to position your tooling as the best. The one solution to rule them all. They want you to work hard to make your tools the best, but also make sure and demonize other tooling as being inferior, out of date, and something the dinosaurs use. I know this absolute belief in your tooling feels good and right, but you are actually creating friction for your users, and potentially failure or at least conflict within their teams. Absolutism, along with divide and conquer strategies for evangelizing API tooling works for great short term financial strategies, but doesn’t do much to help us on the ground actually developing, managing, and sustaining APIs.</p>

<p>Ironically, there are many divers factors that contribute to why API tooling providers and their followers resort to absolutism when it comes to marketing and evangelizing their tools. Much of which has very little to do with the merits of the tools being discussed, and everything about those who are making the tools. I wanted to explore a few of them so they are available on the tip of my tongue while working within the enterprise.</p>

<ul>
  <li><strong>No Due Diligence On What Is Out There</strong> - Most startups who are developing API tooling do not spend the time understanding what already exists across the landscape, and get outside of the echo chamber to learn what real world companies are using to get the job done each day.</li>
  <li><strong>No Learning Around Using Existing Tools</strong> - Even if startups are aware of existing tools, patterns, and processes, they rarely invest the time to actually understand what existing tools deliver—spending time to deeply understand how existing tools are being put to use by their would-be customers.</li>
  <li><strong>Lack Of Awareness Around The Problem</strong> - There is a reason investors prefer young engineers when it comes to developing the next set of disruptive tooling, because they rarely understand the scope of problems being solved, and provide great fuel for short to mid-term growth strategies.</li>
  <li><strong>Aggressive Male Dominated Environment</strong> - Young white men are perfect for this approach to delivering tooling that isn’t about the tool, but about a larger economic strategy, putting us passionate, privileged souls at the helm, and push them to do the disruptive bidding with very little awareness of the big picture.</li>
  <li><strong>No Empathy For Others You Encounter</strong> - API tooling that takes an absolutist approach is rarely about empowering others, or understanding and providing solutions to their problems—lacking in empathy for other tooling providers, tooling consumers, or the companies left with each round of tech debt.</li>
  <li><strong>Lack Of Diverse Experience In Industry</strong> - Entrepreneurs who ride each wave of API tooling absolutism and state their API tool is the one solution often lack experience in a variety of industries, and rarely have diverse experience outside of the - Silicon Valley echo chamber, and across multiple industries or geographic regions.</li>
  <li><strong>VC Backed With Aggressive Growth</strong> - The aggressive absolutist approach of each wave of API tooling is almost always fueled by aggressive funding cycles, and have very little to do with the actual application of API tooling—operating the puppet strings which most API tooling providers and consumers on the front line do not see.</li>
</ul>

<p>If you are in the business of tearing down someone else to deliver your tool, your tool will die by the same approach–someday. There is always a better funded, more aggressive solution to emerge on the market. Even if your tool has managed to achieve some level of market success, there will be a time when you let your guard down, and someone comes along to begin taking jabs at you. With each cycle of absolutism assault, the merits of the tooling mean very little. Perception always trumps reality, and there are always armies of developers waiting by in the wings to adopt what is new, and begin raising a pitchfork to attack what was. There is no allegiance and loyalty in this game.</p>

<p>I know. I know. This is just business. I just don’t get the game. Smart people have to make money! Yes, there are also many of us who are responsible for keeping the lights on. That aren’t as disloyal as you are, willing to jump from job to job, startup to startup. There are many of us who have been doing this a lot longer than you, and are willing to be responsible for the tech debt we incur along the way, and we do not mind doing the hard work to clean up your messes. I know that API tool absolutism makes you feel knowledgable and in control now, but just wait until you’ve ridden a few waves, and you’ve had many of your valuable tooling taken away from you because of this game. Then you will begin to see the other side of this, and better understand the toll of this business approach. Eventually you will grow weary of it, but fortunate for you, there will always be a fresh crop of recruits to wage this battle, and there is no rest for the wicked. #liveByDisruption #DieByDisruption</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/24/absolutism-around-api-tools-increases-friction-and-failure/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/23/the-higher-level-business-poitics-that-i-am-not-good-at-seeing-in-the-api-space/">The Higher Level Business Politics That I Am Not Good At Seeing In The API Space</a></h3>
        <span class="post-date">23 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/los-angeles-from-observatory-losangeles-from-observatory-purp-paper.jpg" width="45%" align="right" style="padding: 15px;" />
I have built successful startups. I’m good at the technology of delivering new solutions. I am decent at understanding and delivering much of business side of bringing new technological solutions to market. What I’m not good at is the higher level business politics that occur. These are the invisible forces behind businesses that I’m good at seeing, playing in, and almost always catch me off guard, too late, or just simply piss me off that they are going on behind the scenes. Unfortunately it is in this realm where most of the money is to be made doing APIs, resulting in me being written out of numerous successful API efforts, because I’m not up to speed on what is going on.</p>

<p>Startups are great vehicles for higher level economic strategies. They are the playground of people with access to resources, and have economic visions that rarely jive with what is happening on the ground floors. Startup strategies count on a handful at the top understanding the vision, with most at the bottom levels not being able to see the vision, and small group of disposable stooges in the middle, ensuring that the top level vision is realized—at all costs. You can work full time at a startup, and even enjoy a higher level position, and still never see the political goings on that are actually motivating the investment in your startup. This is by design. The whole process depends on the lower levels working themselves to the bone, working on, marketing, and selling one vision, while there are actually many other things going on above, usually with a whole other set of numbers.</p>

<p>After 30 years of playing in this game I still stuck at seeing the higher level influences. I’ve seen shiny API tooling solution after shiny API tooling solution arrive on the market, and I still fall for the shine. Ooooohhh, look at that. It will solve X, or Y problem. I really like the vision of those team members. Their timing is perfect. They seem to have the right funding, and mindshare of developers. Then I begin to see some of the usual tell-tale signs of direction coming from up above. It will be subtle signals, like the change in pricing tiers, a quickness to support a standard on import, but very slow to support export. A shift in the marketing strategy. A public “pivot”. There are a diverse of signals you can tune into that will help predict where an API startup is headed, often times away from the original tooling vision, and the needs of the end-users.</p>

<p>With so much experience, you’d think I’d be better at this. I’m not good at it, because I hate playing these games. I like making money, but not in the way that follow the usual VC fueled playbook. To make money at scale you have to be willing to play by multiple playbooks, keeping one or more of them secret from your teams and end-users. This just isn’t me. I prefer being more transparent. I like building real businesses. I like developing real tools. This is what I’m good at. I’m not good at the higher level games required to build wealth for myself or others. It is this reality that leaves me so reluctant to share my knowledge with VCs, talk to and support new startups, and leaves me so cranky on a regular basis when I tell stories in the space. I know y’all think this is business as usual, and are looking to get your piece of the pie, but I operate at a different level, and refuse to go there.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/23/the-higher-level-business-poitics-that-i-am-not-good-at-seeing-in-the-api-space/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/23/api-provider-and-consumer-developer-portals/">API Provider And Consumer Developer Portals</a></h3>
        <span class="post-date">23 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/server-cloud-server-racks-clouds-copper-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
I’ve been studying API developer portals for almost a decade. I’ve visited the landing pages, portals, websites, and other incarnations from thousands of API providers. I have an intimate understanding of what is needed for API providers to attract, support, and empower API consumers. One area I’m deficient in, and I also think it reflects a wider deficiency in the API space, is regarding how to you make an API portal service both API providers and API consumers. Providing a single portal within the enterprise where everyone can come and understand how to deliver or consume an API.</p>

<p>There are plenty of examples out there now when it comes to publishing an API portal for your consumers, but only a few that show you how to publish an API. I’d say the most common example are API marketplaces that allow both API consumers and providers to coexist, but this model isn’t exactly what you want within the enterprise. One thing the model lacks is the on-boarding of new developers when it comes to actually developing an API. Suffering from many of the same same symptoms API management service providers have historically suffered from—-not providing true assistance when it comes to delivering a quality API.</p>

<p>When I envision an API portal that serves both providers and consumers, either publicly or privately, I envision just as much assistance when it comes to delivering a new API as we provide for new consumers of an API. Helping with API definition, design, deployment, management, testing, monitoring, documentation, and other critical stops along the API lifecycle. We need to see more examples of the split between API provider and consumers, equally helping both sides of the coin get up to speed, and be successful with what they are looking to achieve. I think we’ve spend almost 15 years investing in perfecting and monetizing the API portal with a focus not he consumer, and now we need to invest on helping make the portal easier for new API providers to step up and learn how to properly publish their API.</p>

<p>The modern API management solution is still tailored for the mystical API provider who knows how do to everything, where most do not understand the full API lifecycle. It would be an opportunity for an API management provider to go beyond just one or a handful of stops along the API lifecycle, and properly invest in on boarding new APIs. I think one reason why all of this suffers is that venture capitalists have never prioritized education and training for both API providers or consumers—-directing API service providers to only lightly invest when it comes to these API educational resources. Now that APIs have gone mainstream, we are going to need an industrial grade enterprise solution for delivering API portals that help onboard both API providers and consumers, and provide them both with what they need to navigate the entire lifecycle of the API solutions they are providing and applying.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/23/api-provider-and-consumer-developer-portals/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/22/the-role-having-awareness-of-your-api-traffic-plays-in-api-security/">The Role Having Awareness Of Your API Traffic Plays In API Security</a></h3>
        <span class="post-date">22 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/IMG_4038_blue_circuit.jpg" width="45%" align="right" style="padding: 15px;" />
One of the biggest reasons we adopt new technology, and justify the development of new technology, is we do not want to do the heavy lifting when it comes to what we already have in place. A common illness when it comes to API security that I’ve been battling since 2015 is that you will have API security addressed once you adopted an API management solution. Your APIs require API keys, and thus they are secure. No further work necessary. The unwillingness or lack of knowledge regarding what is needed next, leaves a vacuum for new technology providers to come in and sell you the solution for what is next, when you should be doing more work to use the tools you already have.</p>

<p>When it comes to API management, most vendors sold it as purely a security solution, and when companies implement it they become secure. Missing the entire point for why we do API management-—to develop an awareness of our API usage and consumption. Having keys for your APIs is not enough. You actually have to understand how those API consumers are putting API resources to work, otherwise your API security will always be deficient. Some of the fundamentals of API management you should be employing as part of your API security are:</p>

<ul>
  <li><strong>Registration</strong> - Make all developers sign of for API usage, establishing the terms of use.</li>
  <li><strong>API Keys</strong> - Require all developers internal or external to use API keys for every application.</li>
  <li><strong>API Usage</strong> - Which APIs are being used by all API consumers putting them to use in applications.</li>
  <li><strong>API Errors</strong> - Understanding what the errors being generated are, and who is responsible for them.</li>
  <li><strong>Logging</strong> - The logging of all API traffic, reconciling against what you know as reported usage.</li>
  <li><strong>Invoicing</strong> - Invoicing of all consumers for their usage, even if they aren’t paying you money.</li>
  <li><strong>Reporting</strong> - Provide reports on API usage for all stakeholders, to regularly develop awareness.</li>
</ul>

<p>These are the fundamentals of API management, however API keys and tokens seem to be the part that people feel is API security. Where API security is really all about actually developing a real-time awareness of who is using your API resources. Leaving your finger on the pulse so that when anything changes, or error rates are elevated, you already have a base level of awareness and can easily respond by shutting off keys, or limiting overall access to resources by offending applications.</p>

<p>There is much more that can be done in the name of API security. This is just a list of the elements of API management that contribute to API security, which are often neglected. Having API management does not equal API security. Properly applying API management contributes to API security, it is never API security by itself. If you aren’t doing API management properly, you are more likely to fall for the next generation of API security providers who are machine learning focused, promising to do the hard work of managing awareness for you, so you don’t have to. Your unwillingness to do the work in the first place, and properly understand the role that awareness of your traffic, makes you a ripe target for selling the next wave of API security solutionism. Good luck with that!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/22/the-role-having-awareness-of-your-api-traffic-plays-in-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/22/happy-path-api-testing-bias/">Happy Path API Testing Bias</a></h3>
        <span class="post-date">22 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-DSC-0084-dali-three.jpg" width="45%" align="right" style="padding: 15px;" />
I see a lot of happy path bias when it comes to the development of APIs, but specifically when it comes to crafting testing to ensure APIs are delivering as expected. Happy path is a term used in testing to describe the desired outputs a developer and product owner is looking for. Making the not so happy path being about testing for outcomes that a developer and product owner is not wanting to occur. When it comes to API development most developers and product owners are only interested in the happy path, and will almost always cut corners, minimize the investment in, or completely lack an imagination when it comes to less than happy path API testing.</p>

<p>There are many reasons why someone will have a bias towards the happy path when developing an API. Every API provider is invested in achieving the happy path for delivering, providing, and consuming an API. This is what generates revenue. However, in this quest for revenue, we often become our own worst enemy. Shining a spotlight on the happy path, while being completely oblivious to what the not so happy paths will look like for end users. Why do we do this?</p>

<ul>
  <li><strong>Greed</strong> - We are so interested in getting an API up and running, used in our applications, and generating behavioral surplus, we are more than willing to ignore all other possible scenarios if we can easily meet our revenue goals by ignoring the unhappy path and there are no consequences.</li>
  <li><strong>Tickets</strong> - Most development occurs using JIRA or other software development “tickets”, which tell developers what they are supposed to do to meet the requirements of their employment—tickets are written with the happy path in mind, and developers are rarely willing to do more.</li>
  <li><strong>Imagination</strong> - While many of us technologists think we are imaginative creatures, most of us are pretty stuck in a computational way of thinking, and elaborating, iterating, and exploring beyond the initial happy path design of our API just does not exist.</li>
  <li><strong>Use Software</strong> - Most of us developers do not actually use the platform we are developing, setting the stage for where we really don’t understand the problem being solve, further siloing us into seeing only the happy path that have been handed to us as part of initial product vision.</li>
  <li><strong>White Male</strong> - The majority of us API developers are white men, or developers who report to white men, leaving entire shadows regarding how our APIs will be used and abused—when you are privileged, the happy path is always easier to see and walk on.</li>
  <li><strong>Apathy</strong> - The majority of us are just doing our jobs, and we really do not have any excitement, passion, or interest in our jobs. We are just doing what we are told, and if our bosses do not specifically point out every single unhappy path, we don’t care.</li>
  <li><strong>Velocity</strong> - Things move fast at almost any company delivering APIs, and it is easy to not have time to be able to step back and sufficiently think about what the happy paths might be when we are delivering APIs that deliver some functionality amidst a fast pace environment.</li>
  <li><strong>Experience</strong> - Another reason for overlooking unhappy paths is we just do not have the experience to know about them. Startups and many technology focused companies like hiring young, low pay developers to get the job done, and they won’t always have the experience to see in the shadows.</li>
  <li><strong>By Design</strong> - The product owners do not want the less than happy or unhappy paths patched, as they are there by design, and support the overall business model, which is usually advertising. Encouraging abuse, and exploitation of APIs, or at least ensuring they are much lower priorities.</li>
</ul>

<p>There are few incentives to develop quality software these days. Revenue drives much of why we are delivering APIs, and incentivizing developers to think out of the box when it comes to API testing just doesn’t exist. Plus, it takes a lot of work to write first class tests alongside your code. Most developers are conditioned to see tests as secondary, and the thing you do only when you have the time. Making quality unhappy and less than happy path API testing always left on the cutting room floor, never making it into the final product.</p>

<p>You can see this bias playing out in the APIs behind Facebook, Twitter, and other advertising driven platforms. The abuse of APIs are often overlooked if it generates clicks, traffic, and increases the eyeballs. Secondarily I’d say that the consequences for when unhappy paths are identified for APIs is almost non-existent. There is no accountability for poorly designed APIs, or APIs that allow for uses beyond their intended purpose. In this environment, most API providers will never prioritize API testing, and incentivize developers to properly explore how an API can be misused, abused, or just not deliver the functionality promised. Ensuring that much of API usage exists on the unhappy path by design.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/22/happy-path-api-testing-bias/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/18/what-is-an-appication/">What Is An Application?</a></h3>
        <span class="post-date">18 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/lost-angeles-downtown-freeway-los-angeles-downtow-freeway-copper-circuit-2.jpg" width="45%" align="right" style="padding: 15px;" />
I have struggled asking this question in many discussions I’ve had around the world, at technology conferences, on consulting projects, and in the back rooms of dimly lit bars. What is an application? You get ten different answers if you ask this question to ten different people. I’d say the most common response is to reference the applications on a mobile device. These are the relevant. Most accessible. The most active and visible form of application in our modern life. Older programmers see them as desktop applications, where younger programmers see them as web applications, with varying grades of server applications in between. If you operate at the network layer, you’ve undoubtedly bastardized the term to mean several different things. Personally, I’ve always tried to avoid these obvious and tangible answers to this question, looking beyond the technology.</p>

<p>My view of what an application is stems from a decade of studying the least visible, and least tangible aspect of an application, its programming interface. When talking to people about applications, the first question I ask folks is usually, “do you know what an API is”? If someone is API savvy I will move to asking, “when it comes to application programming interface (API), who or what is being programmed? Is it the platform? The application? Or, is it the end-user of the applications?” I’ve spent a decade thinking about this question, playing it over and over in my end, never quite being satisfied with what I find. Honestly, the more I scratch, the more concerned I get, and the more I’m unsure of exactly what an “application” is, and precisely who are what is actually being programmed. Let’s further this line of thinking by looking at the definitions of “application”:</p>

<ul>
  <li>noun - The act of applying.</li>
  <li>noun - The act of putting something to a special use or purpose.</li>
  <li>noun - A specific use to which something is put.</li>
  <li>noun - The capacity of being usable; relevance.</li>
  <li>noun - Close attention; diligence.</li>
  <li>noun - A request, as for assistance, employment, or admission to a school.</li>
  <li>noun - The form or document on which such a request is made.</li>
  <li>noun - Computers A computer program designed for a specific task or use.</li>
  <li>adjective - Of or being a computer program designed for a specific task or use.</li>
</ul>

<p>This list comes from my friends over at Wordnik (https://www.wordnik.com/words/application), who I adore, have an API (https://developer.wordnik.com/), and who have contributed to this discussion by playing a leading role in introducing the API sector to the OpenAPI (fka Swagger) specification to the API community. That is whole other layer of significance when it comes to the semantics and meaning behind the word application, which I will have to write more about in a future post. In short, words matter. Really, words are everything. The meaning behind them. The intent. The wider understanding and belief. This is why APIs, and web applications like Wording are important. Helping us make sense of the world around us. Anyways, back to what is an application?</p>

<p>I like the first entry on the list — the act of applying. But, each of these definitions resonate with my view of the landscape. Yet, I’d say that the most common answer to this question hover towards the second half of this list, not the first half of it. Most application developers would say they are programming the application—the interface is for them. If you are an API developer you believe that are the one programming the application, where higher up on the platform decision making chain, they are the ones programming the application, and applying their vision of the world. Something that isn’t always visible at the lower levels, by API developers delivering APIs, the application developers consuming them, or the end-users of the tangible applications being delivered. I see the end desktop, web, or mobile as an application. I see the API as an application. I see the network connecting the two as an application. I also see the wider ideology being applied across all these layers, even when it is out of view to the outer layers.</p>

<p>One of the biggest imbalances in my belief system around technology, a result of be operating at the lower levels of business, institutional, or government, is that I am the one “applying” and “programming”. I was developing and delivering the application. These interfaces served me. After studying the machine closer. Tracking on the cycles. Documenting the results over the course of many cycles. I began to realize that there is more to this “application” thing than what I”m seeing. Maybe I was too close to the gears and the noise of the machine to see the bigger picture. I’m in the role of application developer not because I’m good at what I do. I’m there because I conveniently think I’m in control of this supply chain. As I worked my way up the supply chain, and became an API developer I continue to believe that I was the one “applying” and “programming”. However after over a decade of doing that, I’m realizing that I am not the one calling the shots. I’m applying something for someone else, and that applications were much more than just an iPhone or Android application, or even a TCP, FTP, STMP, HTTP, HTTP/2, or other protocol application. How you answer this questions depends on where you operate within the machine.</p>

<p>After climbing my way up through the layers of the machine, and finding my way to hatch at the top, finally getting some air in my lungs—-I still do not find myself in a better position. With more knowledge, just comes more concerns. Sometimes I wish I could climb back down to the lower levels, and enjoy the warmth and comfort of the inner workings of the machine. However, no I can’t find comfort in the toil that used to comfort me online late into the night. I can’t ignore what we are applying when we work in the service of the application. We are doing the hard work to mine, develop, integrate, and extract value. We are doing the dirty work of applying the vision of others. We are doing the hard work of laying the digital railroad tracks for the Internet tycoons. We are imposing their vision on the world. The special use or purpose of APIs do not always serve us. The usability and relevance is only minimally focused on us. The close attention and diligence is centered on maximum extraction and value generation for the platform. All wrapped in a computer program, designed for a specific task or use. Obfuscating the true application, with digital eye candy that keeps us always connected, and always open to something new being applied or directed in our life.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/18/what-is-an-appication/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/18/what-makes-you-think-your-graphql-consumers-will-want-to-do-the-work/">What Makes You Think Your GraphQL Consumers Will Want To Do The Work</a></h3>
        <span class="post-date">18 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-status-berlin-matrix.jpg" width="45%" align="right" style="padding: 15px;" />
Data work is grueling work. I’ve been working with databases since my first job developing student information databases in 1988 (don’t tell my wife). I’ve worked with Cobol, Foxpro, SQL Server, Filemaker, Access, MySQL, PostGres, and now Aurora databases over the last 30 years. I like data. I can even trick myself into doing massive data and schema refinement tasks on a regular basis. It is still grueling work that I rarely look forward to doing. Every company I’ve worked for has a big data problem. Data is not easy work, and the more data you accumulate, the more this work grows out of control. Getting teams of people to agree upon what needs to happen when it comes to schema and data storage, and actually execute upon the work in a timely, cost effective, and efficient way is almost always an impossible task. Which leaves me questioning (again), why GraphQL believers think they are going to be successfully in offshoring the cognitive and tangible work load to understand what data delivers, and then successfully apply it to a meaningful and monetizable business outcome.</p>

<p>Don’t get me wrong. I get the use cases where GraphQL makes sense. Where you have an almost rabid base of known consumers, who have a grasp on the data in play, and possesses an awareness of the schema behind. I’m have made the case for GraphQL as a key architectural component within a platform before. The difference in my approach over the majority of GraphQL believers, is that I’m acknowledging there is a specific group of savvy folks who need access to data, and understand the schema. I’m also being honest about who ends up doing the heavy data lifting here—-making sure this group wants it. However, I have an entirely separate group of users (the majority) who do not understand the schema, and have zero interest in doing the hard work to understand the schema, navigate relationships, and develop queries—-they just want access. Now. They don’t want to have to think about the big picture, they want one single bit of data, or a series of bits.</p>

<p>I’ve worked hard to engage in debate with GraphQL believers, and try to help provide them with advice on their approach. They aren’t interested. They operate within the echo chamber. They see a narrow slice of the API pie, and passionately believe their tool is the one solution. Like many API tooling peddlers who originate from within the echo chamber, they are hyper focused on the technology of managing our data. They think all data wranglers are like them. They think all data-driven companies are like theirs. They do not see the diverse types of API solutions that I see working across companies, institutions, organizations, and government agencies. They are not always aware of the business and political barriers that lie in between a belief in an API tool, and achieving a sustained implementation across the enterprise. They have that aggressive, tenacious startup way of penetrating operations, something that works well within the echo chamber, but it is an approach that will lose strength, and even begin to work against you outside the eco chamber within mainstream business operations.</p>

<p>I definitely see some interesting and useful tooling coming out of the GraphQL community. GraphQL is a tool in my API toolbox right along with REST, Hypermedia, Siren, HAL, JSON API, Alps, JSON Schema, Schema.org, OpenAPI, Postman Collections, Async API, Webhooks, Kafka, NATS, NGINX, Docker, and others. It has a purpose. It isn’t the silver bullet for me getting a handle on large amounts of data. It is one thing I consider when I’m trying to make sense of large data sets, and depending on the platform, the resources I have on staff, and the consumers, or the industry I am operating in–I MAY apply GraphQL. However, the times I will be able to successfully get it in the door, past legal, approved by leadership, accepted by internal developers, and then accepted and applied successfully by external developers, will be much fewer because of the aggressive echo chamber, investor-driven approach, which does not help sell the tool to my enterprise customers who have been investing in evolving their schema, and developing a suite of internal and external APIs over the last 20+ years. You might help me sell to a Silicon Valley savvy company, but you aren’t helping me in the mainstream enterprise.</p>

<p>This post will get the usual lineup of critical Tweets and comments. It’s fine. Once again the fact that I’m trying to help will be lost on believers. You will be more successful if you are honest about how the cognitive and  tangible workload is being shifted here. You are refusing to do the hard work to properly define and organize your schema, and provide meaningful imperative API capabilities that any developer can easily use, over providing a single declarative interface (and some tooling) to empower consumers to make sense of the schema, and access platform capabilities on their own. This works well with folks who are willing to take on the cognitive load of knowing the schema, knowing GraphQL, then are willing to accept the real work of crafting queries to get at what they desire. There are a whole lot of assumptions there that do not apply in all situations. I’d say about 12% of people I’ve worked with in my career would sign up for this. The rest of them, just want to get their task accomplished—get out of their way and give them an interface that is capable of accomplishing it for them.</p>

<p>Nobody wants to do data shit work. If you do, get help. It is a job that is only growing because our ability to generate, harvest, and store data has grown. There is a belief that data provides answers, without being really honest about what it takes to actually clean, refine, and organize the data, let alone any truthfulness regarding whether or not the answers are ever even there after we do invest in doing the dirty data work. Everyone is drowning in data. Everyone is chasing more data. Few are managing it well. This type of environment makes new data tooling very sexy. However, sexy tools rarely change the actual behavior on the ground within the enterprise. People still aren’t going to change behaviors overnight. GraphQL tooling will not solve all of our data problems. Ideally, we would see more interoperability of tooling between GraphQL and other API design, deployment, management, testing, monitoring, mocking, and client tooling. Like we are seeing with IBM Loopback, Postman, and others. Ideally, we would see less rhetoric around GraphQL being the one solution to rule them all. Ideally, we’d see less investor-driven rhetoric, and more real world solutions for applying through the mainstream business world. But, I’m guessing I’ll see the same response I’ve been getting on these posts since 2016. ;-(</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/18/what-makes-you-think-your-graphql-consumers-will-want-to-do-the-work/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/17/the-many-ways-in-which-apis-are-taken-away/">The Many Ways In Which APIs Are Taken Away</a></h3>
        <span class="post-date">17 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/catacombs-catacombs-copper-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
APIs are notorious for going away. There are so many APIs that disappear I really stopped tracking on it as a data point. I used keep track of APIs that were shuttered so that I could play a role in the waves of disgruntled pitchfork mobs rising up in their wake–it used to be a great way to build up your Hacker News points! But, after riding the wave a couple hundred waves of APIs shuttering, you begin to not really not give a shit anymore—-growing numb to it all. API deprecation grew so frequent, I wondered why anyone would make the claim that once you start an API you have to maintain it forever. Nope, you can shut down anytime. Clearly.</p>

<p>In the real world, APIs going away is a fact of life, but rarely a boolean value, or black and white. There are many high profile API disappearances and uprising, but there are also numerous ways in which some API providers giveth, and then taketh away from API consumers.:</p>

<ul>
  <li><strong>Deprecation</strong> - APIs disappear regularly both communicated, and not so communicated, leaving consumers scratching their heads.</li>
  <li><strong>Disappear</strong> - Companies regularly disappear specific API endpoints acting like they were never there in the first place.</li>
  <li><strong>Acquisition</strong> - This is probably one of the most common ways in which high profile, successful APIs disappear.</li>
  <li><strong>Rate Limits</strong> - You can always rate limit away users make APIs inaccessible, or barely usable for users, essentially making it go away.</li>
  <li><strong>Error Rates</strong> - Inject elevated error rates either intentionally or unintentionally can make an API unusable to everyone or select audience.</li>
  <li><strong>Pricing Tiers</strong> - You can easily be priced out of access to an API making it something that acts just like deprecating for a specific group.</li>
  <li><strong>Versions</strong> - With rapid versioning, usually comes rapid deprecation of earlier versions, moving faster than some consumers can handle.</li>
  <li><strong>Enterprise</strong> - APIs moving from free or paid tier, into the magical enterprise, “call us” tier is a common ways in which APIs go away.</li>
  <li><strong>Dumb</strong> - The API should not have existed in the first place and some people just take a while to realize it, and then shut down the API.</li>
</ul>

<p>I’d say Facebook, Twitter, and Google shutting down, or playing games in any of these areas have been some of the highest profile. <a href="http://apievangelist.com/2017/12/04/facebook-quietly-deprecates-the-audience-insight-api-used-to-automate-targeting-during-the-election/">The sneaky shuttering of the Facebook Audience Insight API was one example</a>, but didn’t get much attention. I’d say that <a href="http://apievangelist.com/2017/03/28/i-think-the-parse-twitter-page-sums-it-up-pretty-well/">Parse is one that Facebook</a> handled pretty well. Google did it with Google+ and Google Translate, but then brought back it with a paid tier. LinkedIn regularly locks down and disappears its APIs. Twitter has also received a lot of flack for limiting, restricting, and playing games with their APIs. In the end, many other APIs shutter after waves of acquisitions, leaving us with as my ex-wife says–“nothing nice”!</p>

<p>Face.com, Netflix, 23andMe, Google Search, ESPN, and others have provided us with lots of good API deprecation stories, but in reality, most APIs go aware without much fanfare. You are more likely to get squeezed out by rate limits, errors, pricing, and other ways of consciously making an API unusable. If you really want to understand the scope of API deprecation visit the leading deprecated API directory ProgrammableWeb—-they have thousands of APIs listed that do not exist anymore. In the end it is very difficult to successfully operate an API, and most API providers really aren’t in it for the long haul. The reasons why APIs stay in existence are rarely a direct result of them being directly financially viable. Developers squawk pretty loudly when the free API they’ve been mooching off of disappears, but there are many, many, many other APIs that go away and nobody notices, or nobody talks about. In the world of APIs there are very few things you can count on being around for very long, and you should always have a plan B and C for every API you depend on.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/17/the-many-ways-in-which-apis-are-taken-away/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/17/paying-for-api-access/">Paying for API Access</a></h3>
        <span class="post-date">17 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-old-door-lock-copper-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
APIs that I can’t pay for more access grinds my gears. I am looking at you GitHub, Twitter, Facebook, and a few others. I spend $250.00 to $1500.00 a month on my Amazon bill, depending on what I’m looking to get done. I know I’m not the target audience for all of these platforms, but I’m guessing there is a lot more money on the table than is being acknowledged. I’m guessing that the reason companies don’t cater to this, is that there are larger buckets of money involved in what they are chasing behind the scenes. Regardless, there isn’t enough money coming my way to keep my mouth shut, so I will keep bitching about this one alongside the inaccessible pricing tiers startups like to employ as well. I’m going to keep kvetching about API pricing until we are all plugged into the matrix—-unless the right PayPal payment lands in my account, then I’ll shut up. ;-)</p>

<p>I know. I know. I’m not playing in all your reindeer startup games, and I don’t understand the masterful business strategy you’ve all crafted to get rich. I’m just trying to do something simple like publish data to GitHub, or do some basic research on an industry using Twitter. I know there are plenty of bad actors out there who want also access to your data, but it is all something that could be remedied with a little pay as you go pricing, applied to some base unit of cost applied to your resources. If I could pay for more Twitter and GitHub requests without having to be in the enterprise club, I’d be very appreciative. I know that Twitter has begun expanding into this area, but it is something that is priced out of my reach, and not the simple pay as you go pricing I prefer with AWS, Bing, and other APIs I happily spend money on.</p>

<p>If you can’t apply a unit of value to your API resources, and make them available to the masses in a straightforward way—-I immediately assume you are up to shady tings. Your business model is much more loftier than a mere mortal like me can grasp, let alone afford. I am just an insignificant raw material in your supply chain—-just be quiet! However, this isn’t rocket science. I can’t pay for Google Searches, but I can pay for Bing searches. I can’t pay for my GitHub API calls. I’m guessing at some point I’ll see Bing pricing go out of reach as Microsoft continues to realize the importance of investing at scale in the surveillance economy—-it is how you play in the big leagues. Or maybe they’ll be like Amazon, and realize they can still lead in the surveillance game while also selling things to the us lower level doozers who are actually building things. You can still mine data on what we are doing and establish your behavioral models for use in your road map, while still generating revenue by selling us lower level services.</p>

<p>The problem here ultimately isn’t these platforms. It is me. Why the hell do I keep insisting on using these platforms. I can always extricate myself from them. I just have to do it. I’d much rather just pay for my API calls, and still give up my behavioral data, over straight extraction and not getting what I need to run my business each day. I feel like the free model, with no access to pay for more API calls is a sign of a rookie operation. If you really want to operate at scale, you should be obfuscating your true intentions with a real paid service. If you are still hiding behind the free model, you are just getting going. The grownups are already selling services for a fair price as a front, while still exploiting us at levels we can’t see, so ultimately they can compete with all of us down the road. Ok, in all seriousness, why can’t we get on a common model for defining API access, and setting pricing. I’m really tired of all the games. It would really simplify my life if I could pay for what I use of any resource. I’m happy to pay a premium for this model, just make sure it is within my reach. Thanks.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/17/paying-for-api-access/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/16/imperative-declarative-and-workflow-apis/">Imperative, Declarative, and Workflow APIs</a></h3>
        <span class="post-date">16 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/server-cloud-server-racks-clouds-smoking-cigarette.jpg" width="45%" align="right" style="padding: 15px;" />
At every turn in my API work I come across folks who claim that declarative APIs solutions are superior to imperative ones. They want comprehensive, single implementation, do it all their way approaches, over granular, multiple implementation API calls that are well defined by the platform. Declarative calls allow you to define a single JSON or YAML declaration that can then be consumed to accomplish many things, abstracting away the complexity of doing those many things, and just getting it done. Imperative API interfaces require many individual API calls to tweak each and every knob or dial on the system, but is something that is often viewed as more cumbersome from a seasoned integrator, but for newer, and lower level integrators a well designed imperative API can be an important lifeline.</p>

<p>Declarative APIs are almost always positioned against imperative APIs. Savvier, more experienced developers almost always want declarations. Where newer developers and those without a full view of the landscape, often prefer well designed imperative APIs that do one thing well. From my experience, I always try to frame the debate as imperative and declarative where the most vocal developers on the subject prefer to frame it as declarative vs imperative. I regularly have seasoned API developers “declare” that I am crazy for defining every knob and dial of an API resource, without any regard for use cases beyond what they see. They know the landscape, don’t want to be burdened them with having to pull every knob and dial, just give them one interface to declare everything they desire. A single endpoint with massive JSON or YAML post or abstract it all away with an SDK, Ansible, GraphQL, or a Terraform solution. Demanding that a platform meet their needs, without ever considering how more advanced solutions are delivered and executed, or the lower level folks who are on boarding with a platform, and may not have the same view of what is required to operate at that scale.</p>

<p>I am all for providing declarative API solutions for advanced users, however, not at the expense of the new developers, or the lower level ones who spend their day wiring together each individual knob or dial, so it can be used individually, or abstracted away as part of more declarative solution. I find myself regularly being the voice for these people, even though I myself, prefer a declarative solution. I see the need for both imperative and declarative, and understand the importance of good imperative API design to drive and orchestrate quality declarative API implementations, and even more flexible workflow solutions, which in my experience are often what processes, breaks down, and executes most declarations that are fed into a system. The challenge in these discussions are that the people in the know, who want the declarative solutions, are always the loudest and usually higher up on the food chain when it comes to getting things done. They can usually rock the boat, command the room, and dictate how things will get delivered, rarely ever taking into consideration the full scope of the landscape, especially what lower level people encounter in their daily work.</p>

<p>For me, the quality of an API always starts with the imperative design, and how well you think through the developer experience around every dial and knob, which will ultimately work to serve (or not), a more declarative and workflow approach. They all work together. If you dismiss the imperative, and bury it within an SDK, Ansible, or Terraform solution, you will end up with an inferior end solution. They all have to work in concert, and at some point you will have to be down in the weeds turning knobs and dials, understanding what is possible to orchestrate the overall solution we want. It is all about ensuring there is observability and awareness in how our API solutions work, while providing very granular approaches to putting them to work, while also ensuring there are simple, useable comprehensive approaches to moving mountains with hundreds or thousands of APIs. To do this properly, you can’t be dismissing the importance of imperative API design, in the service of your declarative—-if you do this, you will cannibalize the developer experience at the lower levels, and eventually your declarations will become incomplete, clunky, and do not deliver the correct “big picture” vision you will need of the landscape.</p>

<p>When talking API strategy with folks I can always tell how isolated someone is based upon whether they see it as declarative vs imperative, or declarative and imperative. If it is the former, they aren’t very concerned with with others needs. Something that will undoubtedly introduce friction as the API solutions being delivered, because they aren’t concerned with the finer details of API design, or the perspectives of the more junior level, or newer developers to the conversation. They see these workers in the same way they see imperative APIs, something that should be abstracted away, and is of no concern for them. Just make it work. Something that will get us to the same place our earlier command and control, waterfall, monolith software development practices have left us. With massive, immovable, monolith solutions that are comprehensive and known by a few, but ultimately cannot pivot, change, evolve, or be used in new ways because you have declared one or two ways in with the platform should be used. Rather than making things more modular, flexible, and orchestrate-able, where anyone can craft (and declare) a new way of stitching things together, painting an entirely new picture of the landscape with the same knobs and dials used before, but done so in a different way than was ever conceived by previous API architects.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/16/imperative-declarative-and-workflow-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/16/hoping-for-more-investment-in-api-design-tooling/">Hoping For More Investment In API Design Tooling</a></h3>
        <span class="post-date">16 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-new-68-158-800-500-0-max-0-1--1.jpg" width="45%" align="right" style="padding: 15px;" />
I was conducting an accounting of my API design toolbox, and realized it hasn’t changed much lately. It is still a very manual suite of tooling, and sometimes services, that help me craft my APIs. There are some areas I am actively investing in when it comes to API design, but honestly there really isn’t that much new out there to use. To help me remember how we got here, I wanted to take a quick walk through the history of API design, and check in on what is currently available when it comes to investing in your API design process.</p>

<p>API design has historically meant REST. Many folks still see it this way. While there has been plenty of books and articles on API design for over a decade, I attribute the birth of API design to Jakub and Z at Apiary (https://apiary.io). I believe they first cracked open the seed of API design, and the concept API design first. Which is one of the reasons I was so distraught when Oracle bought them. But we won’t go there. The scars run deep, and where has it got us? Hmm? Hmm?? Anyways, they set into motion an API design renaissance which has brought us a lot of interesting thinking on API design, a handful of tooling and services, some expansion on what API design means, but ultimately not a significant amount of movement overall.</p>

<p>Take a look at what AP+I Design (https://www.apidesign.com/) and API Plus (https://apiplus.com/) have done to architecture, API has done for the oil and gas industry (https://www.api.org/), and API4Design has done for the packaging industry (http://api4design.com/)—I am kidding. Don’t get me wrong, good things have happened. I am just saying we can do more. The brightest spot that represents the future for me is over at:</p>

<ul>
  <li><a href="http://stoplight.io"><strong>Stoplight.io</strong></a> - They are not just moving forward API design, they are also investing in the full API lifecycle, including governance. I rarely plug startups, unless they are doing meaningful things, and Stoplight.io is.</li>
</ul>

<p>After Stoplight.io, I’d say some of the open source tooling that still exists, and has been developed over the last five years, gives me the most hope that I will be able to efficiently design APIs at scale across teams:</p>

<ul>
  <li><a href="https://editor.swagger.io/"><strong>Swagger Editor</strong></a> - I still find myself using this tool for most of my quick API design work.</li>
  <li><a href="http://apistylebook.com/"><strong>API Stylebook</strong></a> - What Arnaud has done reflects what should be standard across all industries.</li>
  <li><a href="https://mermade.github.io/openapi-gui/"><strong>OpenAPI GUI</strong></a> - A very useful and progressive OpenAPI GUI editor.</li>
  <li><a href="https://www.apicur.io/"><strong>Apicurio</strong></a> - Another useful GUI OpenAPI editor which shouldn’t be abandoned (cough cough).</li>
  <li><a href="http://webconcepts.info/"><strong>Web Concepts</strong></a> - The building blocks of every API design effort is located here.</li>
</ul>

<p>I use these tools in my daily work, and think they reflect what I like to see when it comes to API design tooling investment. I would be neglectful if I didn’t give a shout out to a handful of companies doing good work in this area:</p>

<ul>
  <li><a href="https://www.getpostman.com/"><strong>Postman</strong></a> - While not coming from a pure API design vantage point, you can do some serious design work within Postman.</li>
  <li><a href="https://www.apimatic.io/"><strong>APIMATIC</strong></a> - It takes good API design to deliver usable SDKs, and APIMATIC provides a nice set of design tooling for their services.</li>
  <li><a href="https://www.reprezen.com/"><strong>Reprezen</strong></a> - They have invested heavily in their overall API design workflow and are a key player in the OpenAPI conversation.</li>
  <li><a href="https://restlet.com/"><strong>Restlet</strong></a> - My friends over at Restlet are still up to good things even thought they are part of Talend.</li>
</ul>

<p>While I am not quite ready to showcase and highlight these companies because they don’t always reflect the positive API community influence I’d like to see, I don’t want to leave them out for what they bring to the table:</p>

<ul>
  <li><a href="https://app.swaggerhub.com/"><strong>SwaggerHub</strong></a> - They are doing interesting things, even if I’m still bummed over the whole Swagger -&gt; OpenAPI bullshit, which I will never forget!</li>
  <li><a href="https://www.mulesoft.com/platform/api/anypoint-designer"><strong>Mulesoft</strong></a> - Their AnyPoint Designer is worth noting in this discussion. I will leave it there.</li>
</ul>

<p>While writing this, and taking a fresh look at the search results for API design, editors, and tooling, and looking through my archives, I came across a couple players I have never seen before, either because I haven’t been tuned in, or because they are new:</p>

<ul>
  <li><a href="https://openapi.design/#/about"><strong>OpenAPI Designer</strong></a> - An interesting new player to the OpenAPI editor game.</li>
  <li><a href="https://visual-paradigm.com/features/code-engineering-tools/#rest-api-generation"><strong>Visual Paradigm</strong></a> - Another interesting approach to delivering APIs – we may have to test drive.</li>
</ul>

<p>I do not want to stop there. Maybe there are other API design toolbox forces at play, influencing, shifting, or directing the API design conversation in other ways, using different protocols and approaches:</p>

<ul>
  <li><a href="https://graphql.org/"><strong>GraphQL</strong></a> - Maybe the GraphQL believers are right? Maybe it is the true solution to designing our APIs? What if? OMG</li>
  <li><a href="https://kafka.apache.org/"><strong>Kafka</strong></a> - I think an event-driven approach has shifted the conversation for many, moving classic API design into the background.</li>
  <li><a href="https://grpc.io/">gRPC</a> - Maybe we are moving towards a more HTTP/2 RPC way of delivering APIs and API design is becoming irrelevant.</li>
</ul>

<p>It is possible that these solutions are siphoning off the conversation in new directions. Maybe the lack of investment is due to other influences that go well beyond the technology, or a specific approach to defining and designing the API problems. What might be some out of the box reasons the API design conversation hasn’t moved forward:</p>

<ul>
  <li><strong>Investment</strong> -  Most of the movement I’ve seen has occurred as well as stagnated because of the direction of venture capital.</li>
  <li><strong>Hard</strong> - Maybe it is because it is hard, and nobody wants to do it, making it something that is difficult too monetize.</li>
  <li><strong>Expertise</strong> - We need more training and the development of API design expertise to help lead the way, and show us how it is done.</li>
  <li><strong>Bullshit</strong> - Maybe API design is bullshit, and we are delusional to think anything will ever become of API design in the first place.</li>
  <li><strong>My Vision</strong> - Maybe my vision of API design tooling and services is too high of a bar, or unrealistic in some way.</li>
</ul>

<p>Ultimately, I think API design is difficult. I think we need more investment in small open source API design tooling that do one thing well. I think other API paradigms will continue to distract us, but also potentially enrich us. I think my vision of API design is obtainable, but out of view of the current investment crowd. I think API design vision is either technical, or it is business. There is very little in between. This is why I highlight Stoplight.io. I feel they are critically thinking about not just API design, but also the rest of the lifecycle. I’d throw Postman into this mix, but they are more API lifecycle than pure design, but I do think they reflect more of the type of services and tooling I’d like to see.</p>

<p>I do not think resource centered web API design is going anywhere. From what I”m seeing, it is going mainstream. It is simple. Low cost. It gets the job done with minimal investment. I think we should invest more into open source API design solutions. I think we need continued investment in API design services like Stoplight.io, Postman, Reprezen, Restlet, and others. I think we need to shift the conversation to also include GraphQL, Kafka, and gRPC. I think investors can do a better job, but I”m not going to hold my breathe there. In the end, I go back to my hand-crafted, artisanal, API design workbench out back where I have cobbled together a few open source tools, on top of a Git foundation. Honestly, it is all I can afford, but I’ll keep playing with other tools I have access to, to see if something will shift my approach.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/16/hoping-for-more-investment-in-api-design-tooling/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/15/what-is-an-api-contract/">What Is An API Contract?</a></h3>
        <span class="post-date">15 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/adam-smith-adam-smith-purp-paper.jpg" width="45%" align="right" style="padding: 15px;" />
I am big on regularly interrogating what I mean when I use certain phrases. I’ve caught myself repeating and reusing many hollow, empty, and meaningless phrases over my decade as the API Evangelist. One of these phrases is, “an API contract”. I use it a lot. I hear it a lot. What exactly do we mean by it? What is an API contract, and how is it different or similar to our beliefs and understanding around other types of contracts? Is it truth, or is just a way to convince people that what we are doing is just as legitimate as what came before? Maybe it is even more legitimate, like in a blockchain kind of way? It is an irreversible, unbreakable, digital contract think bro!</p>

<p>If I was to break down what I mean when I say API contract, I’d start with being able to establish to a shared articulation of what an API does. We have an OpenAPI definition which describes the surface area of the request and response of each individual API method being offered. It is available in a machine and human readable format for both of us to agree upon. It is something that both API provider and API consumer can agree upon, and get to work developing and delivering, and then integrating and consuming. An API contract is a shared understanding of what the capabilities of a digital interface are, allowing for applications to be programmed on top of.</p>

<p>After an API contract establishes a shared understanding, I’d say that an API contract helps mitigate change, or at leasts communicates it—-again, in a human and machine readable way. It is common practice to semantically version your API contracts, ensuring that you won’t remove or rename anything within a minor or patch release, committing to only changing things in a big way with each major release. Providing an OpenAPI of each version ahead of time, allowing consumers to review that new version of an API contract before they ever commit to integrating and moving to the next version. Helping reduce the amount of uncertainty that inevitably exists when an API changes, and consumers will have to respond with changes in their client API integrations.</p>

<p>Then I’d say an API contract moves into service level agreement (SLA) territory, and helps provide some guarantees around API reliability and stability. Moving beyond any single API, and also speaking to wider operations. An API contract represents a commitment to offering a reliable and stable service that is secure, observability, and the provider has consumers best interest in mind. A contract should reflect a balance between the provider and the consumer interests, and provide a machine and human readable agreement that reflects the shared understanding of what an API delivers—for an agreed upon price. Any API contract reflects the technical and business details of us doing business in this digital world.</p>

<p>Sadly, an API contract is often wielded in the name of all of these things, but there really is very little accountability or enforcement when it comes to API contracts. It is 100% up to the API provider to follow through and live up to the contract, with very little an API consumer can do if the contract isn’t met. Resulting in many badly behaved API providers, as well as monstrous API consumers. Right now, API contract is thrown around by executives, evangelists, analysts and pundits, more than they are ever actually used to govern what happens on the ground of API operations. Only time will tell if API contracts are just another buzzword that comes and goes, or if they become common place when it comes to doing business online in a digital world.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/15/what-is-an-api-contract/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/12/my-primary-api-search-engines/">My Primary API Search Engines</a></h3>
        <span class="post-date">12 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-crypto-machine-bletchley-copper-circuit.png" width="45%" align="right" style="padding: 15px;" />
I am building out several prototypes for the moving parts of an API search engine I want to build, pushing my usage of APIs.json and OpenAPI, but also trying to improve how I define, store, index, and retrieve valuable data about thousands of APIs through a simple search interface. I’m breaking out the actual indexing and search into their own areas, with rating system being another separate dimension, but even before I get there I have to actually develop the primary engines for my search prototypes, feeding the indexes with fresh signals of where APIs exist across the online landscape. There isn’t an adequate search engine out there, so I’m determined to jumpstart the conversation with an API search engine of my own. Something that is different from what web search engines do, and tailored to the unique mess we’ve created within the API industry.</p>

<p>My index of APIs.json and OpenAPI definitions, even with a slick search interface is just a catalog, directory, or static index of a small piece of the APIs that are out there. I see a true API search engine as three parts</p>

<ol>
  <li>The Humans Searching for APIs - Providing humans with web application to search for new and familiar APIs.</li>
  <li>The Search Engine Searching For APIs - Ensuring that the search engine is regularly searching for new APIs.</li>
  <li>Other Systems Searching For APIs - Providing an API for other systems to search for new and familiar APIs.</li>
</ol>

<p>Without the ability for the search engine to actually seek out new APIs, it isn’t a search engine in my opinion—-it is a search application. Without an API for searching for APIs, in my opinion, it isn’t an API search engine. It takes all three of these areas to make an application a true API search engine, otherwise we just have another catalog, directory, marketplace, or whatever you want to call it.</p>

<p>To help me put the engine into my API search engine, I’m starting with a handful of sources I’ve cultivated over the last five years studying the API industry. Providing me with some seriously rich sources of information when it comes to identifying new APIs:</p>

<ul>
  <li><strong>GitHub Code Search API</strong> - I have a vocabulary I use for uncovering artifacts that provide clues to where APIs exist. I can also expand this search to topics, repos, and other dimensions of GitHub search, but I’m going to make sure I’m exhausting and optimizing core search for all I can before I move on.  GitHub provides me with a handful of nuggets when it comes to finding APIs:
    <ul>
      <li><strong>Swagger</strong> - Machine readable JSON and YAML API definitions.</li>
      <li><strong>OpenAPI</strong> - Machine readable JSON and YAML API definitions.</li>
      <li><strong>Postman</strong> - Machine readable JSON API definitions.</li>
      <li><strong>API Blueprint</strong> - Machine readable markdown definitions.</li>
      <li><strong>RAML</strong> - Machine readable YAML definitions.</li>
      <li><strong>HAR</strong> - Machine readable traffic snapshots.</li>
      <li><strong>Domains</strong> - Domains doing interesting things with APIs.</li>
      <li><strong>People</strong> - People doing interesting things with APIs.</li>
    </ul>
  </li>
  <li><strong>Bing Web Search API</strong> - I use my vocabulary to uncover domains and artifacts that provide clues to where APIs exist. Unlike GitHub, I have to pay for these API calls, so I’m being much more careful about how I spider, and coherently defining the vocabulary I use to uncover this landscape.  Bing provides me with a handful of nuggets when it comes to finding APIs:
    <ul>
      <li><strong>Domains</strong> - A look into many different domains who are talking APIs in specific verticals.</li>
      <li><strong>GitHub</strong> - I find that Bing has some interesting indexes of GitHub — wondering how this will evolve.</li>
    </ul>
  </li>
  <li><strong>Twitter</strong> - I use my vocabulary to identify new domains where people are talking about APIs, and additional signs of APIs.
    <ul>
      <li><strong>Domains</strong> - A look into many different domains who are talking APIs in specific verticals.</li>
      <li><strong>People</strong> - People doing interesting things with APIs.</li>
    </ul>
  </li>
  <li><strong>Domain</strong> - I have an exhaustive list of domains to spider for API artifacts, autogenerating OpenAPI index along the way.
    <ul>
      <li><strong>URLs</strong> - I look for a handful of valuable URLs for use as part of my index.
        <ul>
          <li><strong>Twitter</strong> - Their Twitter accounts.</li>
          <li><strong>GitHub</strong> - Their GitHub accounts.</li>
          <li><strong>LinkedIn</strong> - Their LinkedIn accounts.</li>
          <li><strong>Feeds</strong> - Their Atom and RSS feeds.</li>
          <li><strong>Definitions</strong> - Any API definitions I can find.</li>
          <li><strong>Documentation</strong> - Where their documentation is.</li>
          <li><strong>Other Links</strong> - I have a long list of other links I look for</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>These four areas represent the primary engines for my API search engine. I currently have these engines running on AWS, processing GitHub and Bing searches, and I’m currently refining my existing Twitter, and relevant domain harvesting engines. While Bing and GitHub are harvesting API signals, and indexing API artifacts like OpenAPI, Postman, and others, I’m going to overhaul my Twitter and domain approaches. Twitter has always been a treasure trove of API signals, but like on GitHub, it is getting harder to obtain these API signals at scale—-as their value increases, things are getting tighter with API access. Also, running a proper domain harvesting campaign across thousands of domains isn’t easy, and will require some refactoring to do at the scale I need for this type of effort.</p>

<p>While I have two of these up and running, indexing new APIs, I still have a significant amount of work to invest in each engine. What I have now is purely of prototype. It will take several cycles until I get each engine performing as desired, and then I’m expecting ongoing tweaks, adjustments, and refinements to be made daily, weekly, and monthly to get the results I’m looking for. There are many areas of deficiency in the API sector that bother me, but not having a simple way to search for new and existing APIs is one are I cannot tolerate any longer. I am happy that ProgrammableWeb has been around all these years, but they haven’t moved the needle in the right way. I also get why people do API marketplaces, but I’m afraid they aren’t moving the needle in a positive direction either. I’d say that APIs.Guru (https://apis.guru/openapi-directory/) is the most progressive vision when it comes to API search in the last decade–with all the innovation supposedly going on, that is just sad. I am guessing that venture capital does not always equal meaningful things we need will get built.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/12/my-primary-api-search-engines/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/11/taking-a-fresh-look-at-the-nuance-of-api-search/">Taking A Fresh Look At The Nuance Of API Search</a></h3>
        <span class="post-date">11 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/stories-beach-rocks-currents-internet-numbers.jpg" width="45%" align="right" style="padding: 15px;" />
I have a mess of APIs.json and OpenAPI definitions I need to make sense of. Something that I could easily fire up an ElasticSearch instance, point at my API “data lake”, and begin defining facets and angles for making sense of what is in there. I’ve done this with other datasets, but I think this round I’m going to go a more manual route. Take my time to actually understand the nuance of API search over other types of search, take a fresh look at how I define and store API definitions, but also how I search across a large volume of data to find exactly the API I am looking for. I may end up going back to a more industrial grade solution in the end, but I am guessing I will at least learn a lot along the way.</p>

<p>I am using API standards as the core of my API index—APIs.json and OpenAPI. I’m importing other formats like API Blueprint, Postman, RAML, HAR, and others, but the core of my index will be APIs.json and OpenAPI. This is where I feel solutions like ElasticSearch might overlook some of the semantics of each standard, and I may not immediately be able to dial-in on the preciseness of the APIs.json schema when it comes to searching API operations, and OpenAPI schema when it comes to searching the granular details of what each individual API method delivers. While this process may not get me to my end solution, I feel like it will allow me to more intimately understand each data point within my API index in a way that helps me dial-in exactly the type of search I envision.</p>

<p>The first dimensions are of my API search index are derived from APIs.json schema properties I use to define every entity within my API search index:</p>

<ul>
  <li><strong>Name</strong> - The name of a company, organization, institution, or government agency.</li>
  <li><strong>Description</strong> - The details of what a particular entity brings to the table.</li>
  <li><strong>Tags</strong> - Specific tags applied to an entity, or even a collection of entities.</li>
  <li><strong>Kin Rank</strong> - What Kin thinks of the entity being indexed with APIs.json.</li>
  <li><strong>Alexa Rank</strong> - What Alex thinks of the entity being indexed with APIs.json.</li>
  <li><strong>Common Properties</strong> - Using common properties like blog, Twitter, and GitHub.</li>
  <li><strong>Included</strong> - Other related APIs that are included within the index.</li>
  <li><strong>Maintainers</strong> - Details about who is the maintainer of the API definition.</li>
  <li><strong>API Name</strong> - The name of specific API program or project that an entity possesses.</li>
  <li><strong>API Description</strong> - The details of a specific API program or project that an entity possesses.</li>
  <li><strong>API Tags</strong> - How the individual API program or project is tagged for organization.</li>
  <li><strong>API Properties</strong> - The details of specific properties of an API like documentation, pricing, etc.</li>
</ul>

<p>After indexing the 100K view with APIs.json, providing references to the different layers of API operations, I’m indexing the following OpenAPI schema properties:</p>

<ul>
  <li><strong>Title</strong> - The title of an individual API program or project that an entity possesses.</li>
  <li><strong>Description</strong> - The description of an individual API program or project that an entity possesses.</li>
  <li><strong>Domain</strong> - The subdomain, or top level domain that an API operates within.</li>
  <li><strong>Version</strong> - The version of each individual API.</li>
  <li><strong>Tags</strong> - The tags that are applied to a specific API program or project that an entity possesses.</li>
  <li><strong>API Path</strong> - The actual path of each API.</li>
  <li><strong>API Method Summary</strong> - The summary for an individual API method.</li>
  <li><strong>API Method Description</strong> - The description for an individual API method.</li>
  <li><strong>API Method Operation ID</strong> - The operation id for an individual API method.</li>
  <li><strong>API Method Query Parameters</strong> - The query parameters for an individual API method.</li>
  <li><strong>API Method Headers</strong>  - The headers for an individual API method.</li>
  <li><strong>API Method Body</strong> - The body of an individual API method.</li>
  <li><strong>API Method Tags</strong> - The tags applied to each individual API methods.</li>
  <li><strong>Schema Object Name</strong> - The name of each of the schema objects.</li>
  <li><strong>Schema Object Description</strong> - The description of each of the schema objects.</li>
  <li><strong>Schema Properties</strong> - The properties of each of the schema objects.</li>
  <li><strong>Schema Tags</strong> - The tags of each of the schema objects.</li>
</ul>

<p>These details provide to be by the OpenAPI definition for each API provides me with the long tail of my search, going beyond just the names and description of each API, allowing me to turn on or turn off different facets of the OpenAPI specification when indexing, and delivering search results.  My biggest challenges in building this index center around:</p>

<ul>
  <li><strong>Completeness</strong> - I struggle with being able to invest the resources to properly complete the profile for each API.</li>
  <li><strong>Inconsistency</strong> - Navigating the inconsistency of APIs, trying to nail down a single definition across thousands of the is hard.</li>
  <li><strong>Performance</strong> - The performance of basic JavaScript search against such a large set of YAML / JSON documents isn’t optimal.</li>
  <li><strong>Accuracy</strong> - The accuracy of API methods is difficult to ascertain without actually getting a key and firing up Postman, or other script.</li>
  <li><strong>Up to Date</strong> - Understanding when information has become out of date, obsolete, or deprecated is a huge challenge with search.</li>
</ul>

<p>Right now I have about 2K APIs defined with APIs.json, with a variety of OpenAPI artifacts to support. With more coming in each day through my search engine spiders, trolling GitHub and the open web for signs of API life. I’m working to refine my current index of APIs, making sure they are complete-enough for making available publicly. Then I want to be able to provide a basic keyword search tool, then slowly add each of these individual data points to some sort of advanced filter setting for this search tool. I’m not convinced I’ll end up with a usable solution in the end, but I convinced that I will flesh out more of the valuable data points that exist within an APIs.json and OpenAPI index.</p>

<p>This prototype will at least give me something to play with when it comes to crafting a JavaScript interface for the YAML API index I am publishing to GitHub. I feel like these API search knobs will help me better define my search index, and craft cleaner OpenAPI definitions for use in this API search index. As the index grows I can dial in the search filters, and look for the truly interesting patterns that exist across the API landscape. Then I’m hoping to add an API ratings layer to further help me cut through the noise, and identify the truly interesting APIs amidst the chaos and trash. Not all APIs are created equal and I will need a way to better index, rank, and then ultimately search for the APIs I need. While also helping me more easily discover entirely new types of APIs that I may not notice in my insanely busy world.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/11/taking-a-fresh-look-at-the-nuance-of-api-search/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/10/navigating-api-rate-limit-diffs-between-platforms/">Navigating API Rate Limit Differences Between Platforms</a></h3>
        <span class="post-date">10 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-death-valley-national-park-dali-three-just-road.jpg" width="45%" align="right" style="padding: 15px;" />
I always find an API providers business model to be very telling about the company’s overall strategy when it comes to APIs. I’m currently navigating the difference between two big API providers, trying to balance my needs spread across very different approaches to offering up API resources. I’m working to evolve and refine my API search algorithms and I find myself having to do a significant amount of work due to the differences between GitHub and Microsoft Search. Ironically, they are both owned by the same company, but we all know their business models are seeking alignment as we speak, and I suspect my challenges with GitHub API is probably a result of this alignment.</p>

<p>The challenges with integrating with GitHub and Microsoft APIs are pretty straightforward, and something I find myself battling regularly when integrating with many different APIs. My use of each platform is pretty simple. I am looking for APIs. The solutions are pretty simple, and robust. I can search for code using the GitHub Search API, and I can search for websites using the Bing Search API. Both produce different types of results, but what both produce is of value to me. The challenge comes in when I can pay for each API call with Bing, and I do not have that same option with GitHub. I am also noticing much tighter restriction on how many calls I can make to the GitHub APIs. With Bing I can burst, depending on how much money I want to spend, but with GitHub I have no relief value—I can only make X calls a minute, per IP, per user.</p>

<p>This is a common disconnect in the world of APIs, and something I’ve written a lot about. GitHub (Microsoft) has a more “elevated” business model, with the APIs being just an enabler of that business model. Where Bing (Microsoft) is going with a much more straightforward API monetization strategy—pay for what you use. In this comparison my needs are pretty straightforward—-both providers have data I want, and I’m willing to pay for it. However, there is an additional challenge. I’m also using GitHub to manage the underlying application for my project. Meaning after I pull search results from GitHub and Bing, and run them through my super top secret, magical, and proprietary refinement algorithm, I publish the refined results to a GitHub repository, and manage the application in real time using Git, and GitHub APIs—which counts against my API usage.</p>

<p>I used to manage all my static sites and applications 100% on GitHub, using the APIs to orchestrate the data behind each Jekyll-driven site. For the last five years I’ve run API Evangelist, and waves of simple data-driven static applications on GitHub like this. It has been a good ride. A free ride. One I fear is coming to a close. I can no longer deploy static data-driven Jekyll apps on the platform, and confidently manage using the GitHub API anymore. It is something I do not expect to continue getting for free. I’d be happy to pay for my account on a per organization, per repo, and per API call basis. In the end, I’ll probably begin just relying on Git for bulk builds of each application I run on GitHub, and eventually begin migrating them to my own servers, running Jekyll on my own, and custom developing an API for managing the more granular changes across hundreds of micro applications that run on Jekyll using YAML data. It would be nice for GitHub to notice this type of application development as part of their business model, but I’m guessing it isn’t mainstream enough for folks to adopt, and GitHub to cater to.</p>

<p>Getting back to the search portion of this post. I am finding myself writing a scheduling algorithm that spread out my API calls across a 24 hour period. I guess I can also leverage the different GitHub accounts I have access to and maybe spread the harvesting across a couple EC2 instance, but I’d rather just do what Bing offers me, and put in my credit card. I am sure there are other ways I can find to circumvent the GitHub API rate limits, but why? I would rather just be above board and put in my credit card to be able to scale how I’m using the platform. One of the biggest challenges to API integration at scale in the future will be API providers who do not offer relief valves for their consumers. Significantly increasing the investment required to integrate with an API in a meaningful way, making it much more difficult to seamless use just a handful of APIs, let alone hundreds or thousands of them. This challenge is nothing new, and just one example of how the business of APIs can get in the way of the technology of APIs—-slowing things down along the way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/10/navigating-api-rate-limit-diffs-between-platforms/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/10/the-json-schema-tooling-in-my-life/">The JSON Schema Tooling In My Life</a></h3>
        <span class="post-date">10 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/udnie-DSC_0033.jpg" width="45%" align="right" style="padding: 15px;" />
I am always pushing for more schema order in my life. I spend way too much time talking about APIs, when a significant portion of the API foundation is schema. I don’t have as many tools to help me make sense of my schema, and to improve them as definitions of meaningful objects. I don’t have the ability to properly manage and contain the growing number of schema objects that pop up in my world on a daily basis, and this is a problem. There is no reason I should be making schema objects available to other consumers if I do not have a full handle on what schema objects exist, let alone a full awareness of everything that has been defined when it comes to the role that each schema object plays in my operations.</p>

<p>To help me better understand the landscape when it comes to JSON Schema tooling, I wanted to take a moment and inventory the tools I have bookmarked and regularly use as part of my daily work with JSON Schema:</p>

<ul>
  <li><strong>JSON Schema Editor</strong> - https://json-schema-editor.tangramjs.com/ - An editor for JSON Schema.</li>
  <li><strong>JSON Schema Generator</strong> - https://github.com/jackwootton/json-schema - Generates JSON Schema from JSON</li>
  <li><strong>JSON Editor</strong> - https://json-editor.github.io/json-editor/ - Generates form and JSON from JSON Schema.</li>
  <li><strong>JSON Editor Online</strong> -https://github.com/josdejong/jsoneditor/ - Allows me to work with JSON in a web interface.</li>
  <li><strong>Another JSON Schema Validator (AJV)</strong> - https://github.com/epoberezkin/ajv - Validates my JSON using JSON Schema.</li>
</ul>

<p>I am going to spend some time consolidating these tools into a single interface. They are all open source, and there is no reason I shouldn’t be localizing their operation, and maybe even evolving and contributing back. This helps me understand some of my existing needs and behavior when it comes to working with JSON Schema, which I’m going to use to seed a list of my JSON Schema needs, as drive a road map for things I’d like to see developed. Getting a little more structure regarding how I work with JSON Schema.</p>

<ul>
  <li><strong>Visual Editor</strong> - Being able to visual render and edit JSON Schema in browser.</li>
  <li><strong>YAML / JSON Editor</strong> - Being able to edit JSON Schema in YAML or JSON.</li>
  <li><strong>YAML to JSON Converter</strong> - Converting my YAML JSON Schema into JSON.</li>
  <li><strong>JSON to YAML Converter</strong> - Converting my JSON JSON Schema into YAML.</li>
  <li><strong>JSON to JSON Schema Generator</strong> - Generate JSON Schema from JSON object.</li>
  <li><strong>JSON Schema to JSON Generator</strong> - Generate a JSON object from JSON Schema.</li>
  <li><strong>JSON Validation Using JSON Schema</strong> - Validate my JSON using JSON Schema.</li>
  <li><strong>Enumerators</strong> - Help me manage enumerators used across many objects.</li>
  <li><strong>Search</strong> - Help me search across my JSON Schema objects, wherever they are.</li>
  <li><strong>Guidance</strong> - Help me create better JSON Schema objects with standard guidelines.</li>
</ul>

<p>This is a good start. If I can bring some clarity and coherence to these areas, I’m going to be able to step up my API design and development game. If I can’t, I’m afraid I’m going to be laying a poor foundation for any API I’m designing in this environment. I mean, how can I consciously provide access to any schema object that I don’t have properly defined, indexed, versioned, and managed? If I don’t fully grasp my schema objects, my API design is going to be off kilter, and most likely be causing friction with my consumers. Granted, I could be offloading the responsibility for making sense of my schema to my consumers using a GraphQL solution, but I’m more in the business of doing the heavy lifting in this area, as it pertains to my business—-I’m the one who should know what is going on with each and every object that passes through my business servers.</p>

<p>I wish there was a schema tool out there to help me do everything that I need. Unfortunately I haven’t seen it. The tooling that has rose up around the OpenAPI specification helps us better invest in schema objects when they are in the service of our API contracts, but nothing just for the sake of schema management. I will keep taking inventory of what tooling is available, as well as what I am needing when it comes to JSON Schema management. Who knows, something might pop up out there on the landscape. Or, more realistically I’m hoping little individual open source solutions keep popping up, allowing me to stitch them together and create the experience I’m looking for. I’m a big fan of this approach, rather than one service provider swooping in and providing the one tool to rule them all, only to get acquired and then be shut down–breaking my heart all over again.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/10/the-json-schema-tooling-in-my-life/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/09/The-details-of-my-api-rating-formula/">The Details Of My API Rating Formula</a></h3>
        <span class="post-date">09 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/udnie-IMG_7559.jpg" width="45%" align="right" style="padding: 15px;" />
Last week I put some thoughts down about the basics of my API rating system. This week I want to go through each of those basics, and try to flesh out the details of how I would gather the actual data needed to rank API providers. This is a task I’ve been through with several different companies, only to be abandoned, and then operated on my own for about three years, only to abandon once I ran low on resources. I’m working to invest more cycles into actually defining my API rating in a transparent and organic way, then applying it in a way that allows me to continue evolving, while also using to make sense of the APIs I am rapidly indexing.</p>

<p>First, I want to look at the API-centric elements I will be considering when looking at a company, organization, institution, government agency, or other entity, and trying to establish some sort of simple rating for how well they are doing APIs. I’ll be the first to admit that ratings systems are kind of bullshit, and are definitely biased and hold all kinds of opportunity for going, but I need something. I need a way to articulate in real time how good of an API citizen an API provider is. I need a way to rank the searches for the growing number of APIs in my API search index. I need a list of questions I an ask about an API in both a manual, or hopefully automated way:</p>

<ul>
  <li>**Active / Inactive **- APIs that have no sign of life need a lower rating.
    <ul>
      <li><strong>HTTP Status Code</strong> - Do I get a positive HTTP status code back when I ping their URL(s)?</li>
      <li><strong>Active Blog</strong> - Does their blog have regular activity on it, with relevant and engaging content?</li>
      <li><strong>Active Twitter</strong> - Is there a GitHub account designated for the API, and is it playing an active role in its operations?</li>
      <li><strong>Active GitHub</strong> - Is there a GitHub account designated for the API, and is it playing an active role in its operations?</li>
      <li><strong>Manual Visit</strong> - There will always be a need for a regular visit to an API to make sure someone is still home.</li>
    </ul>
  </li>
  <li><strong>Free / Paid</strong> - What something costs impacts our decision to use or not.
    <ul>
      <li><strong>Manual Visit</strong> - There is no automated way to understand API pricing.</li>
    </ul>
  </li>
  <li><strong>Openness</strong> - Is an API available to everyone, or is a private thing.
    <ul>
      <li><strong>Manual Review</strong> - This will always be somewhat derived from a manual visit by an analyst to the API.</li>
      <li><strong>Sentiment Analysis</strong>  - Some sentiment about the openness could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
    </ul>
  </li>
  <li><strong>Reliability</strong> - Can you depend on the API being up and available.
    <ul>
      <li><strong>Manual Review</strong> - Regularly check in on an API to see what the state of things are.</li>
      <li><strong>Sentiment Analysis</strong> - Some sentiment about the reliability of an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
      <li><strong>Monitoring Feed / Data</strong> - For some APIs, monitoring could be setup, but will cost resources to be able to do accurately.</li>
    </ul>
  </li>
  <li><strong>Fast Changing</strong> - Does the API change a lot, or remain relatively stable.
    <ul>
      <li><strong>Manual Review</strong> - Regularly check in on an API to see how often things have changed.</li>
      <li><strong>Change Log Feed</strong> - Tune into a change log feed to see how often changes are Ade.</li>
      <li><strong>Sentiment Analysis</strong>   - Some sentiment about the changes to an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
    </ul>
  </li>
  <li><strong>Social Good</strong> - Does the API benefit a local, regional, or wider community.
    <ul>
      <li><strong>Manual Review</strong> - It will take the eye of an analyst to truly understand the social impact of an API.</li>
    </ul>
  </li>
  <li><strong>**Exploitative</strong> - Does the API exploit its users data, or allow others to do so.
    <ul>
      <li><strong>Manual Review</strong> - It will take a regular analyst review to understand whether an API has become exploitative.</li>
      <li><strong>Sentiment Analysis</strong> - Some sentiment about the exploitative nature of an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
    </ul>
  </li>
  <li><strong>Secure</strong> - Does an API adequately secure its resources and those who use it.
    <ul>
      <li><strong>Manual Review</strong> - Regularly check in on an API to see how secure things are.</li>
      <li><strong>Sentiment Analysis</strong> - Some sentiment about the security of an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
      <li><strong>Monitoring Feed / Data</strong> - For some APIs, monitoring could be setup, but will cost resources to be able to do accurately, unless provided by provider.</li>
    </ul>
  </li>
  <li><strong>Privacy</strong> - Does an API respect privacy, and have a strategy for platform privacy.
    <ul>
      <li><strong>Manual Review</strong> - Regularly check in on an API to see how privacy is addressed, and what steps the platform has been taking to address.</li>
      <li><strong>Sentiment Analysis</strong> - Some sentiment about the privacy of an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
    </ul>
  </li>
  <li><strong>Monitoring</strong> - Does a platform actively monitor its platform and allow others as well.
    <ul>
      <li>**Manual Review **- Regularly check in on an API to see how secure things are.</li>
      <li><strong>Sentiment Analysis</strong> - Some sentiment about the security of an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
      <li><strong>Monitoring Feed / Data</strong> - For some APIs, monitoring could be setup, but will cost resources to be able to do accurately, unless provided by provider.</li>
    </ul>
  </li>
  <li><strong>Observability</strong> - Is there visibility into API platform operations, and its processes.
    <ul>
      <li><strong>Manual Review</strong> - It will always take an analyst to understand observability until there are feeds regarding every aspect of operations.</li>
    </ul>
  </li>
  <li><strong>Environment</strong> - What is the environment footprint or impact of API operations.
    <ul>
      <li><strong>Manual Review</strong> - This would take a significant amount of research into where APIs are hosted, and disclosure regarding the environment impact of data centers, and the regions they operate in.</li>
    </ul>
  </li>
  <li><strong>Popular</strong> - Is an API popular, and something that gets a large amount of attention.
    <ul>
      <li><strong>Manual Review</strong> - Analysts can easily provide a review of an API to better understand an APIs popularity.</li>
      <li><strong>Sentiment Analysis</strong> - Some sentiment about the presence of an API could be established from analyzing Twitter, Blogs, and Stack Exchange.</li>
      <li><strong>Twitter Followers</strong>** - The number of Twitter followers for an account dedicated to an API provides some data.</li>
      <li><strong>Twitter Mentions</strong> - Similarly the number of mentions of an API providers Twitter account provides additional data.</li>
      <li><strong>GitHub Followers</strong> - The number of GitHub followers provides another dimension regarding how popular an API is.</li>
      <li><strong>Stack Exchange Mentions</strong> - The question and answer site always provides some interesting insight into which APIs are being used.</li>
      <li><strong>Blog Mentions</strong> - The number of blog posts on top tech blogs, as well as independent blogs provide some insight into popularity.</li>
    </ul>
  </li>
  <li><strong>Value</strong> - What value does an API bring to the table in generalized terms.
    <ul>
      <li><strong>Manual Review **</strong>- The only way to understand the value an API brings to the table is for an analyst to evaluate the resources made available. Maybe some day we’ll be able to do this with more precision, but currently we do not have the vocabulary for describing.</li>
    </ul>
  </li>
</ul>

<p>I am developing a manual questionnaire I can execute against while profiling every API. I have already done this for many APIs, but I’m looking to refine for 2019. I will also be automating wherever I can, leverage other APIs, feeds, and some machine learning to help me augment my heuristic analyst rank with some data driven elements. Some of these will only change when I, or hopefully another analyst reviews them, but some of this will be more dependent on data gathered each month. It will take some time for a ranking system based upon these elements to come into focus, but I’m guessing along the way I”m going to learn a lot, and this list will look very different in twelve months.</p>

<p>Next, I wanted to look at the elements of the rating system itself which I think are essential to the success of an API ranking system based upon the elements above. I’ve seen a number of efforts fail when it comes to indexing and ranking APIs. It is not easy. It is a whole lot of work, without an easy path to monetization like Google established with advertising. Many folks have tried and failed, and I feel like some of these elements will help keep things grounded, and provide more opportunity for success, if not at least sustainability.</p>

<ul>
  <li><strong>YAML Core</strong> - I would define the rating system in YAML.
    <ul>
      <li><strong>Rating Formula</strong> - The rating formula is machine readable and available as YAML, taking everything listed above and automating the application of it across APIs using a standard YAML definition.</li>
      <li><strong>Rating Results</strong> - Publishing a YAML dump of the results of rating for each API provider, also providing a machine readable template for understanding how each API provider is being ranked.</li>
    </ul>
  </li>
  <li><strong>GitHub Base</strong> - Everything would be in a series of repositories.
    <ul>
      <li><strong>GitHub Repo</strong> - A GitHub repository is the unit of compute and storage for the rating.</li>
      <li><strong>Git Management</strong> - I am using GitHub to apply the rating system across all APIs in my search index.</li>
      <li><strong>GitHub API Management</strong> - I am automating the granular editing of the YAML core using the GitHub API.</li>
    </ul>
  </li>
  <li><strong>Observable</strong> - The entire algorithm, process, and results are open.
    <ul>
      <li><strong>Search Transparency</strong> - I will be tracking keyword searches, minus IP and user agent, then publishing the results to GitHub as YAML.</li>
      <li><strong>Minimal Tracking</strong> - There will be minimal tracking of end-users searching and applying the ranking, with tracking being provider focused.</li>
    </ul>
  </li>
  <li><strong>Evolvable</strong> - It would be essential to evolve and adapt over time.
    <ul>
      <li><strong>Semantic Versioned</strong> - The search engine will be semantically versioned, providing a way of understanding it as it evolves.</li>
      <li><strong>YAML</strong> - Everything is defined as YAML which is semantically versioned, so nothing is removed or changed until major releases.</li>
    </ul>
  </li>
  <li><strong>Weighted</strong> - Anyone can weight the questions that matters to them.
    <ul>
      <li><strong>Data Points</strong> - All data points will have a weight applied as a default, but ultimately will allow end-users to define the weights they desire.</li>
      <li><strong>Slider Interface</strong> - Providing end-users with a sliding interface for defining the importance of each data point to them, and apply to the search.</li>
    </ul>
  </li>
  <li><strong>Completeness</strong> - Not all the profiles of APIs will be as complete as others.
    <ul>
      <li><strong>Data Points</strong> - The continual addition and evolution of data points, until we find optimal levels of ranking across industries, for sustained periods of time.</li>
    </ul>
  </li>
  <li><strong>Ephemeral</strong> - Understanding that nothing lasts forever in this world.
    <ul>
      <li><strong>Inactive</strong> - Making sure things that are inactive reflect this state.</li>
      <li><strong>Deprecation</strong> - Always flag something as deprecated, reducing in rank.</li>
      <li><strong>Archiving</strong> - Archive everything that has gone away, keeping indexes pure.</li>
    </ul>
  </li>
  <li><strong>Community</strong> - It should be a collaboration between key entities and individuals.
    <ul>
      <li><strong>GitHub</strong> - Operate the rating system out in the open on GitHub, leveraging the community for evolving.</li>
      <li><strong>Merge Request</strong> - Allow for merge requests on the search index, as well as the ratings being applied.</li>
      <li><strong>Forks</strong> - Allow for the workability of the API search, leveraging ranking as a key dimensions for how things can be forked.</li>
      <li><strong>Contribution</strong> - Allow for community contribution to the index, and the ranking system, establishing partnerships along the way.</li>
    </ul>
  </li>
  <li><strong>Machine Readable</strong> - Able for machines to engage with seamlessly.
    <ul>
      <li><strong>YAML</strong> - Everything is published as YAML to keep things simple and machine readable.</li>
      <li><strong>APIs.json</strong> - Follow a standard for indexing API operations and making them available.</li>
      <li><strong>OpenAPI</strong> - Follow a standard for indexes the APIs, and making them available.</li>
    </ul>
  </li>
  <li><strong>Human Readable</strong> - Kept accessible to anyone wanting to understand.
    <ul>
      <li><strong>HTML</strong> - Provide a simple HTML application for end-users.</li>
      <li><strong>CSS</strong> - Apply a minimalist approach to using CSS.</li>
      <li><strong>JavaScript</strong> - Drive the search and engagement with client-side JavaScript, powered by APIs.</li>
    </ul>
  </li>
</ul>

<p>This provides me with my starter list of elements I think will set the tone for how this API search engine will perform. Ultimately there will be a commercial layer to how the API search and ranking works, but the goal is to be as transparent, observable, and collaborative around how it all works. A kind of observability that does not exist in web search, and definitely doesn’t in anything API search related. I’ll give it to DuckDuckGo, for being the good guys of web search, which I think provides an ethical model to follow, but I want to also be open with the rating system behind, to avoid some of the illness that commonly exists within rating agencies of any kind.</p>

<p>Next stop, will be about turning the rating elements into a YAML questionnaire that I can begin systematically applying to the almost 2,000 APIs I have in my index. With most of it being a manual process, I need to get the base rating details in place, begin asking them, and then version the questionnaire schema as I work my way through all of the APIs. I have enough experience with profiling APIs to know that what questions I ask, how I ask them, and what data I can gather about API will rapidly evolve once I begin trying to satisfy questions again real world APIs. How fast I can apply my API rating system to the APIs I have indexed, as well as quickly turn around and refresh over time will depend on how much time and resources I am able to manifest for this project. Something that will come and go, as this is just a side project for me, to keep me producing fresh content and awareness of the API space.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/09/The-details-of-my-api-rating-formula/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/08/thinking-differently-when-approaching-openapi-diffs-and-considering-how-to-layer-each-potential-change/">Thinking Differently When Approaching OpenAPI Diffs And Considering How To Layer Each Potential Change</a></h3>
        <span class="post-date">08 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-server-cloud1-feed-people.jpg" width="45%" align="right" style="padding: 15px;" />
I have a lot of OpenAPI definitions, covering about 2,000 separate entities. For each entity, I often have multiple OpenAPIs, and I am finding more all the time. One significant challenge I have in all of this centers around establishing a master “truth” OpenAPI, or series of definitive OpenAPIs for each entity. I can never be sure that I have a complete definition of any given API, so I want to keep vacuuming up any OpenAPI, Swagger, Postman, or other artifact I can, and compare it with the “truth” copy” I have on indexed. Perpetually layering the additions and changes I come across while scouring the Internet for signs of API life. This perpetual update of API definitions in my index isn’t easy, and any tool that I develop to assist me will be in need constant refinement and evolution to be able to make sense of the API fragments I’m finding across the web.</p>

<p>There are many nuances of API design, as well as the nuances of how the OpenAPI specification is applied when quantifying the design of an API, making the process of doing a “diff” between two OpenAPI definitions very challenging. Rendering common “diff” tools baked into GitHub, and other solutions ineffective when it comes to understanding the differences between two API definitions that may represent a single API. These are some of the things I’m considering as I’m crafting my own OpenAPI “diff” tooling:</p>

<ul>
  <li><strong>Host</strong> - How the host is stored, defined, and applied across sandbox, production, and other implementations injects challenges.</li>
  <li><strong>Base URL</strong> - How OpenAPI define their base url versus their host will immediately cause problems in how diffs are established.</li>
  <li><strong>Path</strong> - Adding even more instability, many paths will often conflict with host and base URL, providing different fragments that show as differences.</li>
  <li><strong>Verbs</strong> - Next I take account of the verbs available for any path, understanding what the differences are in methods applied.</li>
  <li><strong>Summary</strong> - Summaries are difficult to diff, and almost always have to be evaluated and weighted by a human being.</li>
  <li><strong>Description</strong> -  Descriptions are difficult to diff, and almost always have to be evaluated and weighted by a human being.</li>
  <li><strong>Operation ID</strong> - These are usually autogenerated by tooling, and rarely reflect a provider defined standard, making them worthless in “diff”.</li>
  <li><strong>Query Properties</strong> - Evaluating query parameters individually is essential to a granular level diff between OpenAPI definitions.</li>
  <li><strong>Path Properties</strong> - Evaluating path parameters individually is essential to a granular level diff between OpenAPI definitions.</li>
  <li><strong>Headers</strong> - Evaluating headers individually is essential to a granular level diff between OpenAPI definitions.</li>
  <li><strong>Tags</strong> - Most providers do not tag their APIs, and they are often not included, and rarely provide much value when applying a “diff”.</li>
  <li><strong>**Request Bodies</strong> - Request bodies provide a significant amount of friction for diffs depending on the complexity and design of an API.</li>
  <li><strong>Responses</strong> - Responses often provide an incomplete view of an API, and rarely are robust enough to impact the “diff” view.</li>
  <li><strong>Status Codes</strong> - Status codes should be evaluated on an individual basis, providing a variety of ways to articulate these statuses.</li>
  <li><strong>Content Types</strong> - Content types these days are often application/json, but do provide some opportunities to define unique characteristics.</li>
  <li><strong>Schema Objects</strong> - Schema is often not defined, and rarely used as part of a diff unless OpenAPIs are generated from log, HAR, and other files.</li>
  <li><strong>Schema Properties</strong> - Schema properties are rarely present in OpenAPIs, making them not something that comes  up on the “diff” radar.</li>
  <li><strong>Security Definitions</strong> - Security definitions are the holy grail of automating API indexing, but are rarely present in OpenAPI, and only in Postman Collections.</li>
  <li><strong>References</strong> - The use of $ref, or absence of $ref and doing everything inline poses massive challenges to coherently considering “diff” results.</li>
  <li><strong>Scope</strong> - The size of the OpenAPI snippet being applied as part of a “diff” helps narrow what needs to be considered by a human or machine.</li>
</ul>

<p>This reflects the immediate concerns I have approaching the development of a custom “diff” tool for OpenAPI. First I am just trying to establish a strategy for stripping back the layers of OpenAPI definitions, and established a sort of layered user interface for me to manually accept or reject changes to an OpenAPI. An interface that will also allow me to define a sort of rules vocabulary for increasingly automating the decision making process. I’d love it if eventually the diff tool would show me just a single diff, present me with the change it thinks I should make, and allow me to just agree and move to the next “diff”. I have a lot of work to get things to this point.</p>

<p>Like API search, I feel like API diff is something I have to reduce to its basics, and then fumble my way towards finding an acceptable solution. I don’t feel there is a single “diff” tool for JSON or YAML that will have the eye that I demand for analyzing, presenting, and either manually or automatically merging a diff. Like the other layers of my API search engine, diff is something I need to think through, iterate upon, and repeat until I come up with something that helps me merge “diffs” efficiently across thousands of APIs, and hopefully eventually automates and abstract away the most common differences between the APIs that I am spidering and indexing. Like every other area it is something I’m only working on when I have time, but something I will eventually come out the other end with a usable OpenAPI diff tool, that can help me make sense of all the API definitions I’m bombarded with on a daily basis.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/08/thinking-differently-when-approaching-openapi-diffs-and-considering-how-to-layer-each-potential-change/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/05/why-the-open-data-movement-has-not-delivered-as-expected/">Why The Open Data Movement Has Not Delivered As Expected</a></h3>
        <span class="post-date">05 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/fast-lights-freeway-redes-fast-flux-623x425-internet-numbers.jpg" width="45%" align="right" style="padding: 15px;" />
I was having a discussion with my friends working on API policy in Europe about API discovery, and the topic of failed open data portals came up. Something that is a regular recurring undercurrent I have to navigate in the world of APIs. Open data is a subset of the API movement, and something I have first-hand experience in, building many open data portals, contributing to city, county, state, and federal open data efforts, and most notably riding the open data wave into the White House and working on open data efforts for the Obama administration.</p>

<p>Today, there are plenty of open data portals. The growth in the number of portals hasn’t decreased, but I’d say the popularity, utility, and publicity around open data efforts has not lived up to the hype. Why is this? I think there are many dimensions to this discussion, and few clear answers when it comes to peeling back the layers of this onion, something that always makes me tear up.</p>

<ul>
  <li><strong>Nothing There To Begin With</strong> - Open data was never a thing, and never will be a thing. It was fabricated as part of an early wave of the web, and really never got traction because most people do not care about data, let alone it being open and freely available.</li>
  <li><strong>It Was Just Meant To Be A Land Grab</strong> - The whole open data thing wasn’t about open data for all, it was meant to be open for business for a few, and they have managed to extract the value they needed, enrich their own datasets, and have moved on to greener pastures (AI / ML).</li>
  <li><strong>No Investment In Data Providers</strong> - One f the inherent flaws of the libertarian led vision of web technology is that government is bad, so don’t support them with taxes. Of course, when they open up data sets that is goo for us, but supporting them in covering compute, storage, bandwidth, and data refinement or gathering is bad, resulting in many going away or stagnating.</li>
  <li><strong>It Was All Just Hype From Tech Sector</strong> - The hype about open data outweighs the benefits and realities on the ground, and ultimately hurt the movement with unrealistic expectations, setting efforts back many years, and are now only beginning to recover now that the vulture capitalists are on to other things.</li>
  <li><strong>Open Data Is Not Sexy</strong> - Open data is not easy to discover, define, refine, manage, and maintain as something valuable. Most government, institutions, and other organizations do have the resources to do properly, and only the most attractive of uses have the resources to pay people to do the work properly, incentivizing commercial offerings over the open, and underfunded offerings.</li>
  <li><strong>Open Data Is Alive and Well</strong> - Open data is doing just fine, and is actually doing better, now that the spotlight is off of them. There will be many  efforts that go unnoticed, unfunded, and fall into disrepair, but there will also be many fruitful open data offerings out there that will benefit communities, and the public at large, along with many commercial offerings.</li>
  <li><strong>Open Data Will Never Be VC Big</strong> - Maybe open data share the spotlight because it just doesn’t have the VC level revenue that investors and entrepreneurs are looking for. If it enriches their core data sets, and can be used to trying their machine learning models, it has value as a raw material, but as something worth shining a light on, open data just doesn’t rise to the scope needed to be a “product” all by itself.</li>
</ul>

<p>My prognosis on why open data never has quite “made it”, is probably a combination of all of these things. There is a lot of value present in open data as a raw material, but a fundamental aspect of why data is “open”, is so that entrepreneurs can acquire it for free. They aren’t interested in supporting city, county, state, and federal data stewards, and helping them be successful. They just want it mandated that it is publicly available for harvesting as a raw material, for use in the technology supply chain. Open data primarily was about getting waves of open data enthusiasts to do the heavy lifting when it came to identifying where the most value raw data sources exist.</p>

<p>I feel pretty strong that we were all used to initiate a movement where government and institutions opened up their digital resources, right as this latest wave of information economy was peaking. Triggering institutions, organizations, and government agencies to bare fruit, that could be picked by technology companies, and used to enrich their proprietary datasets, and machine learning models. Open doesn’t mean democracy, it mostly means for business. This is the genius of the Internet evolution, is that it gets us all working in the service of opening things up for the “community”. Democratizing everything. Then once everything is on the table, companies grab what they want, and show very little interest in giving anything back to the movement. I know I have fallen for several waves of this ver the last decade.</p>

<p>I think open data has value. I think community-driven, standardized sets of data should continue to be invested in. I think we should get better at discovery mechanisms involving how we find data, and how we enable our data to be found. However, I think we should also recognize that there are plenty of capitalists who will see what we produce as a valuable raw resource, and something they want to get their hands on. Also, more importantly, that these capitalists are not in the businesses of ensuring this supply of raw resource continues to exist in the future. Like we’ve seen with the environment, these companies do not care about the impact their data mining has on the organizations, institutions, government agencies, and communities that produced them, or will be impacted when efforts go unfunded, and unsupported. Protecting our valuable community resources from these realities will not be easy as the endless march of technology continues.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/05/why-the-open-data-movement-has-not-delivered-as-expected/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/03/api-interoperatibility-is-a-myth/">API Interoperability is a Myth</a></h3>
        <span class="post-date">03 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/san-francisco-city-bridge-sf-city-bridge-copper-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
There are a number of concepts we cling to in the world of APIs. I’ve been guilting of inventing, popularizing, and spreading many myths in my almost decade as the API Evangelist. One of them that I’d like to debunk and be more realistic about is when it comes to API interoperability. When you are focused on just the technology of APIs, as well as maybe the low-level business of APIs, you are an API interoperability believer. Of course everyone wants API interoperability, and that all APIs should work seamlessly together. However, if you at all begin operating at the higher levels of the business of APIs, and spend any amount of time studying the politics of why and how we do APIs at scale, you will understand that API interoperability is a myth.</p>

<p>This reality is one of the reasons us technologists who possess just a low-level understanding of how the business behind our tech operation, are such perfect tools for the higher level business thinkers, and people who successfully operate and manipulate at the higher levels of industries, or even at the policy level. We are willing to believe in API interoperability, and work to convince our peers that it is a thing, and we all work to expose, and open up the spigots across our companies, organizations, institutions, and government agencies. Standardized APIs and schema that play nicely with each other are valuable, but only within certain phases of a companies growth, or as part of a myth-information campaign to convince the markets that a company is a good corporate citizen. However, once a company achieves dominance, or the winds change around particular industry trends, most companies just want to ensure that all roads lead towards their profitability.</p>

<p>Believing in API interoperability without a long term strategy means you are opening up your company to value extraction by your competitors. I don’t care how good your API management is, if your API makes it frictionless to integrate with because you use a standard format, it just means that the automated value harvesters of companies will find it frictionless to get at what you are serving, and more easily weaponize and monetize your digital resources. It pains me to say this, but it is the reality. If you are in the business of making your API easier to connect with, you are in the business of making it easier for your competitors to extract value from you. Does this mean we shouldn’t do APIs, and make them interoperable? No, but it does mean that we shouldn’t be ignorant of the cutthroat, exploitative, and aggressive nature of businesses that operate within our industries. Does it mean we shouldn’t invest in standards? No, but we should be aware that not every company sitting at the table shares the same interests as us, and could be playing a longer game that involves lock-in, proprietary nuances, or even slowing the standards movement in their favor.</p>

<p>I think that storage APIs are a great example of this. In the early days of cloud storage APIs, I remember everyone saying they were AWS S3 compatible—even Google and Microsoft highlighted this. However, as things have progressed, everyone adds their own tweaks, changes, and nuances that make it much harder to get your terabytes of data off their platform. It was easy to get it in, and keep it synced across your providers, but eventually the polarities change, and all roads lead to lock-in, and are not in the service of interoperability. This is just businesses. I’m not condoning it, I am only repeating what my entrepreneurial friends tell me. If you make it easy for your customers to use other services, you are eroding their loyalty to your brand, and eventually they will leave. So you have to make it harder for them over time. Just incrementally. Forget to grease the door hinges. Change the way the doorknob turns. Make the door narrower. Stop following the international or local standards for how you design a door, call it innovation, and reduce the ways in which your customers can easily get out the door.</p>

<p>I call this the Hotel California business model. You can check-in, but you can never leave. Wrap it all in a catchy tune, even call yourself a hotel, but in reality you’ve gotten hooked a technological myth, and you will never actually be able to ever find the door. Anyways, c’mon, I fucking hate the Eagles, don’t we just have some Credence we could play? Anyways, I got off track. Nobody, but us low-level delusional developers believe in API interoperability. The executives don’t give a shit about it. Unless it supports the latest myth-information campaign. In the long run, nobody wants their APIs to work together, we all just want EVERYONE to use OUR APIs! Sure, we also want to be seen as working together on standards groups, and that our APIs are the the standard EVERYONE should follow, ensuring interoperability with us at the center. But, nobody truly believes in API interoperability. If you do, I recommend you do some soul searching regarding where you exist in the food chain. I’m guessing you are a lower level pawn, doing the work of the puppet master in your industry. This is why you won’t find me on many standards bodies, or me blindly pushing interoperability at scale. It doesn’t exist. It isn’t real. Let’s get to work on more meaningful policy level things that will help shape the industry.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/03/api-interoperatibility-is-a-myth/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/02/your-api-and-schame-is-that-complex-because-you-have-not-done-the-hard-work-to-simplify/">Your API and Schema Is That Complex Because You Have Not Done The Hard Work To Simplify</a></h3>
        <span class="post-date">02 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/machine-road-machine-road-blue-circuit-3.jpg" width="45%" align="right" style="padding: 15px;" />
I find myself looking at a number of my more complex API designs, and saying to myself, “this isn’t complicated because it is hard, it is complicated because I did not spend the time required to simplify it appropriately”. There are many factors contributing to this reality, but I find that more often than not it is because I’m over-engineering something, and I am caught up in the moment focusing on a purely computation approach, and not considering the wider human, business, and other less binary aspects of delivering APIs.</p>

<p>While I am definitely my own worst enemy in many API deliver scenarios, I’d say there are a wide range of factors that are influencing how well, or poorly that I design my API resources, with just a handful of them being:</p>

<ul>
  <li><strong>Domain</strong> - I just do not have the domain knowledge required to get the job done properly.</li>
  <li><strong>Consumer</strong> - I just do not have the knowledge I need of my end consumers to do things right.</li>
  <li><strong>Bandwidth</strong> - I just do not have the breathing room to properly sit down and make it happen.</li>
  <li><strong>Narcissism</strong> - I am the best at this, I know what is needed, and I deem this complexity necessary.</li>
  <li><strong>Lazy</strong> - I am just too damn lazy to actually dig in and get this done properly in the first place.</li>
  <li><strong>Caring</strong> - I just do not give a shit enough to actually go the extra distance with API design.</li>
  <li><strong>Dumb</strong> - This API is dumb, and I really should not be developing it in the first place.</li>
</ul>

<p>These are just a few of the reasons why I settle for complexity over simplicity in my API designs. It isn’t right. However, it seems to be a repeating pattern in some of my work. It is something that I should be exploring more. For me to understand why my work isn’t always of highest quality possible I need to explore each of these areas and understand where I can make improvements, and which areas I cannot. Of course I want to improve in my work, and reach new heights with my career, but I can’t help be dogged by imperfections that seem out of my control…or are they?</p>

<p>I have witnessed API simplicity. APIs that do powerful and seemingly complicated things, but in an easy and distilled manner. I know that it is possible to do, but I can’t help but feel that 90% of my API designs fall short of this reality. Some get very close, while others look like amateur hour. One thing is clear. If I’m going to deliver high quality simple and intuitive APIs, I’m going to have to work very hard at it. No matter how much experience I have, I can only improve the process so much, and there will always be a significant amount of investment required to take things to the next level.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/02/your-api-and-schame-is-that-complex-because-you-have-not-done-the-hard-work-to-simplify/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/01/the-basics-of-my-api-ratings-formula/">The Basics of My API Rating Formula</a></h3>
        <span class="post-date">01 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-square-supreme-court-judgement.jpg" width="45%" align="right" style="padding: 15px;" />
I have been working on various approaches to rating APIs since about 2012. I have different types of algorithms, even having invested in operating one from about 2013 through 2016, which I used to rank my daily intake of API news. Helping me define what the cream on top of each industry being impacted by APIs, while also not losing site of interesting newcomers to the space. I have also had numerous companies and VCs approach me about establishing a formal API rating system—many of whom concluded they could do fairly easily and went off to try, then failed, and gave up. Rating the quality of APIs is subjective and very hard.</p>

<p>When it comes to rating APIs I have a number of algorithms to help me, but I wanted to step back and think of it from a more simpler human vantage point, and after establishing a new overall relationship with the API industry. What elements do I think should exist within a rating system for APIs:</p>

<ul>
  <li><strong>Active / Inactive</strong> - APIs that have no sign of life need a lower rating.</li>
  <li><strong>Free / Paid</strong> - What something costs impacts our decision to use or not.</li>
  <li><strong>Openness</strong> - Is an API available to everyone, or is a private thing.</li>
  <li><strong>Reliability</strong> - Can you depend on the API being up and available.</li>
  <li><strong>Fast Changing</strong> - Does the API change a lot, or remain relatively stable.</li>
  <li><strong>Social Good</strong> - Does the API benefit a local, regional, or wider community.</li>
  <li><strong>Exploitative</strong> - Does the API exploit its users data, or allow others to do so.</li>
  <li><strong>Secure</strong> - Does an API adequately secure its resources and those who use it.</li>
  <li><strong>Privacy</strong> - Does an API respect privacy, and have a strategy for platform privacy.</li>
  <li><strong>Monitoring</strong> - Does a platform actively monitor its platform and allow others as well.</li>
  <li><strong>Observability</strong> - Is there visibility into API platform operations, and its processes.</li>
  <li><strong>Environment</strong> - What is the environment footprint or impact of API operations.</li>
  <li><strong>Popular</strong> - Is an API popular, and something that gets a large amount of attention.</li>
  <li><strong>Value</strong> - What value does an API bring to the table in generalized terms.</li>
</ul>

<p>These are just a handful of the most relevant data points I’d rank APIs on. Using terms that almost anyone can understand. You might not fully understand the technical details of what an API delivers, but you should be able to walk through these overall concepts that will impact your company, organization, institution, or government agency when putting an API to work. Now the more difficult questions around this API rating system, is how do you make it happen. Gathering data to satisfy all of these areas is easier said than done.</p>

<p>Getting the answer to some of these question will be fairly easy, and we can come up with some low tech ways to handle. However, some of them are near impossible to satisfy, let alone do it continually over time. It isn’t easy to gather the data needed to answer these questions. In my opinion no single entity can deliver what is needed, and it will ultimately need to be a community thing if we are going to provide any satisfactory answer to these API rating questions, regularly satisfy them on a regular schedule, and then honestly acknowledge when an API goes dormant, or away altogether. To properly do this, it would have to be done out in the open, and a few things I’d consider introducing would be:</p>

<ul>
  <li><strong>YAML Core</strong> - I would define the rating system in YAML.</li>
  <li><strong>YAML Store</strong> - I would store all data gathered as YAML.</li>
  <li><strong>GitHub Base</strong> - Everything would be in a series of repositories.</li>
  <li><strong>Observable</strong> - The entire algorithm, process, and results are open.</li>
  <li><strong>Evolvable</strong> - It would be essential to evolve and adapt over time.</li>
  <li><strong>Weighted</strong> - Anyone can weight the questions that matters to them.</li>
  <li><strong>Completeness</strong> - Not all the profiles of APIs will be as complete as others.</li>
  <li><strong>Ephemeral</strong> - Understanding that nothing lasts forever in this world.</li>
  <li><strong>Collaborative</strong> - It should be a collaboration between key entities and individuals.</li>
  <li><strong>Machine Readable</strong> - Able for machines to engage with seamlessly.</li>
  <li><strong>Human Readable</strong> - Kept accessible to anyone wanting to understand.</li>
</ul>

<p>I will stop there. I have other criteria I’d like to consider when defining a ranking system. Specifically, a public ranking system, for public APIs. Actually, I’d consider a company, organizations, institution, and government agency ranking system with an emphasis on APIs. Do they do APIs or not? If they do, how many of the questions can we answer pretty easily, with as few resources as possible, while being able to reliably measure using these data points on into the future. It is something we need. It is something that will be very difficult to setup, taking a significant amount of investment over time. It will also rely on the contribute of other entities and individuals. It is something that won’t be easy to make happen. That shouldn’t stop us from doing it.</p>

<p>That is the basics of my API rating formula. Version 2019. This is NOT an idea for a startup. There is revenue to be generated here, but not if approached through the entrepreneurial playbook. It will fail. I’ve seen it happen over and over. This is a request for the right entities and individuals to come together and make it happen. It is dumb that there is no way of understanding which APIs are good or bad. It is also dumb that there is no healthy and active API search engine after APIs having gone so mainstream—another sign of the ineffectiveness of doing not just API rating, but API discovery as a venture backed startup. Sorry, there are just some infrastructural things we’ll all need to invest in together to make this all work at scale. Otherwise we are going to just end up with a chaotic, unreliable network of API-driven services behind our applications. If you’d like to talk API ratings with me, drop me an email at info@apievangelist.com, or tweet at @apievangelist.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/01/the-basics-of-my-api-ratings-formula/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/07/01/the-complexity-of-api-discovery/">The Complexity of API Discovery</a></h3>
        <span class="post-date">01 Jul 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-containership-copper-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
I can’t get API discovery out of my mind. Partly because I am investing significant cycles in this area at work, but it is also something have been thinking about for so long, that it is difficult to move on. It remains one of the most complex, challenging, and un-addressed aspects of the way the web is working (or not working) online today. I feel pretty strongly that there hasn’t been investment in the area of API discovery because most technology companies providing and consuming APIs prefer things be un-discoverable, for a variety of conscious and un-conscious reasons behind these belief systems. </p>

<h3 id="what-api-discovery-means-depends-on-who-you-are">What API Discovery Means? Depends On Who You Are…</h3>
<p>One of the reasons that API discovery does not evolve in any significant ways is because there is not any real clarity on what API discovery is. Depending on who you are, and what your role in the technology sector is, you’ll define API discovery in a variety of ways. There are a handful of key actors that contribute to the complexity of defining, and optimizing in the area of API discovery.
 </p>
<ul>
  <li><strong>Provider</strong> - As an API provider, being able to discover your APIs, informs your operations regarding what your capabilities are, building a wider awareness regarding what a company, organization, institution, or government agency does, helping eliminate inefficiencies, and allows for more meaning decisions to be made at run-time across operations.</li>
  <li><strong>Consumer</strong> - What you need as an internal consumer of APIs, or maybe a partner, or 3rd party developer will significantly shift the conversation around what API discovery means, and how it needs to be “solved”. There is another significant dimension to this discussion, separating human from other system consumption, further splintering the discussion around what API discovery is when you are a consumer of APIs.</li>
  <li><strong>Analyst</strong> - As an analyst for specific industries, or technology in general, need to understand the industries they are watching, and how API tooling is being applied, helping them develop an awareness of what is happening, and understand what the future might hold.</li>
  <li><strong>Investor</strong> - A small number of investors are in tune with APIs, and even grasp what API discovery means to their portfolio, and the industries they are investing in, generally being unaware of how API discovery will set the tone for how markets behave–providing the nutrients (or lack of) markets need to understand what is happening across industries.</li>
  <li><strong>Journalist</strong> - Most journalists grasp the importance of Facebook and Twitter, but only a small percentage understand what APIs are, and how ubiquitous they are, and the benefits they bring to the table when it comes to helping them in their investigations, and research, let alone how it can benefit them in their work when it comes to syndication and exposure for their work–making API discovery pretty critical to what they do.</li>
  <li><strong>University</strong> - I am seeing more universities depending on accessible APIs when it comes to research, and an increase in the development of API related curriculum–just as important, I am also seeing the increased development of open source API tooling out of university environments.</li>
  <li><strong>Government</strong> - APIs will play an increasing role in regulation, taxation, and government funded / implemented research, making API discovery key to finding the data they need, and being able to have their finger on the pulse of what citizens and businesses are up to on any given week.</li>
  <li><strong>End-User</strong> - Last, but definitely not least, the end-user should b e concerned with API discovery, and using it as a low water mark for where they should be doing business, and requiring that the platforms they use have APIs, and have their best interests in mind when allowing for 3rd party access to their data.</li>
</ul>

<h3 id="how-apis-are-discovered">How APIs Are Discovered?</h3>
<p>Across these different views of the API discovery landscape, there are a variety of ways in which APIs are discovered, and made discoverable. Providing some formal, and some not so formal ways to define the the API landscape, and develop an awareness of the API ecosystems that have risen up within different industries, within institutions and government agencies. These are the ways I am focused on finding APIs, and making APIs findable, inside and outside the firewall.</p>

<p>Our motivations for finding APIs inside or outside the firewall are not always in sync with our motivations for having our APIs be found. This affects our view of the landscape when it comes to how hard API discovery is, and what the possible solutions for it will be. I find people’s view on API discovery to be very relative to their view of the landscape, and very few people in the API sector travel widely enough, exchange ideas externally enough, and lift themselves up high enough to be able to understand API discovery well enough to provide the right tools and services to move the conversation forward.</p>

<h3 id="within-the-firewall">Within the Firewall</h3>
<p>API discovery with the firewall is a real struggle. Most companies I know do not know where all of their APIs are. There is no single up to date truth of where each API is, what it does, let alone the machine readable details of what it delivers. These are a few of the ways in which I have seen groups tackle API discovery within the firewall: </p>

<ul>
  <li><strong>Directories</strong> - Many employ a catalog, directory, or database of APIs, micro services, and other relevant solutions.</li>
  <li><strong>Git Repositories</strong> - Git within the enterprise is a very viable way to manage a large volume of artifacts you can use for discovery.</li>
  <li><strong>Word of Mouth</strong> - Talking to people is always a great way to understand what APIs exist across the enterprise landscape.</li>
  <li><strong>Documentation</strong> - The documentation for APIs often become the focal point of API discovery because it can be searched.</li>
  <li><strong>Log Files</strong> - Harvest what is actually coming across the wire, parse APIs that are in use, and documenting them in some way.</li>
</ul>

<p>The biggest challenge with API discovery within the firewall is having dedicated resources to keep up with the discovery, documenting, while also keeping catalogs, repositories, documentation, and other key sources of API discovery information up to date. In my experience, rarely do teams ever get the budget to properly invest in API discovery, with things often done as part of skunk works, or in every day operations—as teams can–which is never enough.</p>

<h3 id="outside-the-firewall">Outside the Firewall</h3>
<p>This is the aspect of API discovery that gets the most attention when it comes to API discovery. These are the API rock stars, directors, marketplaces, and API showcasing that occurs across tech blogs. API discovery outside the firewall has access to far more tools and services to leverage when getting the word out, or helping you find what you are looking for. The challenge becomes, like most other things on the open web, how do you cut through the noise, and get your APIs found, or find the APIs you are looking for. </p>

<ul>
  <li><strong>Directories</strong> - You use some of the existing API directories out there. Providing you access to a small subsection of the APIs that these operators can find, and manually publish to their API catalogs. There really isn’t a single source of truth when it comes to API directories, but there are some that have been around longer than others.</li>
  <li><strong>Marketplaces</strong> - There have been numerous waves of investment into API marketplaces, trying to centralize the discovery and integration with APIs, hoping to simplify APIs enough that consumers use you as their doorway to the API world—giving the API marketplace provider a unique look at how APIs are consumed.</li>
  <li><strong>Documentation</strong> - Public API documentation is how your APIs will be found using Google, which is the number one way people are going to find your API—using a Google search. I’m surprised that Google hasn’t tackled the issue of API discovery already, but I’m guessing they haven’t deemed it valuable enough to tackle, and will most likely swoop in and take dominate once some smaller providers plant the seeds.</li>
  <li><strong>Definitions</strong> - API discovery has gotten easier, and more robust with the introduction of API definitions like Swagger, OpenAPI, API Blueprint, RAML, Postman collections and other machine readable formats. Going beyond just static or even dynamic API documentation, and providing a machine readable artifact that can be indexed and used to drive API search.</li>
  <li><strong>Domains</strong> - You can drive a lot of interesting API discovery using domains, and building indexes of different types of domains, then conduct several types of searches to see if they have any APIs. Using search engine APIs, Twitter, Github, and other social media APIs to find APIs across the landscape—using domains as the anchor for refining and making API discovery queries more precise.</li>
  <li><strong>Scraping</strong> - If you have the URL for an companies, organization, institution, or government agencies API documentation page you can also scrape that page, or pages for more information about how any API operations, and what it does—adding to the index of APIs to be search against.</li>
  <li><strong>Search Engines</strong> - While Google doesn’t have a good API anymore, Bing and DuckDuckGo do.It is easy to build up an index of queries to search Bing to uncover potential domains, documentation, definitions, and other artifacts to enrich an API discovery index. With the right key phrase glossary, you can quickly automate a pretty comprehensive search for new APIs.</li>
  <li><strong>GitHub</strong> - The social coding platform is a rich one of API related data. Similar to search engines you can easy build a search query vocabulary to uncover a number of domains, documentation, definitions, and other artifacts to enrich an API discovery index.</li>
  <li><strong>Integrated Development Environment (IDE)</strong> - The IDE is an untapped market when it comes to helping developers find APIs, and to help API providers reach developers. Microsoft has been increasing API discovery features, while also being extended with plugins by the community. There is no universal API search engine baked into the top IDEs, a definite missed opportunity.</li>
  <li><strong>News</strong> - It is pretty easy to harvest press releases, blog posts, and other news sources and use them as rich sources of information for new APIs. Helping seed a list of potential domains to look for documentation and other API artifacts. Publishing a press release, or posting to their blog is the most common way that API providers get the word out, unfortunately it tends to be the only thing they do.</li>
  <li><strong>Tweets</strong> - Twitter is also a rich source of information about APIs, with a variety of accounts, hashtags, and other ways to make queries for new APIs more precise. Using the social media platform as.a way of tuning into potential new APIs, as well as the activity around existing APIs in the index.</li>
  <li><strong>LinkedIn</strong> - More business, institutions, and government entities are talking about their APIs on LinkedIn, publishing posts, job listings, and other API related goings on. Making it a pretty rich way to find new APIs, and companies who are embarking, or making their way along their API journey.</li>
  <li><strong>Security Alerts</strong> - Sadly, security alerts is one way I learn about companies and their APIs—when they become un-secure. Providing information about API providers who operate in the shadows, as well as more information to index when actually rating APIs in the index, but that is another story.</li>
</ul>

<p>Even once you discover the APIs you are looking for, often times more context is required, and you may or may not have the time or expertise to assess what an API delivers, and what it will take to get up and running with an API.</p>

<ul>
  <li><strong>Documentation</strong> - Where the documentation resides for the API.</li>
  <li><strong>Signup</strong> - Where a user can signup to use an API.</li>
  <li><strong>Pricing</strong> - What is the pricing for using an API.</li>
  <li><strong>Support</strong> - Where do you get support if you need help.</li>
  <li><strong>Terms of Service</strong> - Where do I find the legalize behind AP operations.</li>
</ul>

<p>These are just five of the most common questions APIs consumers are going to ask when they are looking at an API, and would benefit from direct links to these essential building blocks as part of any API search results.  I have over a hundred questions that I like to ask of an API as I’m reviewing, which all reflect what a potential API consumer will be asking when they come across an API out in the wild.</p>

<h3 id="four-primary-dimensions-of-complexity">Four Primary Dimensions Of Complexity</h3>
<p>I’d say that these are the four main dimensions of complexity I see out there when it comes to API discovery, which makes it really hard to provide a single API discovery solution, and why there hasn’t been more investment in this area. It is difficult to make sense of APIs, and what people are looking for. It is hard to get all API providers on the same page when it comes to investing in API discovery as part of their regular operations. API discovery is something I’ll keep investing in, but it is something that will need wider investment from the community, as well as some bigger players to step up and help move the conversation forward.</p>

<p>Other than API marketplaces, and the proliferation of API definitions, I haven’t seen any big movements in the API discovery conversation. We still have ProgrammableWeb. We still have Google. Not much more. With the number of APIs growing, this is only going to become more of a pain point. I’m interested in investing in API discovery not because I want to help everyone find APIs, or have their APIs found. Im more interested in shining a light on what is going on. I am looking to understand the spread of APIs across the digital landscape, and better see where they are pushing into our physical worlds. My primary objective is not to make sure all APIs are found so they can be used. My primary objects is to make sure all APIs are found so we have some observability into how the machine works.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/07/01/the-complexity-of-api-discovery/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/25/why-schema-org-does-not-see-more-adoption-across-the-api-landscape/">Why Schema.org Does Not See More Adoption Across The API Landscape</a></h3>
        <span class="post-date">25 Jun 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/machine-road-machine-road-blue-circuit-3.jpg" width="45%" align="right" style="padding: 15px;" />
I’m a big fan of Schema.org. A while back I generated an OpenAPI 2.0 (fka Swagger) definition for each one and published to GitHub. I’m currently cleaning up the project, publishing them as OpenAPI 3.0 files, and relaunching the site around it. As I was doing this work, I found myself thinking more about why Schema.org isn’t the goto schema solution for all API providers. It is a challenge that is multi-layered like an onion, and probably just as stinky, and will no doubt leave you crying.</p>

<p>First, I think tooling makes a big difference when it comes to why API providers haven’t adopted Schema.org by default across their APIs. If more API design and development tooling would allow for the creation of new APIs using Schema.org defined schema, I think you’d see a serious uptick in the standardization of APIs that use Schema.org. In my experience, I have found that people are mostly lazy, and aren’t overly concerned with doing APIs right, they are just looking to get them delivered to meet specifications. If we provide them with tooling that gets the API delivered to specifications, but also in a standardized, they are doing to do it.</p>

<p>Second, I think most API providers don’t have the time and bandwidth to think of the big picture like using standardized schema for all of their resources. Most people are under pressure to more with less, and standards is something that can be easily lost in the shuffle when you are just looking to satisfy the man. It takes extra effort and space to realize common standards as part of your overall API design.  This is a luxury most companies, organizations, and government agencies can not afford, resulting in many ad hoc APIs defined in isolation.</p>

<p>Third, I think some companies just do not care about interoperability. Resulting in them being lazy, or not making it a priority as stated in the first and second points. Most API providers are just concerned with you using their API, or checking the box that they have an API. They do not connect the dots between standardization and it being easier for consumers to put their resources to work. Many platforms who are providing APIs are more interested in lock-in, providing proprietary SDKs and tooling on top of their API. Selling them on the benefits of interoperable open source SDKs and tooling just falls on deaf ears—leaving most API providers to perpetually reinvent the wheel when there is an existing well defined one within reach.</p>

<p>I wish ore API folks cared about Schema.org. I wish I had the luxury of using in more of my own work. If it is up to me, I will always adopt Schema.org for my core API designs, but unfortunately I’m not always the one in charge of what gets decided. I will continue to invest in OpenAPI definitions for all of the Schema.org defined schema. This allows me to have within reach when I’m getting ready to define a new API. If Schema.org ready API definitions are in a neat stack on my desk, the likelihood that I’m going to put to work in the API tooling I’m developing, and actually as the base for an API I’m delivering, increases significantly. Helping me standardize my API vocabulary to something that reaches beyond the tractor beam of daily API bubble.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/25/why-schema-org-does-not-see-more-adoption-across-the-api-landscape/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/24/avoiding-complexity-and-ust-deploying-yaml-json-csv-apis-using-github-or-gitlab/">Avoiding Complexity and Just Deploying YAML, JSON, and CSV APIs Using GitHub or GitLab</a></h3>
        <span class="post-date">24 Jun 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/meadowbutterfly-meadow-butterfly-internet-numbers.jpg" width="45%" align="right" style="padding: 15px;" />
I find that a significant portion of I should be doing when defining, designing, developing, and delivering an API is all of avoiding complexity. Every step away along the API journey I am faced with opportunities to introduce complexity, forcing me to constantly question and say no to architectural design decisions. Even after crafting some pretty crafty APIs in my day, I keep coming back to JSON or YAML within Git, as the most sensible API architectural decision I can make.</p>

<p>Git, with JSON and YAML stored within a repository, fronted with a Jekyll front-end does much of what I need. The challenge with selling this concept to others is that it is a static publish approach to APIs, instead of a dynamic pull of relevant data. This approach isn’t for every API solution, I’m not in the business selling one API solution to solve all of our problems. However, for many of the API uses I’m building for, a static Git-driven approach to publishing machine readable JSON or YAML data is a perfect low cost, low tech solution to delivering APIs.</p>

<p>A Git repository hosted on GitHub or GitLab will store a significant amount of JSON, YAML, or CSV data. Something you can easily shard across multiple repositories within an organization / group, as well as across many repositories within many organization / groups. Both GitHub and GitLab offer free solutions, essentially letting you publish as many repositories as you want. As I said earlier, this is not a solution to all API needs, but when I’m looking to introduce some constraints to keep things low cost, simple, and easy to use and manage—a Git-driven API is definitely worth considering. However, going static for your API will force you to think about how you automate the lifecycle of your data, content, and other resources.</p>

<p>The easiest way to manage JSON, CSV, or YAML data you have on GitHub or GitLab is to use the GitHub or GitLab API, allowing you to update individual JSON, CSV, or YAML files in real-time. If you want to do it in batch process by checking out the repository, making all the changes you want and committing back as a single Git commit using the command line—I’ve automated a number of these to reduce the number of API calls I’m making. If you want to put in an editorial layer you can require submission via pull / merge request, requiring there be multiple eyes on each update to the data behind a static API. It is an imperative, and a declarative API, with an open source approval workflow by default—all for free.</p>

<p>Once you have your data in the Git repository you can make it available using the RAW links provided by GitHub or GitLab. However, I prefer to publish a Jekyll front-end, which can act as the portal landing page for the site, but then you can also manually or dynamically create neat paths that route users to your data using sensible URLs—the best part is you can add a cname and publish your own domain. Making your API accessible to humans, while also providing intuitive, easy to follow URLs to the static data that has been published using the GitHub or GitLab API, or the underlying Git infrastructure to do in bulk.</p>

<p>This is the cheapest, most productive way to deliver simple data and content APIs. The biggest challenges are that you have to begin thinking a little differently about how you manage your data. You have to move from a pull to a push way of delivering data, and embrace the existing CI/CD way of doing things embraced by both GitHub and GitLab. For me, using Git to deliver APIs provides a poor mans way to not just deliver an API, but also ensure it is secure, performant, and something I can automate the management of using existing tools developers are depending on. Over the last couple of years I’ve pushed the limits of this approach by publishing thousands of OpenAPI-driven API discovery portals, and it is something I’m going to be refining and using as the default layer for delivering simple APIs that allow me to avoid unnecessary complexity.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/24/avoiding-complexity-and-ust-deploying-yaml-json-csv-apis-using-github-or-gitlab/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/19/organizing-my-apis-using-openapi-tags/">Organizing My APIs Using OpenAPI Tags</a></h3>
        <span class="post-date">19 Jun 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/aws-s3-stories-containership-copper-circuit.jpg" width="45%" align="right" style="padding: 15px;" />
I like my OpenAPI tags. Honestly, I like tags in general. Almost every API resource I design ends up having some sort of tagging layer. Too help me organize my world, I have a centralized tagging vocabulary that I use across my JSON Schema, OpenAPI, and AsyncAPI, to help me group, organize, filter, publish, and maintain my catalog of API and schema resources.</p>

<p>The <a href="https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#tagObject">tag object for the OpenAPI specification</a> is pretty basic, allowing you to add tags for an entire API contract, as well as apply them to each individual API method. Tooling, such as API documentation uses these tags to group your API resources, allowing you to break down your resources into logical bounded contexts. It is a pretty basic way of defining tags, that can go a long ways depending on how creative you want to get. I am extending tags with an OpenAPI vendor extension, but I also see that there is <a href="https://github.com/OAI/OpenAPI-Specification/issues/1367">a issue submitted suggesting they move the specification forward by allowing for the nesting of tags</a>–potentially taking OpenAPI tagging to the next level.</p>

<p>I’m allowing for a handful of extensions to the OpenAPI specification to accomplish the following:</p>

<ul>
  <li><strong>Tag Grouping</strong> - Help me nest, and build multiple tiers of tags for organization APIs.</li>
  <li><strong>Tag Sorting</strong> - Allowing me to define a sort order that goes beyond an alphabetical list.</li>
</ul>

<p>I am building listing, reporting, and other management tools based up OpenAPI tagging to help me in the following areas:</p>

<ul>
  <li><strong>Tag Usage</strong> - Reporting how many resources are available for each tag, and tag group.</li>
  <li><strong>Tag Cleanup</strong> - Helping me de-dupe, rename, deal with plural challenges, etc.</li>
  <li><strong>Tag Translations</strong> - Translating old tags into new tags, helping keep things meaningful.</li>
  <li><strong>Tag Clouds</strong> - Generating D3.js tag clouds from the tags applied to API resources.</li>
  <li><strong>Packages</strong> - Deployment of NPM packages based upon different bounded contexts defined by tags.</li>
</ul>

<p>I am applying tags to the following specifications, stretching my OpenAPI tagging approach to be more about a universal way to organize all my resources:</p>

<ul>
  <li><strong>JSON Schema</strong> - All schema objects have tags to keep organized.</li>
  <li><strong>OpenAPI</strong> - Each API method have tags, for easy grouping.</li>
  <li><strong>AsyncAPI</strong> - Each pub/sub, event, and message API have APIs.</li>
  <li><strong>APIs.json</strong> - Collections of APIs have tags for discoverability.</li>
</ul>

<p>Tags are an important dimension of API discoverability when it comes to my API definitions. They provide rich metadata that I can use to make sense of my API infrastructure. Without them, the quality of my API definitions tend to trend lower. By evolving the tagging schema, and investing in tooling to help me make sense across the API definitions I’m depending on, I can push the boundaries of how I tag, and evolve it to be the core of how I manage my API definitions.</p>

<p>I’ll keep watching how others are tagging their APIs, although I don’t see too much innovation, and low levels of usage by other API providers as part of their API definitions. I’ll also keep an eye out for other ways in which tag schema are being extended, helping potentially define the future of how the leading API specifications enable tagging. I have a short list of tooling I am developing to help make my life easier, but I’m working hard to just make sure I’m applying tags across my API resources in a consistent way. I find this is the most valuable aspect of API tagging, but eventually I’m guessing that the tooling will make the real difference when it comes to slicing and dicing, and making sense of my API infrastructure at scale.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/19/organizing-my-apis-using-openapi-tags/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/17/doing-the-hard-work-to-define-apis/">Doing The Hard Work To Define APIs</a></h3>
        <span class="post-date">17 Jun 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/gears-4882162452-fa3126b38d-b-umberto-bocc.jpg" width="45%" align="right" style="padding: 15px;" />
Two years later, <a href="https://apievangelist.com/2017/01/09/the-api-driven-marketplace-that-is-my-digital-self/">I am still working to define the API driven marketplace that is my digital self</a>. Understanding how I generate revenue from my brand (vomits in mouth a little bit), but also fight off the surveillance capitalists from mining and extracting value from my digital existence. It takes a lot of hard work to define the APIs you depend on to do business, and quantify the digital bits that you are transacting on the open web, amongst partners, and unknowingly with 3rd parties. As an individual, I find this to be a full time job, and within the enterprise, it is something that everyone will have to own a piece of, which in reality, is something that is easier said than done.</p>

<p>Convincing enterprise leadership of the need to be aware of every enterprise capability being defined at the network, system, or application level is a challenge, but doable. Getting consensus on how to do this at scale, across the enterprise will be easier said than done. Identifying how the network, system, and applications across a large organization are being accessed, what schema, messages, and other properties are being exchanged is not a trivial task. It is a massive undertaking to reverse engineer operations, and identify the core capabilities being delivered, then define and document in a coherent way that can be shared with others, and included as part of an organization messaging campaign.</p>

<p>Many will see work to define all enterprise API capabilities as a futile task–something that is impossible to deliver. Many others will not see the value of doing it in the first place, and unable to realize the big picture, they will see defining of APIs and underlying schema as meaningless busy work. Even when you do get folks on-board with the important, having the discipline to see the job through becomes a significant challenge. If moral is low within any organization group, and team members do not have visibility into the overall strategy, the process of defining gears that make the enterprise move forward will be seen as mind numbing accounting work–not something most teams will respond positively about working on.</p>

<p>Once you do define your APIs, you then have to begin investing in defining what the future will hold when it comes to unwinding, evolving, maturing the API infrastructure you are delivering and depending on. This is something that can’t fully move forward until a full or partial accounting of enterprise API capabilities has occurred. If you do not know what is, you will always have trouble defining or controlling what will be. One of the reasons we have so much technical debt is we prefer to focus on what comes next rather than attending to the maintenance required to keep everything clean ,coherent, organized, and well defined. It is always easier to focus on the future, than it is to reconcile with mess we’ve created in the past. This is why it is so easy to sell each wave of enterprise technology solutions, promising to do this work for you–when in reality, most times, you are just laying down the next layer of debt.</p>

<p>Whether it is our personal lives, or our professional worlds, defining the APIs we depend on, as well as the APIs that aren’t useful and become parasitic, as well as the schema objects they produce and exchange is a lot of hard work. Hard work most of us will neglect and outsource for convenience. Making the work become even harder down the road–nobody will care about doing this as we do. The really fascinating part of all of this for me, is that with each cycle of technology that passes through, we keep doubling down on technology being the solution to yesterday’s problem, even though it is the core of yesterday’s problem. In my experience, once you really begin investing in the hard work to define the APIs you depend on, you begin to realize that you don’t need so many of them. That the number of API connections you depend on can actually begin to hurt you, which is something that can wildly grow if you aren’t in tune with what your API landscape consists of in your personal and professional worlds.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/17/doing-the-hard-work-to-define-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/16/there-is-no-single-right-way-to-do-apis/">There Is No Single Right Way To Do APIs</a></h3>
        <span class="post-date">16 Jun 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/rockingchair-face-2-atari-asteroids.jpg" width="45%" align="right" style="padding: 15px;" />
My time working in the API sector has been filled with a lot of lessons. I researched hard, paid attention, and found a number of surprising realities emerge across the API landscape. The majority of surprises have been in the shadows caused by my computational belief scaffolding I’ve been erecting since the early 1980s. A world where there has to be absolutes, known knowns, things are black and white, or more appropriately 1 or 0. If I studied all APIs, I’d find some sort of formula for doing APIs that is superior to everyone else’s approach to doing APIs. I was the API Evangelist man–I could nail down the one right way to do APIs. (Did I mention that I’m a white male autodidact?)</p>

<p>I was wrong. There is no one right way to do APIs. Sure, there are many different processes, practices, and tools that can help you optimize your API operations, but despite popular belief, there is no single “right way” to do define, design, provide, or consume APIs. REST is not the one solution. Hypermedia is not the one solution. GraphQL is not the one solution. Publish / Subscribe is not the one solution. Event-driven is not the one solution. APIs in general are the the one solution. Anyone telling you there is one solution to doing APIs for all situations is selling you something. Understanding your needs, and what the pros and cons of different approaches are, is the only thing that will help you.</p>

<p>If you are hyper focused on the technology, it is easy to believe in a single right way of doing things. Once you start having to deliver APIs in a variety of business sectors and domains, you will quickly begin to see your belief system in a single right way of doing things crumble. Different types of data require different types of approaches to API enablement. Different industries are knowledgable in different ways of API enablement, with some more mature than others. Each industry will present its own challenges to API delivery and consumption, that will require a different toolbox, and mixed set of skills required to be successful. Your social network API strategy will not easily translate to the healthcare industry, or other domain.</p>

<p>With a focus on the technology and business of APIs, you can still find yourself dogmatic around a single right way of doing things. Then, if you find yourself doing APIs in a variety of organizations, across a variety of industries, you quickly realize how diverse your API toolbox and approach will need to be. Organizations come with all kinds of legacy technical debt, requiring a myriad of approaches to ensuring APIs properly evolve across the API lifecycle. Once a technological approach to delivering software gets baked into operations, it becomes very difficult to unwind, and change behavior at scale across a large organization–there is no single right way to do APIs within a large enterprise organization. If someone is telling you there is, they are trying to sell you the next generation of technology to bake into your enterprise operations, which will have to be unwound at some undisclosed date in the future–if ever.</p>

<p>I’ve always considered my API research and guidance to be a sort of buffet–allowing my readers choose the mix that works for them. However, I still found myself providing industry guides, comprehensive checklists, and other declarative API narratives that still nod towards there being a single, or at least a handful of right ways of doing APIs. I think that APIs will ultimately be like cancer, something we never quite solve, but there will be huge amounts of money spent trying to deliver the one cure. I’ll end with the comparison there, because I don’t want to get me on a rant regarding the many ways in which APIs and cancer will impact the lives of everyday people. In the end, I will still keep studying and understanding different approaches to doing APIs (both good or bad), but you’ll find my narrative to be less prescriptive when it comes to any single way of doing APIs, as well as suggesting that doing APIs in the first place is the right answer to any real world problem.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/16/there-is-no-single-right-way-to-do-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/12/api-definitions-are-important/">API Definitions Are Important</a></h3>
        <span class="post-date">12 Jun 2019</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope-master/christianity-christianity-under-construction-copper-circuit.jpg" width="35%" align="right" style="padding: 15px;" />
I found myself scrolling down the home page of API Evangelist and thinking about what topic(s) I thought were still the most relevant in my mind after not writing about APIs for the last six months. Hands down it is API definitions. These machine and human readable artifacts are the single most important thing for me when it comes to APIs I’m building, and putting to work for me.</p>

<p>Having mature, machine readable API definitions for all API that you depend on, is essential. It also takes a lot of hard work to make happen. It is why I went API define first a long time ago, defining my APIs before I ever get to work designing, mocking, developing, and deploying my APIs. Right now, I’m heavily dependent on my:</p>

<ul>
  <li><strong>JSON Schema</strong> - Essential for defining all objects being used across API contracts.</li>
  <li><strong>OpenAPI</strong> - Having OpenAPI contracts for al my web APIs is the default–they drive everything.</li>
  <li><strong>AsyncAPI</strong> - Critical for defining all of my non HTTP 1.1 API contracts being provided or consumed.</li>
  <li><strong>Postman Collections</strong> - Providing me with the essential API + environment definitions for run-time use.</li>
  <li><strong>APIs.json</strong> - Helping me define all the other moving parts of API operations, indexing all my definitions.</li>
</ul>

<p>While there is plenty of other stops along the API lifecycle that are still relevant to me, my API definitions are hands down the most valuable intellectual property I possess. These four API specifications are essential to making my world work, but there are other more formalized specifications I’d love to be able to put to work:</p>

<ul>
  <li><strong>Orchestrations</strong> - I’d liked to see a more standardized, machine readable way for working with many API calls in a meaningful way. I know you can do this with Postman, and I’ve done with OpenAPI, and like Stoplight.io’s approach, but I want an open source solution.</li>
  <li><strong>Licensing</strong> - I am not still actively using API Commons, but I’d like to invest in a 2.0 version of the API licensing specification, moving it beyond just the API licensing, and consider SDK, and other layers.</li>
  <li><strong>Governance</strong> - I’d like to see a formal way of expressing API governance guidance that can be viewed by a human, or executed as part of the pipeline, ensuring that all API contracts conform to a set of standards.</li>
</ul>

<p>These area hit on the main areas that concern for me when it comes to defining the contracts I need to further automate the integration and deployment of API resources in my life. While there are definitely other stops along the API lifecycle on my mind, I spend the majority of my time creating, refining, communicating, and moving forward API definitions that define and drive every other stop along the API lifecycle.</p>

<p>API definitions represent API sanity for me. If they aren’t in order, there is disorder. An immature API definition requires investment, socialization amongst stakeholders, and iterating upon before it will ever be considered for publishing. I’ll be exploring the other things that matter for me along the API lifecycle, and then I’m guessing that the rest of this stuff I’ve been researching over the last eight years will either disappear, or just be demoted on the site. We’ll see how this refresh rolls out, but I’m guestimating about 25% of my research will continue to move forward after this reboot.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/12/api-definitions-are-important/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/06/10/api-evangelist-is-open-for-business/">API Evangelist Is Open For Business</a></h3>
        <span class="post-date">10 Jun 2019</span>
        <p><img src="https://kinlane-productions.s3.amazonaws.com/api-evangelist-site/open-nen.jpg" width="25%" align="right" style="padding: 15px;" /></p>
<p>After six months of silence I've decided to fire API Evangelist back up again. I finally reached a place where I feel like I can separate out the things that caused me to step back in the first place. Mostly, I have a paycheck now, some health insurance, and I don't have to pretend I give a shit about APIs, startups, venture capital, and the enterprise. I'm being paid well to do an API job. I can pay my rent. I can go to the doctor when my health takes a hit. My basic needs are met.</p>

<p>Beyond that, I'm really over having to care about building an API community, making change with APIs, and counteracting all of the negative effects of APIs in the wild. I can focus on exactly what interests me about technology, and contribute to the 3% of the API universe that isn't doing yawnworthy, half-assed, or straight up shady shit. I don't have to respond to all the emails in my inbox just because I need to eat, and have a roof over my head. I don't have to jump, just because you think your API thing is the next API thing. I can just do me, which really is the founding principle of API Evangelist.</p>

<p>Third, I got a kid to put through college, and I'm going to make y'all pay for it. So, API Evangelist is open for business. I won't be producing the number of stories I used to. I'll only be writing about things I actually find interesting, and will explore other models for generating content, traffic, and revenue. So reach out, and pitch me. I'm looking for sponsors, and open to almost anything. Don't worry, I'll be my usual honest self and tell you whether I'm interested or not, and have strong opinions on what should be said, but pitch me. I'm open for business, I'll entertain any business offer keep API Evangelist in forward motion, and generating revenue for me.</p>

<p>If you are interested in sponsoring API Evangelist, it is averaging 2K page views a day, but normally averages 5K a day when it is in full active mode. The Twitter account has 10K followers, and the audience is a pretty damn good representation of the API pie if I don't say so myself. It is a damn shame to squander what I've built over the last nine years just because I like to ride on a sparkly high horse. If I've learned anything during my time as the API Evangelist, it is that revenue drives ALL decisions. So get in on the action. Let me know what you are thinking, and I'll get to work adding your logo to the site, and turning on the other sponsorship opportunities. Ping me at <a href="mailto:info@apievangelist.com">info@apievangelist.com</a> to get the ball rolling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/06/10/api-evangelist-is-open-for-business/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/27/asking-the-honest-questions-when-it-comes-to-your-api-journey/">Asking The Honest Questions When It Comes To Your API Journey</a></h3>
        <span class="post-date">27 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/kin-mountain_feed_people.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>I engage with a lot of enterprise organizations in a variety of capacities. Some are more formal consulting and workshop engagements. While others are just emails, direct messages, and random conversation in the hallways and bars around API industry events. Many conversations are free flowing, and they trust me to share my thoughts about the API space, and provide honest answers to their questions regarding their API journey. Where others express apprehension, concern, and have trouble engaging with me because they are worried about what I might say about their approach to doing APIs within their enterprise organizations. Some have even told me that they’d like to formally bring me in for discussions, but they can’t get me pass legal or their bosses–stating I have a reputation for being outspoken.</p>

<p>While in Vegas today, I had breakfast with Paolo Malinverno, analyst from Gartner, he mentioned the Oscar Wilde quote, “Whenever people agree with me I always feel I must be wrong.” Referring to the “yes” culture than can manifest itself around Gartner, but also within industries and the enterprise regarding what you should be investing in as a company. That people get caught up in  up in culture, politics, and trends, and don’t always want to be asking, or be asked the hard questions. Which is the opposite of what any good API strategist, leader, and architect should be doing. You should be equipped and ready to be asked hard questions, and be searching out the hard questions. This stance is fundamental to API success, and you will never find what you are seeking when it comes to your API journey if you do not accept that many questions will be difficult.</p>

<p>The reality that not all API service providers truly want to help enterprise organizations genuinely solve the business challenges they face, and that many enterprise technology leaders aren’t actually concerned with truly solving real world problems, has been one of the toughest pills for me to swallow as the API Evangelist over the last eight years. Realizing that there is often more money to be made in not solving problems, not properly securing systems, or systems being performant, efficient, and working as expected. While I think many folks are too far down in the weeds of operations and company culture to fully make the right decision, I also think there are many people who make the wrong technological decision because it is the right business decision in their view. They do it to please share holders, investors, their boss, or just going with the flow when it comes to the business culture within their enterprise, and the industry that they operate in.</p>

<p>Honestly, there isn’t a lot of money to be made asking the hard questions, and addressing the realities of getting business done using APIs within the enterprise. Not all companies are willing to pay you to come in and speak truth to what is going on. Pointing out the illnesses that exist within the enterprise, and potentially provide solutions to what is happening. People are afraid what you are going to ask. People don’t want to pay someone to rock the boat. I find it to be a rare occurrence to find large enterprise organizations who are willing to look in the mirror and be held accountable for their legacy technical debt, and be forced to make the right decisions when it comes to moving forward with the next generation of investment. Which is why most organizations will stumble repeatedly in their API journeys, be more susceptible to the winds of technological trends and investment cycles, all because they aren’t willing to surround themselves with the right people who are willing to speak truth.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/27/asking-the-honest-questions-when-it-comes-to-your-api-journey/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/25/a-diverse-api-design-toolbox-driving-hybrid-integrations-in-an-event-driven-landscape/">A Diverse API Toolbox Driving Hybrid Integrations Across An Event-Driven Landscape</a></h3>
        <span class="post-date">25 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/machine-road_atari_missle.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>I’m heading to Vegas in the morning to spend two days in conversations with folks about APIs. I am not there for <a href="https://reinvent.awsevents.com/">AWS re:Invent</a>, or <a href="https://www.gartner.com/en/conferences/na/applications-us">the Gartner thingy</a>, but I guess in a way I am, because there are people there for those events, who want to talk to me about the API landscape. Folks looking to swap stories about enterprise API investment in possessing a diverse API toolbox for driving hybrid integrations in an event-driven landscape. I’m not giving any formal talks, but as with any engagement, I’m brushing up on the words I use to describe what I’m seeing across the space when it comes to the enterprise API lifecycle.</p>

<p><strong>The Core Is All About Doing Resource Based, Request And Response APIs Well</strong><br />
I’m definitely biased, but I do not subscribe to popular notions that at some point REST, RESTful, web, and HTTP APIs will have to go away. We will be using web technology to provide simple, precise, useful access to data, content, and algorithms for some time to come, despite the API sectors continued evolution, and investment trends coming and going. Sorry, it is simple, low-cost, and something a wide audience gets from both a provider and consumer perspective. It gets the job done. Sure, there are many, many areas where web APIs fall short, but that won’t stop success continuing to be defined by enterprise organizations who can do microservices well at scale. Despite relentless assaults by each wave of entrepreneurs, simple HTTP APIs driving microservices will stick around for some time to come.</p>

<p><strong>API Discovery And Knowing Where All Of Your APIs Resources Actually Are</strong><br />
API discovery means a lot of things to a lot of people, but when it comes to delivering APIs well at scale in a multi-cloud, event-driven world, I’m simply talking about knowing where all of your API resources are. Meaning, if I walked into your company tomorrow, could you should me a complete list of every API or web service in use, and what enterprise capabilities they enable? If you can’t, then I’m guessing you aren’t going to be all that agile, efficient, and ultimately effective with doing your APIs at scale, and be able to orchestrate much, and identify what the most meaningful events are that occur across the enterprise landscape. I’m not even getting to the point of service mesh, and other API discovery wet dreams, I’m simply talking about being able to coherently articulate what your enterprise digital capabilities are.</p>

<p><strong>Always Be Leveraging The Web As Part Of Your Diverse API Toolbox</strong><br />
Technologists, especially venture fueled technologists love to take the web for granted. Nothing does web scale better than, the web. Understand the objectives behind your APIs, and consider how you are leveraging the web, negotiate, cache, and build on the strengths of the web. Use the right media type for the job, and understand the tradeoffs of HTML, CSV, XML, JSON, YAML, and other media types. Understand when hypermedia media types might be more suitable for document, media, and other content focused API resources. Simple web APIs make a huge difference when they further speak to their intended audience and allow them to easily translate an API call into a workable spreadsheet, or navigate to the previous or next episode, installment, or other logical grouping with sensible hypermedia controls. Good API design is more about having a robust and diverse API design toolbox to choose from, than it is ever about the dogma that exists around any specific approach, philosophy, protocol, or venture capital fueled trend.</p>

<p><strong>Have A Clear Vision For Who Will Be Using Your APIs</strong><br />
One significant mistake that API designers, developers, and architects make over and over again, is not having a clear vision of who will be using the APIs they are building. Defining, designing, delivering, and operating an API that is based upon what the provider wants over what the consumers will need. Using protocols, ignoring existing patterns, and adopting the latest trend that have nothing to do with what API consumers will be needing or capable of putting to work. Make sure you know your consumers, and consider giving them more control with query languages like GraphQL and Falcor, allowing them to define the type of experience they want. Work to have a clear vision of who will be consuming an API, even if you don’t know who they are. Starting simple with basic web APIs that help easily on-board new users who are unfamiliar with the domain and schema, while also allowing for the evolution give power-users who are in the know, more access, more control, and a stronger voice in the vision of what your APIs deliver or do not.</p>

<p><strong>Responding In Real Time, Not Just Upon Request</strong><br />
A well oiled request and response API infrastructure is a critical base for any enterprise organization, however, a sign of a more mature, scalable API operations is always the presence of event-driven infrastructure including webhooks, streaming solutions, and multi-protocol, multi-message approaches to moving data and content around, and responding algorithmically based upon real time events occurring across the domains. Investing in event-driven infrastructure is not simply about using Kafka, it is about having a well-defined, well-honed web API base, with a suite of event-driven approaches in ones toolbox for also providing access to internal, partner, and last mile public and 3rd party resources using an appropriate set of protocols, and message formats. Something that might be as simple as a webhook subscription to changes, getting a simple HTTP push when something changes, to maintaining persistent HTTP connections to get an HTTP push when something changes, all the way to high volume HTTP and TCP connections to a variety of topical channels using Kafka, or other industrial grade API-driven solutions like gRPC, and beyond.</p>

<p><strong>Have A Reason For When You Switch Protocols</strong><br />
There are a number of reasons why we switch protocols, moving off HTTP towards a TCP way of getting things done, with most reasoning being more emotional than they are ever technical. When I ask people why they went from HTTP APIs to Kafka, or Websockets, there is rarely a protocol based response. They did it because they needed things done in real time, through the existence of specific channels, or just simple because Kafka is how you do big data, or Websockets is how you do real time data. There wasn’t much scrutiny of who the consumers are, what was gained by moving to TCP, and what was lost by moving off HTTP. There is little awareness of the work Google has done around gRPC and HTTP/2, or what has happened recently around HTTP/3, formerly known as Quick UDP Internet Connections (QUIC). I’m no protocol expert, but I do grasp the role that these protocols play, and understand that the fundamental foundation of APIs is the web, and the importance of having a well thought out strategy when it comes to using the Internet for delivering on the API vision across the enterprise.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/containership_copper_circuit.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p><strong>Ensuring All Your API Infrastructure Is Reliable</strong><br />
It doesn’t matter what your API design processes are, and what tools you are using if you cannot do it reliably. If you aren’t monitoring, testing, securing, and understanding performance, consumption, and limitations across ALL of your API infrastructure, then there will never be the right API solution. Web APIs, hypermedia, GraphQ, Webooks, Server-Sent Events, Websockets, Kafka, gRPC, and any other approach will always be inadequate if you cannot reliably operate them. Every tool within your API design toolbox should be able to be effectively deployed, thoughtfully managed, and coherently monitored, tested, secured, and delivered as a reliable service. If you don’t understand what is happening under the hood with any of your API infrastructure, out of your league technically, or kept in the dark through vendor magic, it should NOT be a tool in your toolbox, and be something that left in the R&amp;D lab until you can prove that you can reliably deliver, support, scale, and evolve something that is in alignment with, and has purpose augmenting and working with your existing API infrastructure.</p>

<p><strong>Be Able To Deliver, Operate, And Scale Your APIs Anywhere They Are Needed</strong><br />
One increasingly critical aspect of any tool in our API design is whether or not we can deploy and operate it within multiple environments, or find that we are limited to just a single on-premise or cloud location. Can your request and response web API infrastructure operate within the AWS, Google, or Azure clouds? Does it operate on-premise within your datacenter, locally for development, and within sandbox environments for partners and 3rd party developers? Where your APIs are deployed will have have just as big of an impact on reliability and performance as your approach to design and the protocol you re using. Regulatory and other regional level concerns may have a bigger impact on your API infrastructure, than using REST, GraphQL, Webhooks, Server-Sent Events, or Kafka. Being able to ensure you can deliver, operate, and scale APIs anywhere they are needed is fast becoming a defining characteristic of the tools that we possess in our API toolboxes.</p>

<p><strong>Making Sure All Your Enterprise Capabilities Are Well Defined</strong><br />
The final, and most critical element of any enterprise API toolbox, is ensuring that all of your enterprise capabilities are defined as machine readable API contracts, using OpenAPI, AsyncAPI, JSON Schema, and other formats. API definitions should provide human and machine readable contracts for all enterprise capabilities that are in play. These contracts contribute to every stop along the API lifecycle, and help both API providers and consumers realize everything I have discussed in this post. OpenAPI provides what we need to define our request and response capabilities using HTTP, and Async provides what we need to define our event-driven capabilities, providing the basis for understanding what we are capable of delivering using our API toolboxes, and responding to via the hybrid integration solutions we’ve engineered, and automated using our event-driven solutions. Defining the surface area of our API infrastructure, but also the API operations that surround the enterprise capabilities we are enabling internally, with partners, and publicly via our enterprise API efforts.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/25/a-diverse-api-design-toolbox-driving-hybrid-integrations-in-an-event-driven-landscape/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/23/the-api-journey/">The API Journey</a></h3>
        <span class="post-date">23 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/journey/journey-bridge.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>I’ve been researching the API space full time for the last eight years, and over that time I have developed a pretty robust view of what the API landscape looks like. <a href="http://apievangelist.com/#api-lifecycle">You can find almost 100 stops along what I consider to be the API lifecycle on the home page of API Evangelist</a>. While not every organization has the capacity to consider all 100 of these stops, they do provide us with a wealth of knowledge generated throughout my own journey. Where I’ve been documenting what the API pioneers have been doing with their API operations, how startups leverage simple web API infrastructure, as well as how the enterprise has been waking up to the API potential in the last couple of years.</p>

<p>Over the years I’ve tapped this research for my storytelling on the blog, and for the white papers and guides I’ve produced. I use this research to drive my talks at conferences, meetups, and the workshops I do within the enterprise. I’ve long had a schema for managing my research, tracking on the APIs, companies, people, tools, repos, news, and other building blocks I track across the API universe. Now, after a year of working with them on the ground at enterprise organizations, I’m partnering with <a href="http://streamdata.io">Streamdata.io (SDIO)</a> to continue productizing my approach to the API lifecycle, which we are calling Journey, or specifically SDIO Journey.</p>

<p>Our workshops are broken into four distinct areas of the lifecycle:</p>

<ul>
  <li><strong>Discovery</strong> (Goals, Definition, Data Sources, Discovery Sources, Discovery Formats, Dependencies, Catalog, Communication, Support, Evangelism) - Defining your digital resources are and what your enterprise capabilities are.</li>
  <li><strong>Design</strong> (Definitions, Design, Versioning, Webhooks, Event-Driven, Protocols, Virtualization, Testing, Landing Page, Documentation, Support, Communication, Road Map, Discovery) - Going API first, as well as API design first when it comes to the delivery of all of your API resources.</li>
  <li><strong>Development</strong> (Definitions, Discovery, Virtualization, Database, Storage, DNS, Deployment, Orchestration, Dependencies, Testing, Performance, Security, Communication, Support) - Considering what is needed to properly develop API resources at scale, and move from design to production.</li>
  <li><strong>Production</strong> (Definitions, Discovery, Virtualization, Authentication, Management, Logging, Plans, Portal / Landing Page, Getting Started, Documentation, Code, Embeddables, Licensing, Support, FAQs, Communication, Road Map, Issues, Change Log, Legal, Monitoring, Testing, Performance, Tracing, Security, Analysis, Maintenance) - Thinking about the production needs of an API operation, extracting the building blocks from successful APIs available across the web.</li>
  <li><strong>Outreach</strong> (Purpose, Scope, Defining Success, Sustaining Adoption, Communication, Support, Virtualization, Measurement, Structure) - Getting more structured around how you handle outreach around your APIs, whether they are internal, partner, or public API resources.</li>
  <li><strong>Governance</strong> (Design, Testing, Monitoring, Performance, Security, Observability, Discovery, Analysis, Incentivization, Competition) - Looking at how you can begin defining, measuring, analyzing, and providing guidance across API operations at the highest levels.</li>
</ul>

<p>We are currently working with several API service providers to deliver SDIO Journey workshops within their enteprise organizations, helping bring more API awareness to their pre-sales, sales, business, and executive groups. While also working to deliver independent Journey workshops for their customers, helping them see the bigger picture when it comes to the API lifecycle, but also begin establishing their own formal strategy for how they can execute on their own personal vision and version of it. Helping enterprise organization learn from the research I’ve gathered over the last eight years, and begin thinking more constructively, and being more thoughtful and organized about how they approach the delivery, iteration, and sustainment of APIs across the enterprise.</p>

<p>I have turned SDIO Journey into a set of basic APIs that allow me to build, replicate, and deliver our Journey workshops. I’m preparing for a handful of workshops before the end of the year with <a href="http://axway.com">Axway</a>, and for API Days in Paris, but then in 2019, continue productizing and delivering these API workshops, helping encourage other enterprise organizations to invest more in their own API Journey, get more structured in how they think about the delivering of microservices across the enterprise. Helping them realize that the transformation they are going through right now isn’t going to stop. It is something that will be ongoing, and require their organization to learn to accept perpetual change and evolution in how they deliver the data, content, and algorithmic resources they’ll need to do business across the enterprise. While also evolving their understanding that all of this is more about people, business, and politics more than it will ever be about technology all by itself.</p>

<p>If you have any questions about the SDIO Journey workshops we are doing, feel free to reach out, and I’ll get you more details about how to get involved.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/23/the-api-journey/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/23/api-management-yaml-artifacts-from-aws-api-gateway/">YAML API Management Artifacts From AWS API Gateway</a></h3>
        <span class="post-date">23 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/old-door-lock-2_marcel_duchamp.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>I’ve always been a big supporter of creating machine readable artifacts that help define the API lifecycle. While individual artifacts can originate and govern specific stops along the API lifecycle, they can also bring value when applied across other stops along the API lifecycle, and most importantly when it comes time to govern everything. The definition and evolution of individual API lifecycle artifacts is the central premise of <a href="http://apisjson.org">my API discovery format APIs.json</a>–which depends on there being machine readable elements within the index of each collection of APIs being documented, helping us map out the entire API lifecycle.</p>

<p><a href="https://www.openapis.org/">OpenAPI</a> provides us with machine readable details about the surface area of our API which can be used throughout the API lifecycle, but it lacks other details about the surface area of our API operations. So when I do come across interesting approaches to extending the OpenAPI specification which are also injecting a machine readable artifact into the OpenAPI that support other stops along the API lifecycle, I like to showcase what they are doing. I’ve become very fond of one within the OpenAPI export of any AWS API Gateway deployed API I’m working with, which provides some valuable details that can be used as part of both the deployment and management stops along the API lifecycle:</p>
<pre><code>
x-amazon-apigateway-integration:
	uri: "http://example.com/path/to/the/code/behind/"
	responses:
		default:
			statusCode: "200"
	requestParameters:
		integration.request.querystring.id: "method.request.path.id"
	passthroughBehavior: "when_no_match"
	httpMethod: "GET"
	type: "http"
</code></pre>
<p>This artifact is associated with each individual operation within my OpenAPI. It tells the AWS gateway how to deploy and manage my API. When I first import this OpenAPI into the gateway, it will deploy each individual path and operation, then it helps me manage it using the rest of the available gateway features. From this OpenAPI definition I can design, then autogenerate and deploy the code behind each individual operation, then deploy each individual path and operation to the AWS API Gateway and map them to the code behind. I can do this for custom APIs I’ve deployed, as well as Lambda brokered APIs–I prefer the direct way, because it is still easier, stabler, more flexible and cost effective for me to write the code behind each of my API operations, than to go full serverless.</p>

<p>However, this artifact demonstrates for me the importance of artifacts associated with each stop along the API lifecycle. This little bit of OpenAPI extended YAML gives me a significant amount of control when it comes to the automation of deploying and managing my APIs. There are even more properties available for other layers of the AWS Gateway not included in this example, but is something that I will keep mapping out. Having these types of machine readable artifacts present within our OpenAPI specifications for describing the surface area of our APIs, as well as present within our APIs.json indexes for describing the surface area of our API operations will be critical to further automating, scaling, and defining the API lifecycle as it exists across the enterprise.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/23/api-management-yaml-artifacts-from-aws-api-gateway/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/21/what-does-the-next-chapter-of-storyteling-look-like-for-api-evangelist/">What Does The Next Chapter Of Storytelling Look Like For API Evangelist?</a></h3>
        <span class="post-date">21 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/api-evangelist-logos/api-evangelist-butterfly-vertical.png" width="45%" align="right" style="padding: 15px;" /></p>
<p>I find myself refactoring API Evangelist again this holiday season. Over the last eight years of doing API Evangelist I’ve had to regularly adjust what I do to keep it alive and moving forward. As I  close up 2018, I’m finding the landscape shifting underneath me once again, pushing me to begin considering what the next chapter of API Evangelist will look like. Pushing me to adjust my presence to better reflect my own vision of the world, but hopefully also find balance with where things are headed out there in the real world.</p>

<p>I started API Evangelist in July of 2010 to study the business of APIs. As I was researching things in 2010 and 2011 I first developed what I consider to be the voice of the API Evangelist, which continues to be the voice I use in my storytelling here in 2018. Of course, it is something that has evolved and matured over the years, but I feel I have managed to remain fairly consistent in how I speak about APIs throughout the journey. It is a voice I find very natural to speak, and is something that just flows on some days whether I want it to or not, but then also something I can’t seem to find at all on other days. Maintaining my voice over the last eight years has required me to constantly adjust and fine tune, perpetually finding the frequency required to keep things moving forward.</p>

<p>First and foremost, API Evangelist is about my research. It is about me learning. It is about me crafting stories that help me distill down what I’m learning, in an attempt to articulate to some imaginary audience, which has become a real audience over the years. I don’t research stuff because I’m being paid (not always true), and I don’t tell stories about things I don’t actually find interesting (mostly true). API Evangelist is always about me pushing my skills forward as a web architect, secondarily about me making a living, and third about sharing my work publicly and building an audience–in short, I do API Evangelist to 1) learn and grow, 2) pay the bills, and 3) cultivate an audience to make connections.</p>

<p>As we approach 2019, I would say my motivations remain the same, but there is a lot that has changed in the API space, making it more challenging for me to maintain the same course while satisfying all these areas in a meaningful way. Of course, I want to keep learning and growing, but I’d say a shift in the API landscape toward the enterprise is making it more challenging to make a living. There just aren’t enough API startups out there to help me pay the bills anymore,  and I’m having to speak and sell to the enterprise more. To do this effectively, a different type of storytelling strategy is required to keep the paychecks coming in. Something I don’t think is unique to my situation, and is something that all API focused efforts are facing right now, as the web matures, and the wild west days of the API come to a close. It was fun while it lasted–yee haw!!</p>

<p>In 2019, the API pioneers like SalesForce, Twitter, Facebook, Instagram, Twilio, SendGrid, Slack, and others are still relevant, but it feels like API storytelling is continuing it’s migration towards the enterprise. Stories of building an agile, scrappy startup using APIs isn’t as compelling as they used to be. They are being replaced by stories of existng enterprise groups become more innovative, agile, and competitive in a fast changing digital business landscape. The technology of APIs, the business of APIs, and the stories that matter around APIs have all been caught up in the tractor beam of the enterprise. In 2010, you did APIs if you were on the edge doing a startup, but by 2013 the enterprise began tuning into what is going on, by 2016 the enterprise responded with acquisitions, and by 2018 we are all selling and talking to the enterprise about APIs.</p>

<p>Despite what many people might believe, I’m not anti-enterprise. I’m also not pro-startup. I’m for the use of web infrastructure to deliver on ethical and sensible private sector business objectives, strengthen expectations of what is possible in the public sector, while holding both sectors accountable to each other. I understand the enterprise, and have worked there before. I also understand how it is evolving over the last eight years through API discussions I have been having had with enterprise folks, workshops I’ve conducted within various public and private sector groups, and studying this latest shift in technology adoption across large organizations. Ultimately, I am very skeptical that large business enterprises can adapt, decouple, evolve, and embrace API and microservice principles in a way that will mean success, but I’m interested in helping educate enterprise teams, and assist them in crafting their enterprise-wide API strategy, and contribute what I can to incentivize change within these large organizations.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions/kin-lane/141-Post+Con+2018-Speakers.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>A significant portion of my audience over the last eight years is from the enterprise. However, I feel like these are the people within the enterprise who have picked up their heads, and consciously looked for new ways of doing things. My audience has always been fringe enterprise folks operating at all levels, but API Evangelist does not enjoy mainstream enterprise adoption and awareness. A significant portion of my storytelling speaks to the enterprise, but I recognize there is a portion of it that scares them off, and doesn’t speak to them at all. One of the questions I am faced with is around what type of tone do I strike as the API Evangelist in this next chapter? Will it be a heavy emphasis on the politics of APIs, or will it be more about the technology and business of APIs? To continue learning and growing in regards to what is happening on the ground with APIs, I’m going to need enterprise access. To continue making a living doing APIs, I’m going to need more enterprise access. The question for me is always around how far I put my left foot in the enterprise or government door, and how far I keep my right found outside in the real world–where there is no perfect answer, and is something that requires constant adjustment.</p>

<p>Another major consideration for me is always around authenticity. An area I posses a natural barometer in, and while I have a pretty high tolerance for API blah blah blah, and writing API industry white papers, when I start getting into areas of technology, business, or politics where I feel like I’m not being authentic, I automatically begin shutting down. I’ve developed a bulshit-o-meter over the years that helps me walk this line successfully. I’m confident I can maintain and not sell out here. My challenge is more about continuing to do something that matters to someone who will continue investing in my work, and having relevance to the audience I want to reach, and less about keeping things in areas that I’m interested in. I will gladly decline conversations, relationships, and engagements in unethical areas, shady government or business practices, avoid classified projects, and pay for play concepts along the way. Perpetually pushing me to always strike a balance between something that interests me, that pushes my skills, bring value to the table, has a meaningful impact, enjoys a wide reach, while also paying the bills. Which reflects what I’m thinking through as I write this blog post, demonstrating how I approach my own professional development.</p>

<p>So, what does the next chapter of storytelling look like for API Evangelist? I do not know. I know it will have more of a shift towards the enterprise. Which means a heavy emphasis on the technology and business of APIs. However, I’m also thinking deeply about how I present the political side of the API equation, and how I voice my opinions and concerns when it comes to privacy, security, transparency, observability, regulation, surveillance, and ethics that swirls around APIs. I’m guessing they can still live side by side in some way, I just need to be smarter about the politics of it, and less rantier and emotional. Maybe separate things into a new testament for the enterprise that is softer, wile also maintaining a separate old testament for the more hellfire and brimstone. IDK. It is something I’ll continue mulling over, and make decisions around as I continue to shift things up here at API Evangelist. As you can tell my storytelling levels are lower than normal, but my traffic is still constant, reflecting other shifts in my storytelling that have occurred in the past. I’ll be refactoring and retooling over the holidays, and no doubt have more posts about the changes. If you have any opinions on what value you get from API Evangelist, and what you’d like to see present in the next chapter, I’d love to hear from you in the comments below, on Twitter, or personally via email.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/21/what-does-the-next-chapter-of-storyteling-look-like-for-api-evangelist/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/16/the-ability-to-link-to-api-service-provider-features-in-my-workshops-and-storytelling/">The Ability To Link To API Service Provider Features In My Workshops And Storytelling</a></h3>
        <span class="post-date">16 Nov 2018</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/109_201_800_500_0_max_0_-5_-5.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>All of my API workshops are machine readable, driven from a central YAML file that provides all the content and relevant links I need to deliver what I need during a single, or multi-day API strategy workshop. One of the common elements of my workshops are links out to relevant resource, providing access to services, tools, and other insight that supports whatever I’m covering in my workshop. There are two parts to this equation, 1) me knowing to link to something, and 2) being able to link to something that exists.</p>

<p>A number of API services and tooling I use don’t follow web practices and do not provide any easy way to link to a feature, or other way of demonstrating the functionality that exists. The web is built on this concept, but along the way within web and mobile applications, we’ve have seemed to lose our understanding for this fundamental concept. There are endless situations where I’m using a service or tool, and think that I should reference in one of my workshops, but I can’t actually find any way to reference as a simple URL. Value buried within a JavaScript nest, operating on the web, but not really behaving like you depend on the web.</p>

<p>Sometimes I will take screenshots to illustrate the features of a tool or service I am using, but I’d rather have a clean URL and bookmark to a specific feature on a services page. I’d rather give my readers, and workshop attendees the ability to do what I’m talking about, not just hear me talk about it. In a perfect world, every feature of a web application would have a single URL to locate said feature. Allowing me to more easily incorporate features into my storytelling and workshops, but alas many UI / UX folks are purely thinking about usability and rarely thinking about instruct-ability, and being able to cite and reference a feature externally, using the fundamental building blocks of the web.</p>

<p>I understand that it isn’t easy for all application developers to think externally like this, but this is why I tell stories like this. To help folks think about the externalities of the value they are delivering. It is one of the fundamental features of doing business on the web–you can link to everything. However, I think we often forgot what makes the web so great, as we think about how to lock things down, erect walled gardens around our work, something that can quickly begin to work against us. This is why doing APIs is so important as it can helps us think outside of the walls of the gardens we are building, and consider someone else’s view of the world. Something that can give us the edge when it comes to reaching a wider audience with whatever we are creating.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/16/the-ability-to-link-to-api-service-provider-features-in-my-workshops-and-storytelling/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/06/flickr-and-reconciling-my-history-of-api-storytelling/">Flickr And Reconciling My History Of APIs Storytelling</a></h3>
        <span class="post-date">06 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/flickr/361347580_2d9d02b83d_z.jpg" width="45%" align="right" /></p>
<p>Flickr was <a href="http://apievangelist.com/2010/10/06/flickr-api-review/">one of the first APIs that I profiled back in 2010</a> when I started API Evangelist. Using their API as a cornerstone of my research, <a href="http://apievangelist.com/2011/02/09/history-of-apis-flickr-api/">resulting in their API making it into my history of APIs storytelling</a>, continuing to be a story I’ve retold hundreds of times in the conversations I’ve had over the eight years of being the API Evangelist. Now, after the second (more because of Yahoo?) acquisition, <a href="https://www.businesswire.com/news/home/20181101005328/en/Flickr-Announces-New-Photographer-Centric-Improvements-Flickr-Pro">Flickr users are facing significant changes regarding the number of images we can store on the platform, and what we will be charged for using the platform</a>–forcing me to step back, and take another look at the platform that I feel has helped significantly shape the API space as we know it.</p>

<p>When I step back and think about Flickr, it’s most important contribution to the world of APIs was all about the resources it made available. Flickr was the original image sharing API, powering the growing blogosphere at the beginning of this century. Flickr gave us a simple interface for humans in 2004, and an API for other applications just six months later, that provided us all with a place to upload the images we would be using across our storytelling on our blogs. Providing the API resources that we would be needed to power the next decade of storytelling via our blogs, but also set into the motion the social evolution of the web, demonstrating that images were an essential building block of doing business on the web, and in just a couple of years, on the new mobile devices that would become ubiquitous in our lives.</p>

<p>Flickr was an important API resource, because it provided access to an important resource–our images. The API allowed you to share these meaningful resources on your blog, via Facebook and Twitter, and anywhere else you wanted. In 2005, this was huge. At the time, I was working to make a shift from being an developer lead, to playing around with side businesses built using the different resources that were becoming available online via simple web APIs. Flickr quickly became a central actor in my digital resource toolbox, and I was using it regularly in my work. As an essential application, Flickr quickly got out of my way by offering an API. I would still use the Flickr interface, but increasingly I was just publishing images to Flickr via the API, and embedding them in blogs, and other marketing, becoming what we began to call social media marketing, and eventually was something that I would rebrand as API Evangelist while making it more about the tooling I was using, than the task I was accomplishing.</p>

<p>After thinking about Flickr as a core API resource, next I always think about the stories I’ve told about Flickr’s Caterina Fake who coined the phase, “business development 2.0”. As I tell it, back in the early days of Flickr, the team was getting a lot of interest in the product, and unable to respond to all emails and phone calls. They simply told people to build on their API, and if they were doing something interesting, they would know, because they had the API usage data. Flickr was going beyond the tech and using an API to help raise the bar for business development partnerships, putting the burden on the integrator to do the heavy lifting, write the code, and even build the user base, before you’d get the attention of the platform. If you were building something interesting, and getting the attention of users, the Flickr team would be aware of it because of their API management tooling, and they would reach out to you to arrange some sort of partner relationship.</p>

<p><img src="http://kinlane-productions.s3.amazonaws.com/flickr/flickr-beta.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>It makes for a good story. It resonates with business people. It speaks to the power of doing APIs. It is also enjoys a position which omits so many other negative aspects of doing startups, which as a technologist becomes too easy to look the other way when you are just focused on the tech, and as a business leader after the venture capital money begins flowing. Business development 2.0 has a wonderful libertarian, pull yourself up by your bootstrap ring to it. You make valuable resources available, and smart developers will come along and innovate! Do amazing things you never thought of! If you build it, they will come. Which all feeds right into the sharecropping, and exploitation that occurs within ecosystems, leading to less than ethical API providers poaching ideas, and thinking that it is ok to push public developers to work for free on their farm. Resulting in many startups seeing APIs as simply a free labor pool, and source of free road map ideas, manifesting concepts like the “<a href="https://apievangelist.com/2018/07/09/operating-your-api-in-the-cloud-kill-zone/">cloud kill zone</a>”. Business development 2.0 baby!!</p>

<p>Another dimension of this illness we like to omit is around the lack of a business model. I mean, the shit is free! Why would we complain about free storage for all our images, with a free API? It is easier for us to overlook the anti-competitive approaches to pricing, and complain down the road when each acquisition of the real product (Flickr) occurs, than it is to resist companies who lack a consumer level business model, simply because we are all the product. Flickr, Twitter, Facebook, Gmail, and other tools we depend on are all free for a reason. Because they are market creating services, and revenue is being generated at other levels out of our view as consumers, or API developers. We are just working on Maggie’s Farm, and her pa is reaping all the benefit. When it come’s to Flickr, Maggie and her {a cashed out a long time ago, and the farm keeps getting sold and resold, all while we still keep working away in the soil, giving them our digital bits that we’ve cultivate there, until conditions finally become unacceptable enough to run us off.</p>

<p>I’ve begun moving off of Flickr a couple years ago. I stopped using them for blog photo hosting in 2010. I stopped uploading photos there regularly over the last couple years. The latest crackdown doesn’t mean much to me. It will impact my storytelling to potentially lose such an amazing resource of openly licensed photos. However, I’ve saved each photo I use, and it’s attribution locally–hopefully my attribution link doesn’t begin to 404 at some point. Hopefully other openly licensed photo collections emerge on the horizon, and ideally SmugMug doesn’t do away with openly licensed treasure trove they are stewards of now. The latest acquisition and business model shift occurring across the Flickr platform doesn’t hit me too hard, but the situation does give me an opportunity to step back and reassess my API storytelling, and the role that Flickr plays in my API Evangelist narrative. Giving me another opportunity to eliminate bullshit and harmful myths from my storytelling and myth making–which I feel like is getting pretty close to leaving me with nothing left to tell when it comes to APIs.</p>

<p>In the end, if I just focus purely on the tech, and ignore the business and politics of APIs, I can keep telling these bullshit. This is the real Flickr lesson for me. I’d say there is two reasons we perpetuate stories like this. One, “because we just didn’t know any better”. Which is pretty weak. Two, it is how capitalism works. It is why us dudes, especially us white dudes thrive so well in a Silicon Valley tech libertarian world, because this type of myth making benefits us, even when it repeatedly sets us up for failure. This is one of the things that makes me throw up a little (a lot) in my mouth when I think about the API Evangelist persona I’ve created. This entire reality makes it difficult for me to keep doing this API Evangelist theater each day. APIs are cool and all, but when they are wielded as part of this larger money driven stream of consciousness, we (individuals) are always going to lose. In the end, why the fuck do I want to be a mouthpiece for this kind of exploitation. I don’t.</p>

<p><em><strong>Photo Credit:</strong> <a href="https://www.flickr.com/photos/kinlane/361347580/in/dateposted-public/">Kin Lane (The First Photo I Uploaded to Flickr)</a></em></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/06/flickr-and-reconciling-my-history-of-api-storytelling/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/11/01/the-impact-of-travel-on-being-the-api-evangelist/">The Impact Of Travel On Being The API Evangelist</a></h3>
        <span class="post-date">01 Nov 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/IMG_7598.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>Travel is an important part of what I do. It is essential to striking up new relationships, and reenforcing old ones. It is important for me to get out of my bubble, expose myself to different perspectives, and see the world in different ways. I am extremely grateful for the ability to travel around the US, and the world the way that I do. I am also extremely aware of the impact that travel has on me being the API Evangelist–the positive, the negative, and the general shift in my tone in storytelling after roaming the world.</p>

<p>One of the most negative impact that traveling has on my world is on my ability to complete blog posts. If you follow my work, when I’m in the right frame of mind, I can produce 5-10 blog posts across the domains I write for, on a daily basis. The words just do not flow in the same way when I am on the road. I’m not in a storyteller frame of mind. At least in the written form. When I travel, I am existing in a more physical and verbal sense as the API Evangelist, something that doesn’t always get translated into words on my blog(s). This is something that is ok for short periods of time, but after extended periods of time on the road, it is something that will begin to take a toll on my overall digital presence.</p>

<p>After the storytelling impact, the next area to suffer when I am on the road, is my actual project work. I find it very difficult to write code, or think at architectural levels while on the road. I can flesh out and move forward smaller aspects of the projects I’m working on, but because of poor Internet, packed schedules, and the logistics of being on the road, my technical mind always suffers. This is something that is also related to the impact on my overall storytelling. Most of the stories I publish on a daily basis evolve out of me moving forward actual projects as part of my API Evangelist work. If I am not actually developing a strategy, designing a specific API, or working on API definitions, discovery, governance, or one of the loftier aspects of my work, the chances I’m telling interesting stories will significantly be diminished.</p>

<p>Once I land back home, one of the first orders of business is to unclog the pipes with a “travel is hard” story. ;-) Pushing my fingers to work again. Testing out the connections between my brain and my fingers. While I also open up my IDE, command line, API universe dashboard, and begin refining my paper notes about what the fuck I was actually doing before I got on that airplane. Make it all work again is tough. Even the simplest of tasks seem difficult, and many of the projects I’m working on just seem too big to even know where to even begin. However, with a little effort, focus, and lack of a plane, train, or meeting to be present for, I’ll find my way forward again, slowly picking back up the momentum I enjoy as the API Evangelist. Researching, coding, telling stories, and pushing forward my projects so that they can have an impact on the space, and continue paying the bills to keep this vessel moving forward in the direction that I want.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/11/01/the-impact-of-travel-on-being-the-api-evangelist/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/10/22/what-are-your-enterprise-api-capabilities/">What Are Your Enterprise API Capabilities?</a></h3>
        <span class="post-date">22 Oct 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/machine-road_copper_circuit.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>I spend a lot of time helping enterprise organizations discover their APIs. All of the organizations I talk to have trouble knowing where all of their APIs are–even the most organized of them. Development and IT groups have just been moving too fast over the last decade to know where all of their web services, and APIs are. Resulting in large organizations not fully understanding what all of their capabilities are, even if it is something they actively operate, and may drive existing web or mobile applications.</p>

<p>Each individual API within the enterprise represents a single capability. The ability to accomplish a specific enterprise tasks that is valuable to the business. While each individual engineer might be aware of the capabilities present on their team, without group wide, and comprehensive API discovery across an organization, the extent of the enterprise capabilities is rarely known. If architects, business leadership, and any other stakeholder can’t browse, list, search, and quickly get access to all of the APIs that exist, the knowledge of the enterprise capabilities will not be able to be quantified or articulated as part of regular business operations.</p>

<p>In 2018, the capabilities of any individual API is articulated by it’s machine readable definition. Most likely OpenAPI, but could also be something like API Blueprint, RAML, or other specification. For these definitions to speak to not just the technical capabilities of each individual API, but also the business capabilities, they will have to be complete. Utilizing a higher level strategic set of tags that help label and organize each API into a meaningful set of business capabilities that best describes what each API delivers. Providing a sort of business capabilities taxonomy that can be applied to each API’s definition and used across the rest of the API lifecycle, but most importantly as part of API discovery, and the enterprise digital product catalog.</p>

<p>One of the first things I ask any enterprise organization I’m working with upon arriving, is “do you know where all of your APIs are?” The answer is always no. Many will have a web services or API catalog, but it almost always is out of date, and not used religiously across all groups. Even when there are OpenAPI definitions present in a catalog, they rarely contain the meta data needed to truly understand the capabilities of each API. Leaving developer and IT operations existing as black holes when it comes to enterprise capabilities, sucking up resources, but letting very little light out when it comes to what is happening on the inside. Making it very difficult for developers, architects, and business users to articulate what their enterprise capabilities are, and often times reinventing the wheel when it comes to what the enterprise delivers on the ground each day.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/10/22/what-are-your-enterprise-api-capabilities/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/10/22/join-me-for-a-fireside-chat-at-the-paris-api-meetup-this-week/">Join Me For A Fireside Chat At The Paris API Meetup This Wednesday</a></h3>
        <span class="post-date">22 Oct 2018</span>
        <p><a href="https://www.meetup.com/ParisAPI/events/255614957/"><img src="https://s3.amazonaws.com/kinlane-productions/events/paris-api-meetup/DqJd3bkJ.jpeg" width="45%" align="right" style="padding: 15px;" /></a></p>
<p>I am in Europe for most of October, and while I am in Paris we thought it would be a good idea to pull together a last minute API Meetup. Romain Simiand (<a href="https://twitter.com/RomainSimiand">@RomainSimiand</a>), the API Evangelist at <a href="https://www.people-doc.com/">PeopleDoc</a> was gracious enough to help pull things together, and the <a href="http://streamdata.io">Streamdata.io</a> team is stepping up to help with food and drink. Pulling together a last minute gathering at PeopleDoc in Paris, and bringing me on stage to talk about the technology, business, and politics of APIs, well as about some of my recent work on API discovery, and event-driven architecture.</p>

<p><a href="https://www.meetup.com/ParisAPI/events/255614957/">You can find more details on the Paris API Meetup site</a>, with directions on how to find PeopleDoc. Make sure you RSVP so that we know you are coming, and of course, please help spread the word. We are over 30 people attending so far, but I think we can do better. I’m happy to get on stage and help drive the API discussion, but I’d prefer to have a healthy representation of the Paris API community asking questions, helping me understand what is happening across the area when it comes to APIs. I always have plenty of knowledge to share, but it becomes exponentially more valuable when people on the ground within communities are asking questions, and making it relevant to what is happening within the day to day operations of companies in the local area.</p>

<p>While I enjoy doing conference keynotes and panels, my favorite format of event is the Meetup. Bringing together less than 100 people have a discussion about APIs. I always find that I learn the most in this environment, and able to actually engage with developers and business folks about what really matters when it comes to APIs. The larger the audience the more it is just about me broadcasting my message, and when it is a smaller and more intimate venue, I feel like I can better connect with people. In my opinion, this is how all API events should be–small, intimate, and a real world conversation about APIs. Not just an API pundit pushing their thoughts out, ensuring that all participants feel like they are actually part of the conversation.</p>

<p>If you are in the Paris region, or can make the time to hope on a plane or train and make it to Paris this Wednesday, I love to hang out. If you can’t make it, I’ll be back for API Days Paris in December, but it will be a bigger event, and it might be more difficult to carve out the time to hang. So, bring your API questions, and come over to the PeopleDoc office this Wednesday, and we’ll have a proper discussion about the technology, business, or politics of APIs. Helping drive the API discussion going on in France, continuing to push it forward. Making France a leader when it comes to doing business in the growing API economy. I look forward to seeing you all in Paris this week!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/10/22/join-me-for-a-fireside-chat-at-the-paris-api-meetup-this-week/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/10/22/i-particiated-in-an-api-workshop-with-the-european-commission-last-week/">I Participated In An API Workshop With The European Commission Last Week</a></h3>
        <span class="post-date">22 Oct 2018</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/events/apis4dgov/DpyR9qrXoAAYo4r.jpg" width="45%" align="right" style="padding: 15px;" /></p>
<p>I was in Ispra, Italy last week for a two day workshop on APIs with the European Commission. <a href="https://ec.europa.eu/digital-single-market/en/news/new-study-digital-government-apis-apis4dgov-project">The European Commission’s DG CONNECT together with the Joint Research Centre (JRC) launched a study</a> with the purpose to gain further understanding of the current use of APIs in digital government and their added value for public services, and they invited me to participate. I was joined by Mehdi Medjaoui (<a href="https://twitter.com/medjawii">@medjawii</a>), David Berlind (<a href="https://twitter.com/dberlind">@dberlind</a>), and Mark Boyd (<a href="https://twitter.com/mgboydcom">@mgboydcom</a>), along with EU member states, and European cities, to help provide feedback and strategies for consideration by the commission.</p>

<p>This European Commission study is looking at <em>“innovative ways to improve interconnectivity of public services and reusability of public sector data, including dynamic data in real-time, safeguarding the data protection and privacy legislation in place.”</em> Looking to:</p>

<ul>
  <li>assess digital government APIs landscape and opportunities to support the digital</li>
  <li>transformation of public sector</li>
  <li>identify the added value for society and public administrations of digital government APIs (key enablers, drivers, barriers, potential risks and mitigates)</li>
  <li>define a basic Digital Government API EU framework and the next steps</li>
</ul>

<p>David Berlind from ProgrammableWeb gave a couple talks, with myself, Mehdi, and Mark following up. The rest of the time spent was hearing presentations from EU member states, and other municipal efforts–learning more about the successes and the challeges they face. What I heard reflected what I’ve experienced in federal government, as well as city, county, and state level API efforts I’ve participated in across the United States. &lt;p&gt;<img src="https://s3.amazonaws.com/kinlane-productions/events/apis4dgov/IMG_7464.jpg" width="45%" align="right" style="padding: 15px;" />&lt;/p&gt;All groups were struggling to win over leaders and the public, modernize legacy system, build on top of open data efforts, and push forward the conversation using a modern approach to delivering web APIs.</p>

<p>I am eager to see what comes out of the European Commission API project. While there are still interesting things happening in the United States, I feel like there is an opportunity for the EU to leap frog us when it comes to meaningful API adoption within government. While many cities, counties, and states are still investing in open data and APIs, the investment at the federal level has stagnated with the current administration. There are still plenty of agencies moving forward the API conversation, but the leadership is coming from the GSA, and from within individual agencies, not from the executive branch. What is happening at the European Commission has the potential to be adopted by all the countries in the European Union, and making a pretty significant impact in how government works using APIs.</p>

<p>I’ll be staying in touch with the group leading the effort, and making myself available for future gatherings. There was talk of holding another gathering at API Days in Paris, and I am sure there will be further workshops as the project evolves. Clearly the European Commission has a huge amount of work ahead of them, but the fact that they are coming together like this, and highlighting, as well as learning from the existing work going on across the member states, shows significant promise. I made it clear as we were wrapping up regarding the importance of continued storytelling between the member states, as well as out of the European Commission. Emphasizing it will take a regular drumbeat of activity, and sharing of the work in real-time, for all of this to evolve as they desire. However, with the right cadence, the API effort out of Europe could make a pretty significant impact across the EU, and beyond.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/10/22/i-particiated-in-an-api-workshop-with-the-european-commission-last-week/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/10/11/api-evangelist-api-lifecycle-workshop-on-api-discovery/">API Evangelist API Lifecycle Workshop on API Discovery</a></h3>
        <span class="post-date">11 Oct 2018</span>
        <p><a href="http://locations.api.lifecycle.workshop.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/workshops/kin-lane-api-days-spain.jpg" width="45%" align="right" style="padding: 15px;" /></a></p>
<p>I’ve been doing more <a href="http://locations.api.lifecycle.workshop.apievangelist.com/">workshops on the API lifecycle within enterprise groups lately</a>. Allowing me to refine my materials on the ground within enterprise groups, further flesh out the building blocks I recommend to API groups to help them craft their own API strategy. One of the first discussions I start with large enterprise groups is always in the area of API discovery, or commonly asked as, “do you know where all your APIs are?”</p>

<p>EVERY group I’m working with these days is having challenges when it comes to easy discovery across all the digital resources they possess, and put to use on a daily basis. I’m working with a variety of companies, organizations, institutions, and government agencies when it comes to the API discovery of their digital self:</p>

<ul>
  <li><strong>Low Hanging Fruit</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Low%20Hanging%20Fruit">outline</a>) - Understanding what resources are already on the public websites, and applications, by spidering existing domains looking for data assets that should be delivered as API resources.</li>
  <li><strong>Discovery</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Discovery">outline</a>) - Actively looking for web services and APIs that exist across an organization, industry, or any other defined landscape. Documenting, aggregating, and evolving what is available about each API, while also publishing back out and making available relevant teams.</li>
  <li><strong>Communication</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Communication">outline</a>) - Having a strategy for reaching out to teams and engaging with them around API discovery, helping the remember to register and define their APIs as part of wider strategy.</li>
  <li><strong>Definitions</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Definition">outline</a>) - Work to make ensure that all definitions are being aggregated as part of the process so that they can be evolved and moved forward into design, development and production–investing in all of the artifacts that will be needed down the road.</li>
  <li><strong>Dependencies</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Dependencies">outline</a>) - Defining any dependencies that are in play, and will play a role in operations. Auditing the stack behind any service as it is being discovered and documented as part of the overall effort.</li>
  <li><strong>Support</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Support">outline</a>) - Ensure that all teams have support when it comes to questions about web service and API discovery, helping them initially, as well as along the way, making sure all their APIs are accounted for, and indexed as part of discovery efforts.</li>
</ul>

<p>API discovery will positively or negatively impact the rest of the API lifecycle at any organization. Not knowing where all of your resources are, and not having them properly defined for discovery at critical design, development, production, and integration movements, is an illness all companies are suffering from in 2018. We’ve deployed layers of services to deliver on enterprise growth, and put down a layer of web APIs to service the web, mobile, and increasingly device-based applications we’ve been delivering. Resulting in a tangled web of services, we need to tame before we can move forward properly.</p>

<p>Let me know if you need help with API discovery where you work. It is the fastest growing aspect of my API workshop portfolio. Aside from security, I feel like API discovery is the biggest challenge facing large enterprise groups learning to be more agile, flexible, and pushing forward with a microservices, and event-driven way of doing business. I definitely don’t have all the solutions when it comes to API discovery, but I knew have a lot of experience to share around how we are defining our enterprise capabilities and resources, and making them more discoverable across our entire API catalog.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/10/11/api-evangelist-api-lifecycle-workshop-on-api-discovery/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/10/11/api-evangelist-api-lifecycle-workshop-on-api-design/">API Evangelist API Lifecycle Workshop on API Design</a></h3>
        <span class="post-date">11 Oct 2018</span>
        <p><a href="http://locations.api.lifecycle.workshop.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/workshops/43043431_10156747264069813_2487933138479611904_n.jpg" width="45%" align="right" style="padding: 15px;" /></a></p>
<p>I’ve been doing more <a href="http://locations.api.lifecycle.workshop.apievangelist.com/">workshops on the API lifecycle within enterprise groups lately</a>. Allowing me to refine my materials on the ground within enterprise groups, further flesh out the building blocks I recommend to API groups to help them craft their own API strategy. One area of the API lifecycle I find more groups working on these days, centers around a design-first approach to the API lifecycle.</p>

<p>While not many groups I work with achieved a design-first approach doing APIs, almost all of them I talk to express interest in making this a reality at least within some groups, or projects. The appeal of being able to define, design, mock, and iterate upon an API contract before code gets written is very appealing to enterprise API groups, and I’m looking to help them think through this part of their API lifecycle, and work towards making API design first a reality at their organization.</p>

<ul>
  <li><strong>Definition</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Definition" target="_blank">outline</a>) - Using definitions as the center of the API design process, developing an OpenAPI contract for moving things through the design phase, iterating, evolving, and making sure the definitions drive the business goals behind each service.</li>
  <li><strong>Design</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Design" target="_blank">outline</a>) - Considering the overall approach to design for all APIs, executing upon design patterns that are in use to consistently deliver services across teams. Leveraging a common set of patterns that can be used across services, beginning with REST, but also evetually allowing the leveraging of hypermedia, GraphQL, and other patterns when it comes to the deliver of services.</li>
  <li><strong>Versioning</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Versioning" target="_blank">outline</a>) - Managing the definition of each API contract being defined as part of the API design stop for this area of the lifecycle, and having a coherent approach to laying out next steps.</li>
  <li><strong>Virtualization</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Virtualization" target="_blank">outline</a>) - Providing mocked, sandbox, and virtualized instances of APIs and other data for understanding what an API does, helping provide an instance of an API that reflects exactly how it should behave in a production environment.</li>
  <li><strong>Testing</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Testing" target="_blank">outline</a>) - Going beyond just testing, and making sure that a service is being tested at a granular level, using schema for validation, and making sure each service is doing exactly what it should, and nothing more.</li>
  <li><strong>Landing Page</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Landing%20Page" target="_blank">outline</a>) - Making sure that each individual service being designed has a landing page for acccessing it’s documentation, and other elements during the design phase.</li>
  <li><strong>Documentation</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Documentation" target="_blank">outline</a>) - Ensuring that there is always comprehensive, up to date, and if possible interactive API documentation available for all APIs being designed, allowing all stakeholders to easily understand what an API is going to accomplish.</li>
  <li><strong>Support</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Support" target="_blank">outline</a>) - Ensuring there is support channels available for an API, and stakeholders know who to contact when providing feedback and answering questions in real, or near real time, pushing forward the design process.</li>
  <li><strong>Communication</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Communication" target="_blank">outline</a>) - Making sure there is a communication strategy for moving an API through the design phase, and making sure stakeholders are engaged as part of the process, with regular updates about what is happening.</li>
  <li><strong>Road Map</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Road%20Map" target="_blank">outline</a>) - Providing a list of what is being worked on with each service being designed, and pushed forward, providing a common list for everyone involved to work from.</li>
  <li><strong>Discovery</strong> (<a href="http://locations.api.lifecycle.workshop.apievangelist.com/outline-items/#Discovery" target="_blank">outline</a>) - Make sure all APIs are discoverable after they go through the design phase, ensuring each type of API definition is up to date, and catalogs are updated as part of the process.</li>
</ul>

<p>I currently move my own APIs forward in this way using a variety of open source tooling, and GitHub. I’m working with some groups to do this in Stoplight.io, as well as Postman. I don’t think there is any “right way” to go API define and design first. I’m here to just educate teams about what is going on out there. What some of the services and tools that help enable an API design first reality, and talk through the technological, business, and political challenges are preventing a team, or entire enterprise group from becoming API design first.</p>

<p>Let me know if you need help thinking through the API design strategy where you work. I’ve been studying this area since it emerged as a discipline in 2012, led by API service providers like Apiary, but continue with other next generation platforms like Stoplight.io, APIMATIC, and others. For me, API design is less about REST vs Hypermedia vs GraphQL, and more about the lifecycle, services, tooling, and API definitions you use. I’m happy to share my view of the API design landscape with your group, just let me know how I can help.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/10/11/api-evangelist-api-lifecycle-workshop-on-api-design/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2018/10/09/the-layers-of-completeness-for-an-openapi-definition/">The Layers Of Completeness For An OpenAPI Definition</a></h3>
        <span class="post-date">09 Oct 2018</span>
        <p>Everyone wants their OpenAPIs to be complete, but what that really means will depend on who you are, what your knowledge of OpenAPI is, as well as being driven by your motivation for having an OpenAPI in the first place. I wanted to take a crack at articulating a complete(enough) definition for OpenAPIs I create, based upon what I’m needing them to do.</p>

<p><strong>Info &amp; Base</strong> - Give the basic information I need to understand who is behind, and where I can access the API.
<script src="https://gist.github.com/kinlane/5e52d6063a0744d711795beb6e60365f.js"></script></p>

<p><strong>Paths</strong> - Provide an entry for every path that is available for an API, and should be included in this definition.
<script src="https://gist.github.com/kinlane/1aa1a3f492da5f18bc7947b62589c8f8.js"></script></p>

<p><strong>Parameters</strong> - Provide a complete list of all path, query, and header parameters that can be used as part of an API.
<script src="https://gist.github.com/kinlane/29d0247d6ff4aaa39db4dc793df4a2f9.js"></script></p>

<p><strong>Descriptions</strong> - Flesh out descriptions for all the path and parameter descriptions, helping describe an API does.
<script src="https://gist.github.com/kinlane/160ae6aafdf5a5fb7114b5dd2ac37981.js"></script></p>

<p><strong>Enums</strong> - Publish a list of all the enumerated values that are possible for each parameter used as part of an API.
<script src="https://gist.github.com/kinlane/444731f0214cab5efcc3ae77011823ba.js"></script></p>

<p><strong>Definitions</strong> - Document the underlying schema being returned by creating a JSON schema definition for the API.
<script src="https://gist.github.com/kinlane/e833af3e1df40c716289c6cb81a64b88.js"></script></p>

<p><strong>Responses</strong> - Associate the definition for the API with the path using a response reference, connecting the dots regarding what will be returned.
<script src="https://gist.github.com/kinlane/01b5805b9d2cf60e163f708b9a8e5916.js"></script></p>

<p><strong>Tags</strong> - Tag each path with a meaningful set of tags, describing what resources are available in short, concise terms and phrases.
<script src="https://gist.github.com/kinlane/13331609e54f0dc88383144f08b01f50.js"></script></p>

<p><strong>Contacts</strong> - Provide contact information for whoever can answer questions about an API, and provide a URL to any support resources.
<script src="https://gist.github.com/kinlane/0009c35551f94d9dead677b3555ee7ed.js"></script></p>

<p><strong>Create Security Definitions</strong> - Define the security for accessing the API, providing details on how each API request will be authenticated.
<script src="https://gist.github.com/kinlane/aa56655a10bda8ee26ced5f98434d4fd.js"></script></p>

<p><strong>Apply Security Definitions</strong> - Apply the security definition to each individual path, associating common security definitions across all paths.
<script src="https://gist.github.com/kinlane/2c99e9b3f8382d2ea60a8db838dfdad2.js"></script></p>

<p><strong>Complete(enough)</strong> - That should give us a complete (enough) API description.
<script src="https://gist.github.com/kinlane/061f8c83226027c98079aa5fe3857ff2.js"></script></p>

<p>Obviously there is more we can do to make an OpenAPI even more complete and precise as a business contract, hopefully speaking to both developers and business people. Having OpenAPI definitions are important, and having them be up to date, complete (enough), and useful is even more important. OpenAPIs provide much more than documentation for an API. They provide all the technical details an API consumer will need to successfully work with an API.</p>

<p>While there are obvious payoffs for having an OpenAPI, like being able to publish documentation, and generate code libraries. There are many other uses for an OpenAPI like loading into <a href="https://www.getpostman.com/">Postman</a>, <a href="https://stoplight.io/">Stoplight</a>, and many other API services and tooling that helps developers understand what an API does, and reduce friction when they integrate, and have to maintain their applications. Having an OpenAPI available is becoming a default mode of operation, and something every API provider should have.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2018/10/09/the-layers-of-completeness-for-an-openapi-definition/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  

	<table width="100%" border="1" style="background-color:#FFF; border: 0px #FFF;">
		<tr style="background-color:#FFF; border: 0px #FFF;">
			<td align="left">
				<a href="/blog/page" class="button"><< Prev</a></li>
			</td>
			<td></td>
			<td align="right">
				<a href="/blog/page2" class="button">Next >></a>
			</td>
		</tr>
	</table>

  </div>
</section>

              
<footer>
  <hr>
  <div class="features">
    
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://www.getpostman.com/" target="_blank"><img src="https://apievangelist.com/images/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://apievangelist.com/images/tyk-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
  </div>
  <hr>
  <p align="center">
    relevant work:
    <a href="http://apievangelist.com">apievangelist.com</a> |
    <a href="http://adopta.agency">adopta.agency</a>
  </p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Homepage</a></li>
    <li><a href="http://101.apievangelist.com/">101</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="http://history.apievangelist.com/">History of APIs</a></li>
    <li><a href="/#api-lifecycle">API Lifecycle</a></li>
    <li><a href="/search/">Search</a></li>
    <li><a href="/newsletters/">Newsletters</a></li>
    <li><a href="/images/">Images</a></li>
    <li><a href="/archive/">Archive</a></li>
  </ul>
</nav>

              <section>
  <div class="mini-posts">
    <header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
    
    
      
        <article style="display: inline;">
          <a href="https://www.getpostman.com/" class="image"><img src="https://apievangelist.com/images/postman-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
      
        <article style="display: inline;">
          <a href="https://tyk.io/" class="image"><img src="https://apievangelist.com/images/tyk-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
  </div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
