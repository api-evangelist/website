<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
  <a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
  <ul class="icons">
    <li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
    <li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
    <li><a href="https://www.linkedin.com/organization/1500316/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
    <li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
  </ul>
</header>

    	        <section>
	<div class="content">

	<h3>The API Evangelist Blog</h3>
	<p>This blog is dedicated to understanding the world of APIs, exploring a wide range of topics from design to deprecation, and spanning the technology, business, and politics of APIs. <a href="https://github.com/kinlane/api-evangelist" target="_blank">All of this runs on Github, so if you see a mistake, you can either fix by submitting a pull request, or let us know by submitting a Github issue for the repository</a>.</p>
	<center><hr style="width: 75%;" /></center>
	
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/13/quantifying-the-difference-between-human-services-data-specification-hsds-and-its-api/">Quantifying The Difference Between Human Services Data Specification (HSDS) And Its API</a></h3>
        <span class="post-date">13 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/openapi-spec/openapi-spec-icon.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>To help quantify the move from version 1.0 to 1.1 of the Human Services Data API (HSDA) definition I took the existing Ohana API and created an OpenAPI definition to describe what was present in version 1.0 of the HSDA. Then I took <a href="http://openreferral.readthedocs.io/en/latest/reference/#organization">version 1.1 of the Human Services Data Specification (HSDS)</a> and made sure as much of HSDS was returned as part of API responses, as well as allowing adding, updating, and deleting across the schema.</p>

<p>During the vendor API review portion of our process I took the documentation for four of the vendors APIs and created OpenAPI for each of them. I then laid all the vendor OpenAPIs alongside <a href="https://openreferral.github.io/api-specification/definition/">the current draft I had of the HSDA definition</a>. I then consider each path, the parameters, body, and responses for inclusion as part of the HSDA definition. This allowed me to consider the existing vendor API implementations that are already serving human service implementations.</p>

<p>OpenAPI plays a central role in defining what is, what might be, while opening up a forum for having a conversation about the specific detail of the HSDS/A definition. I’m using OpenAPI to establish a definition of what both HSDS and HSDA are. It will be the contract that gets hammered out as part of the Open Referral governance process, so you will see me use it regularly to articulate specific aspects of what is going. With this in mind, I’d like to use a distilled OpenAPI, articulated just a single API path for GET /organizations.</p>

<script src="https://gist.github.com/kinlane/b44af277c9ad8948e82215ee31a7e195.js"></script>

<p>I won’t go into to much detail on the OpenAPI, <a href="https://github.com/OAI/OpenAPI-Specification">I recommend learning more about the specification on the GitHub repository</a>, and at <a href="https://www.openapis.org/">the OpenAPI Initiative (OAI)</a>. What I’d like to articulate for this story is to help quantity the separation and connection between the Human Services Data Specification (HSDA), and the Human Services Data API (HSDA), using this single OpenAPI, describing a single HSDA path–organizations.</p>

<p>When you take the schemes: located at line 7, and combine it with host: at line 5, basePath: at line 6, and the path for /organizations/ at line 12 you get http://api.open.referral.adopta.agency/organizations/, which when you load in a browser will give you a JSON listing of many organizations. Line 13-29 describes how to make an API request, and line 30-36 describes what you can expect as a response.</p>

<p>Lines 1-38 is HSDA, and 42-71 is HSDS. Line 36 is the link between HSDA, and HSDS, providing a reference that binds the API request, with the API response. HSDS is the valid schema being returned–HSDA is not the schema, it is the surface of the API that lets you send, and in this case received valid HSDS. This is a line that we honestly haven’t had the level of detail, or even the acronyms before now to even articulate HSDS/A at this level. So don’t worry if what I said doesn’t quite make sense–it will come. ;-)</p>

<p>The first reason I’m writing this story is to help myself better articulate the difference between HSDS, and HSDA, and the relationship between them. The second portion is to help other folks participating in the HSDS/A governance conversation see the separate layers between the schema and API, but also understand how they work together. I’d say a third portion is about helping folks understand the value of using OpenAPI to facilitate these types of conversations.</p>

<p>It might take a couple times reading this post and/or having a conversation directly with me about OpenAPI, but there is nothing in this OpenAPI definition that any engaged users can learn to work with–developers, and non-developers. I’ll keep producing simple lessons like this to better articulate aspects of the HSDS/A contract using OpenAPI. I’d love to hear any feedback on how I can better articulate the great work we are doing around the Human Services Data Specification and it’s API.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/13/quantifying-the-difference-between-human-services-data-specification-hsds-and-its-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/13/moving-the-human-services-api-specification-from-version-11-to-12/">Moving The Human Services API Specification From Version 1.1 to 1.2</a></h3>
        <span class="post-date">13 Jul 2017</span>
        <p><a href="http://developer.open.referral.adopta.agency/documentation/"><img src="https://s3.amazonaws.com/kinlane-productions/open-referral/hsda-organizations-documentation.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I am preparing for the recurring governance meeting for the Open Referral Human Services Data API standard–which I’m the technical lead for. I need to load up every detail of my Human Services Data API work into my brain, and writing stories is how I do this. I need to understand where the definition is with v1.1, and encourage discussion around a variety of topics when it comes to version 1.2.</p>

<h3 id="constraints-from-version-10-to-v11">Constraints From Version 1.0 To v1.1</h3>
<p>I wasn’t able to move as fast as I’d like from 1.0 to 1.1, resulting in me leaving out a number of features. The primary motivation to make sure as much of the version 1.1 of Human Services Data Specification (HSDS) was covered as possible–something I ended up doing horizontally with new API paths, over loading up the core paths of /organizations, /locations, and /services. There were too many discussion on the table regarding the scope and filtering of data, and schema for these core paths. Something which led to a discussion, about /search–resulting in me pushing off API design discussions on how to expand vertically at the core API path level to future versions.</p>

<p>There were just too many decisions to make at the API request and response level for me to make a decision in all the areas–warranting more discussion. Additionally, there were other API design discussion regarding operational, validation, and more utility APIs to discuss for inclusion in future versions expanding the scope and filtering discussions to the API path, and now API project level. In preparation for our regular governance meeting I wanted to run through all of the open API design issues, as well as additional projects the community needs to be thinking about.</p>

<h2 id="api-design">API Design</h2>
<p>As part of my Human Services Data API (HSDA) work we have opened up a pretty wide API design conversation regarding where the API definition could (should) be going. I’ve tried to capture the conversations going on across the Slack, and Google Group using GitHub issues for the HSDA GitHub repository. I will be focusing in on 16 of these issues for the current community discussions.</p>

<h3 id="versioning"><a href="https://github.com/openreferral/api-specification/issues/8">Versioning</a></h3>
<p>We are moving forward the version of the API specification from 1.0 to 1.1. This version describes the API definition, to help quantify the compliance of any single API implementation. This is not guidance regarding how API providers should version their API–each implementation can articulate their compliance using an OpenAPI definition, or just in operation by being compliant. I purposely dodged providing versioning guidance of specific API implementations–until I could open up discussion around this subject.</p>

<p>If you need a primer on API versioning I recommend <a href="https://www.troyhunt.com/your-api-versioning-is-wrong-which-is/">Troy Hunt’s piece</a> which helps highlight:</p>

<ul>
  <li>URL: We put the API version into the URL: https://example.com/api/v1.1/organizations/</li>
  <li>Custom request header: Using a header such as “api-version: 1.1”</li>
  <li>Accept header: Using the accept header to specify the version “Accept: application/vnd.hsda.v1.1+json - which relates to content negotiation discussions.</li>
  <li>No Versioning - We do not offer any versioning guidance and let each API implementation decide for themselves with no version being a perfectly acceptable answer.</li>
</ul>

<p>API versioning discussions are always hot topics, and there is no perfect answer. If we are to offer API versioning guidance for HSDA compliant API providers I recommend putting it in the URL, not because it is the right answer, but it is the right answer for this community. It is easy to implement, and easy to understand. Although I’m not 100% convinced we should be offering guidance at all.</p>

<p>I would like to open it up to the community, and get more feedback from vendors, and implementors. I’m curious what folks prefer when they are building applications. This decision was one that was wrapped up with potential content negotiation, hypermedia, and schema scope discussions to make without more discussion.</p>

<h3 id="paths"><a href="https://github.com/openreferral/api-specification/issues/27">Paths</a></h3>
<p>The API definition provides some basic guidance for HSDA implementations when it comes to naming API paths, providing a core set or resources, as well as sub-resources. There are a number of other API designs waiting in the wings to be hammered out, making more discussion around this relevant. How do we name additional API paths? Do we keep evolving a single stack of resources (expanding horizontally), or do we start grouping them and evolve using more sub-resources (expanding vertically)?</p>

<p>Right now, we are just sticking with a core set of paths for /contacts, /locations, /organizations, and /services, with /search somewhat of an outlier, or I guess wrapper. We have moved forward with sub-resource guidance, but should standard API design guidance when it comes to crafting new paths, as well as sub-paths, including the actions discussion below. This will be an ongoing discussion when it comes to API design across future versions, making it an evergreen thread that will just keep growing as the HSDA definition matures.</p>

<h3 id="verbs"><a href="https://github.com/openreferral/api-specification/issues/26">Verbs</a></h3>
<p>HTTP verbs usage was another aspect of the evolution of the HSDA specification from v1.0 to v1.1–the new specification uses its verbs. Making sure POST, PUT, and DELETE were used across all core resources, as well as sub-resources, making the entire schema open for reading and writing at all levels. This further expanded the surface of the API definition, making it manageable at all levels.</p>

<p>Beyond this expansion we need to open up the discussion regarding OPTIONS, and PATCH. Is there a need to provide partial updates using PATCH, and providing guidance on using OPTION for providing requirements associated with a resource, and the capabilities of the server behind the API. Also we should be having honest conversations about which verbs are available for sub-resources, especially when it comes to taking specific actions using HSDA paths. There is a lot more to discuss when it comes to HTTP verb usage across the HSDA specification.</p>

<h3 id="actions"><a href="https://github.com/openreferral/api-specification/issues/24">Actions</a></h3>
<p>I want to prepare for the future when we have more actions to be taken, and talk about how we approach API design in the service of taking action against resources. Right now HTTP verbs are taking care of the CRUD features for all resources and sub-resources. While I don’t have any current actions in the queue to discus, we may want to consider this as part of the schema scope and filtering discussion–allowing API consumers to request partial, and complete representations of API resources using action paths. For example: /organization/simple, or /organizations/complete.</p>

<p>As the HSDA specification matures this question will come up more and more, as vendors, and implementations require more specialized actions to be taken against resources. Ideally, we are keeping resources very resource oriented, but from experience I know this isn’t always the case. Sometimes it becomes more intuitive for API developers to take action with simple, descriptive API paths, than adding more complexity with parameters, headers, and other aspects of the APIs design. I will leave this conversation open to help guide future versions, as well as the schema scope and filtering discussions.</p>

<h3 id="parameters"><a href="https://github.com/openreferral/api-specification/issues/24">Parameters</a></h3>
<p>Currently the numbers parameters in use for any single endpoint is pretty minimal. The core resources allow for querying, and sorting, but as of version 1.1, parameters are still pretty well-defined and minimal. The only path that has an extensive set of parameters is /search, which possesses category, email, keyword, language, lat_lng, location, org_name, page, per_page, radius, service_area, and status. I’d like to to continue the discussion about which parameters should be added to other paths, as well as used to help filter the schema, and other aspects of the API design conversation.</p>

<p>I’d like to open up the parameter discussion across all HSDA paths, but I’d also like to establish a way to regularly quantify how many paths are available, as well as how loaded they are with default values, and enumerators. I’d like to feed this into overall API design guidance, helping keep API paths reflecting a microservices approach to delivering APIs. Helping ensure HSDA services do one thing, and do it well, with the right amount of control over the surface area of the request and response of each API path.</p>

<h3 id="headers"><a href="https://github.com/openreferral/api-specification/issues/5">Headers</a></h3>
<p>Augmenting the parameter discussion I want to make sure headers are an equal part of the discussion. They have the potential to play a role across several of these API design questions from versioning to schema filtering. They also will continue to emerge in authentication, management, security, and even sorting and content negotiation discussions.</p>

<p>It is common for there to be a lack of literacy in developer circles when it comes to HTTP headers. A significant portion of the discussion around header usage should always be whether of not we want to invest in HTTP literacy amongst implementors, and their developer communities, over leveraging other non-header approaches to API design. HTTP Headers are an important building block of the web that developers should understand, but educating developers around their use can be time intensive and costly when it comes to guidance.</p>

<h3 id="body"><a href="https://github.com/openreferral/api-specification/issues/25">Body</a></h3>
<p>There is an open discussion around how the body will be used across HSDA compliant implementations. Currently the body is default for POST and PUT, aka add and update. This body usage has been extended across all core resources, as well as sub-resource, requiring the complete, or sub resource representation to be part of each POST or PUT request.</p>

<p>There is no plan for any other APIs that will deviate from this approach, but we should keep this thread open to make sure we think about when the usage of the body is appropriate and when it might not be. We need to make sure that developers are able to effectively use the body, alongside headers, as well as parameters to get the desired results they are looking for.</p>

<h3 id="data-scope--filtering"><a href="https://github.com/openreferral/api-specification/issues/22">Data Scope / Filtering</a></h3>
<p>Currently the only filtering beyond pagination that is available is the query parameter available on /contact, /organizations, /locations, and /services resources. After that search is where the heaviest data scope and filtering can be filtered and defined. We need to discuss the future of this. Should the core resources have similar capabilities to /search, or should /search be a first class citizen with the majority of the filtering capabilities?</p>

<p>There needs to be more discussion around how data will be available bia default, and how it will be filtered as part of each API request. Will search be carrying most of the load, or will each core resource be given some control when it comes to filtering data. Whatever the approach it needs to be standardized across all existing paths, as well as applied to new API designs, keeping data filtering consistent across all HSDA designs. As this comes into focus I will be making sure there is a guide that provides guidance when it comes to data filtering practices in play.</p>

<h3 id="schema-scope--filtering"><a href="https://github.com/openreferral/api-specification/issues/21">Schema Scope / Filtering</a></h3>
<p>This is one of the top issues being discussed as part of the migration from v1.1 to v1.2, regarding how to not just filter data that is returned as part of API responses, but how do you filter what schema gets returned as part of the response. When it came to v1.0 to v1.1 I didn’t want to shift the response structure so that I can reduce any breaking changes for existing Ohana implementations, and open up with the community regarding the best approach for allowing schema filtering.</p>

<p>My current recommendation when it comes to the filtering of how much or how little of the schema to return with each request is to allow for schema templates to be defined and named, then enable API consumers to specify which template they’d like returned. This should be specified through either through a <a href="https://apievangelist.com/2017/05/24/considering-http-prefer-header-instead-of-field-filtering-for-my-api/">prefer header</a>, as part of the path structure as an action, or possibly through a parameter–all would accept the name of a schema template they desire (ie. simple, complete, etc.).</p>

<p>This approach to enabling schema templating could be applied at the GET, and could be also applied to POST or PUT requests. I personally recommend using a <a href="https://apievangelist.com/2017/05/24/considering-http-prefer-header-instead-of-field-filtering-for-my-api/">prefer header</a>, but I also emphasize the ease of use, and ease of defining the usage as part of documentation, and the OpenAPI definition–which it might make sense to allow for schema enablement as pat of the path name as an action. I’ll leave it to the community to ultimately decide, as with the rest of this API design and project list, I’m just looking to provide guidance, and direction, built on the feedback of the community.</p>

<h3 id="path-scope--filtering"><a href="https://github.com/openreferral/api-specification/issues/38">Path Scope / Filtering</a></h3>
<p>Next up in the scope and filtering discussion is regarding how we define, group, and present all available API paths included in the HSDA specification. With the current specification I see three distinct groups of API paths emerging: 1) core resources (/contacts, /organizations, /locations, /services), and 2) sub resources (/physical-address, /postal-address, /phones, and more), then the more utility aspects of meta data, taxonomy, and eventually webhooks.</p>

<p>When a new user lands on the API documentation, they should see the core resources, and not be burdened with the cognitive load associated sub resources or the more utility aspects of HSDA consumption. However, once ready more advanced API paths are available. The grouping and filtering of the API paths can be defined as part of the OpenAPI definitions for the API(s), as well as the APIs.json index for the site. This path grouping will allow for API consumers to limit scope and filter which API paths are available in the documentation, and possibly with SDKs, testing, and other aspects of integration.</p>

<p>There are additional API projects on the table that might warrant the addition of new API groups, beyond core resources, sub resources, and utility paths. The approval, feedback, and messaging discussions might require their own group, allowing them to be separated in documentation, code, testing, and other areas–reducing the load for new users, while expanding the opportunities for more advanced consumers. Eventually there might be a one to one connection between API path groups, and the API projects in the queue, allowing for different groups of APIs to be moved forward at different rates, and involve different groups of API consumers and vendors in the process.</p>

<h3 id="project-scope--filtering"><a href="https://github.com/openreferral/api-specification/issues/40">Project Scope / Filtering</a></h3>
<p>Adding the fourth dimension to this scope / filtering discussion, I’m proposing we discuss how projects are defined and isolated, which can allow them to move forward at different rates, and be reflected in documentation, code, and other resources–allowing for filtering by consumers. This will drive the path filtering described above, but apply beyond just the API, and influencing documentation, SDKs, testing, monitoring, validation, and other aspects of API operations.</p>

<p>With this tier I am looking to decouple API projects from one another, and from the core specification. I want the core HSDS/A specification to stay focused on doing one thing well, but I’d like to establish a clear way to move forward complimentary groups of API definitions, and supporting tooling independently of the core specification. As we prepare to begin the journey from version 1.1 to 1.2, there are a number of significant projects on the table, and we need a way to isolate and decouple each additional API project in the same we we do with individual API resources–keeping them clearly defined, focused on specific problem set, and a buffet of resources that the community can choose where they’d like to participate.</p>

<h3 id="pagination"><a href="https://github.com/openreferral/api-specification/issues/10">Pagination</a></h3>
<p>This is the discussion around how results will be paginated, allowing for efficient or complete requests to be requested, and navigate through large volumes of human services data. We need to be discussing how we will evolve the current approach to using page= and per_page= to articulate pagination. This approach is a common, well understood way to allow developers to paginate, but we need to keep discussion open as we answer some of the other API design questions on the table.</p>

<p>The pagination topic overlaps with the hypermedia and response structure discussion. Eventually we may offer pagination as part of a response envelope, or relational links provided as part of the response when using JSON API, HAL, or other media type. Right now we will leave pagination as it is, but we should be thinking about how it will evolve alongside all other API design conversations in this list.</p>

<h3 id="sorting"><a href="https://github.com/openreferral/api-specification/issues/12">Sorting</a></h3>
<p>According to the current Ohana API implementation, which is the HSDA v1.0 definition, the guidance for sorting availability is as follows:</p>

<blockquote>
  <p>Except for location-based and keyword-based searches, results are sorted by location id in ascending order. Location-based searches (those that use the lat_lng or location parameter) are sorted by distance, with the ones closest to the search query appearing first. keyword searches are sorted by relevance since they perform a full-text search in various fields across various tables.</p>
</blockquote>

<p>This guidance follows the API definition from version 1.0 to 1.2, but for future versions we should be considering providing further guidance regarding sorting of results. I’d like to get more feedback from the community on how they are providing data sorting capabilities for API consumes, or even as part of web and mobile applications.</p>

<h3 id="response-structure"><a href="https://github.com/openreferral/api-specification/issues/6">Response Structure</a></h3>
<p>Right now the API responses for HSDA are pretty flat, like the schema. As part of the move from version 1.1 to 1.2 we need to be expanding on them, allowing for sub-resources to be included. This conversation will be heavily influenced by the schema filtering conversation above, as well as potentially the hypermedia and content negotiation discussions below. If we are gong to expand on the the schema being returned with API response we should be discussing all possible changes to the schema at once.</p>

<p>This conversation is meant to bring together the API schema filtering, hypermedia, and content negotiation conversations into a single discussion regarding the overall structure of a response, by default, as well as through filtering at the path, parameter, or header levels. I’d like to see  HSDA responses expand to accommodate sub resources, but also the relationships between resources, as well as assisting with pagination, sorting, and other aspects of data, schema, and path filtering. I am looking to make sure the expansion of the response structure be more inclusive beyond just talk of sub resource access.</p>

<h3 id="hypermedia"><a href="https://github.com/openreferral/api-specification/issues/7">Hypermedia</a></h3>
<p>I really want to see a hypermedia fork in the HSDA definition, allowing more advanced users to negotiate and hypermedia version of the specification, instead of the more simpler, or even advanced default versions of the API. I recommend the adoption of HAL, Siren, or JSON API, as an alternate edition of an HSDA implementation. This expansion of the design of the HSDA specification would not impact the current version, but would allow for another dimension of API consumption and integration.</p>

<p>The relationships between human services data, and the semantic nature of the data really begs for a hypermedia solution. It would allow more meaningful API responses, and defining of relationships between resources, and emphasis of the taxonomy. I will be encouraging a separate, but complimentary version of HSDA that uses one of the leading hypermedia media types. I’d like to ensure there is community awareness of the potential of this approach, and support for investing in this as part of the HSDA design strategy.</p>

<h3 id="status-codes"><a href="https://github.com/openreferral/api-specification/issues/3">Status Codes</a></h3>
<p>One of the areas of design around version 1.1 of the HSDA specification that was put off until future versions is guidance when it comes to API response status and error codes. Right now the OpenAPI definition for version 1.1 of the HSDA specification only suggests a 200 successful response, returning a reference to the appropriate HSDS schema. A project needs to be started that would provider further guidance for 300, 400, and 500 series status codes, as well as error responses.</p>

<p>Each HSDA path should provide guidance on all relevant HTTP Status Codes, but should also provide guidance regarding the error object schema returned as part of every possible API response. Helping standardize how errors are communicated, and provide further guidance on how to help API consumers navigate a solution. Currently there is no guidance when it comes to HTTP responses and errors, something that should be considered in version 1.2 or 1.3, depending on available resources.</p>

<h3 id="content-negotiation"><a href="https://github.com/openreferral/api-specification/issues/39">Content Negotiation</a></h3>
<p>Augmenting other conversations around schema filtering, API response structure, and hypermedia, I want to make sure content negotiation stays part of the conversation. This aspect of API design will significantly impact API integration, and the evolution of the API specification. I want to make sure vendors, and other key actors are aware of it as an option, and can participate in the conversation regarding the different content types.</p>

<p>This conversation should begin with making CSV and HTML representations of the data available as part of the API response structure alongside the current JSON representations. API consumers should have the option to get raw HTML, CSV, and JSON through content negotiation–with JSON remaining as the default. Then the conversation should evolve to consider HSDA specific content type designation, as well as implementation of a leading hypermedia media type like JSON API, HAL, or Siren.</p>

<p>Content negotiation plays an important role in versioning the HSDA specification, as well as providing different dimensions for dealing with more complex integrations, as well as other aspects of operations like pagination, sorting, access to sub resources, other actions and even data, schema, and path filtering. Like headers, the mainstream developer community tends to not all be aware of content negotiation, but the benefits of adopting far outweigh the overhead involved with bringing developers up to speed.</p>

<p>That concludes the list of API design conversations that are occurring as part of the move from version 1.0 to 1.1, and will set the stage for the move towards 1.2, and beyond. It is a lot to consider, but it is a manageable amount for the community to think about as part of the version 1.1 feedback cycle. Allowing us to make a community informed decision regarding what should be focused on with each release–delivering what matters to the community.</p>

<h2 id="api-projects">API Projects</h2>
<p>As the version 1.0 to 1.1 migration occurred several projects were identified, or suggested for consideration. I want to make sure all these projects are on the table as part of the evolution of HSDA, beyond just the current API design discussion occurring. These are the projects we added to the specification that are moving forward but will have varying degrees of impact on the core API definition.</p>

<h3 id="taxonomy"><a href="https://github.com/openreferral/api-specification/issues/19">Taxonomy</a></h3>
<p>There are two objects included in version 1.1 of the Human Services Data Specification (HSDS) that deal with taxonomy, the service_taxonomy object, and the core taxonomy object. I purposely left these aspects of the schema out of version 1.1 of HSDA. I wanted to see more discussion regarding taxonomy before we included in the specification. This is one of the first areas that influenced the above discussions regarding path scope and filtering, as well as project scope and filtering.</p>

<p>I’d like to see taxonomy exist as a separate set of paths, as a separate project, and out of the core specification. In addition to further discussion about what is HSDA taxonomy, I’d like to see  more consideration regarding what exactly is acceptable levels of HSDA compliant taxonomy. Ideally, the definition allows for multiple taxonomy, and possibly even a direct relationship between the available content types and a taxonomy, allowing for a more meaningful API response.</p>

<p>I will leave open a Github issue to discuss taxonomy, and either move forward as entirely separate schema, or inclusion in version 1.2, 1.3 of the core HSDA definition. One aspect of this delay is to ensure that my awareness of available taxonomies is up to snuff to help provide guidance. I’m just not aware of everything out there, as well as an intimacy the leading taxonomies in use–I need to hear more from vendors and implementors on this subject before I feel confident in making any decision.</p>

<h3 id="metadata"><a href="https://github.com/openreferral/api-specification/issues/28">Metadata</a></h3>
<p>The metadata, and the meta_table_description objects v1.1 of HSDA were two elements I also left out of version 1.1 of HSDA. I felt like there should be more discussion around API management, logging, and other aspects of API operations that feed into this area, before we settled in on an API design to satisfy the HSDA metadata conversation. I’d like to hear more from human services implementors regarding what metadata they desire before we connect the existing schema to the API.</p>

<p>The metadata conversation overlaps with the approval and feedback project. There are aspects of logging and meta data collection and storage that will contribute to the transactional nature of any approval and feedback solution. There is also conversation going on regarding privacy concerns around API access to HSDS data, and logging, auditing that occurs at the metadata level. This thread covers these conversations, and is looking to establish a separate group of API paths, and separate project to drive documentation, and other aspects of API operations.</p>

<h3 id="approval--feedback"><a href="https://github.com/openreferral/api-specification/issues/34">Approval &amp; Feedback</a></h3>
<p>One of the projects that came up recently was about working to define the layer that allows developers to add, update, and delete data via the API. Eventually through the HSDA specification we to encourage 3rd party developers, and external stakeholders to help curate and maintain critical human services data within a community, through trusted partners.</p>

<p>HSDA allows for the reading and writing of organizations, locations, and services for any given area. I am looking to provide guidance on how API implementors can allow for POST, PUT, PATCH, and DELETE on their API, but require approval before any changing transaction is actually executed. Requiring the approval of an internal system administrator to ultimately give the thumbs up or thumbs down regarding whether or not the change will actually occur.</p>

<p>A process which immediately begs for the ability to have multiple administrators or even possibly involving external actors. How can we allow organizations to have a vote in approving changes to their data? How can multiple data stewards be notified of a change, and given the ability to approve or disprove, logging every step along the way? Allowing any change to be approved, reviewed, audited, and even rolled back. Making public data management a community affair, with observability and transparency built in by default.</p>

<p>I am doing research into different approaches to tackling this, ranging from community approaches like Wikipedia, to publish and subscribe, and other events or webhook models. I am looking for technological solutions to opening up approval to the API request and response structure, with accompanying API and webhook surface area for managing all aspects of the approval of any API changes. If you know of any interesting solutions to this problem I’d love to hear more, so that I can include in my research, future storytelling, and ultimately the specification for the Open Referral Human Services Data Specification and API.</p>

<h3 id="universal-unique-ids"><a href="https://github.com/openreferral/api-specification/issues/35">Universal Unique IDs</a></h3>
<p>How will we allow for a universal unique ID system for all organizations, locations, and services, providing some provenance on the origin of the record. There is a solid conversation started about how to approach a universal ID system to live alongside, or directly as part of the core HSDA specification–depending on how we decide to approach project scope. Ideally, a universal ID system isn’t pat of being compliant, but could add a healthy layer of certification for some leading providers.</p>

<p>More research needs to be done regarding how universal IDs are handled in other industries. An exhaustive search needs to be conducted regarding any existing standards and guidance that can help direct this discussion. This approach to handling identifiers will have a significant impact on individual API implementations, as well as the overall HSDA definition. More importantly, it will set the stage for future HSDA aggregation and federation, allowing HSDA implementations to work together more seamlessly, and better serve end-uses.</p>

<h3 id="messaging"><a href="https://github.com/openreferral/api-specification/issues/37">Messaging</a></h3>
<p>I separated this project out of the approval and feedback project. I am suggesting that we isolate the messaging guidance for APIs, setting a standard for how you communicate within a single implementation as well across implementations. There are a number of messaging API standards and best practices available out there, as well as existing messaging APIs that are already in use by human services practitioners, including social channels like Facebook and Twitter, but also private channels like Slack.</p>

<p>HSDA compliant messaging channels should live as a separate project, and set of API path specifications. It should augment the core HSDA definition, overlaying with existing contact information, but it should also be dovetailed with new projects like approval and feedback system. More research needs to be conducted on existing messaging API standards, and leading channels that existing human services implementations and their software vendors are already using.</p>

<h3 id="webhooks"><a href="https://github.com/openreferral/api-specification/issues/35">Webhooks</a></h3>
<p>I want to begin separate project for handling an important aspect of any API operations, and not just being their to receive requests, but can also push information externally, and respond to scheduled, or event driven aspects of API operations. Webhooks will play a role in the approval and feedback system, as well as the metadata, and messaging projects–eventually touching all aspects of the core HSDA resources, and separate projects.</p>

<p>Alongside the approval and feedback, universal id, and messaging projects, webhooks will set the stage for the future of HSDA, where individual city and regional implementations can work together, share information, federate and share responsibility in updates and changes. Webhooks will be how each separate implementation will work in concert, making the deliver of human services more real time, and orchestrated across providers, achieving API the vision of Open Referral founder Greg Bloom.</p>

<h2 id="what-is-next">What Is Next?</h2>
<p>We have a lot on the table to discuss currently. We need to settle some pretty important API design discussions that will continue to have an impact on API operations for a long time. I want to help push forward the conversation around these API design discussions, and get these API projects moving forward in tandem. I need more input from the vendors, and the community around some of the pressing discussions, and then I’m confident we can settle in on what the final version 1.1 of the API specification should be, and what work we want to tackle as part of 1.2 and beyond. I’m feeling like with a little discussion we can find a path forward to reach 1.2 in the fall of 2017.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/13/moving-the-human-services-api-specification-from-version-11-to-12/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/12/challenges-when-aggregating-data-from-across-the-years/">Challenges When Aggregating Data Published Across Many Years</a></h3>
        <span class="post-date">12 Jul 2017</span>
        <p><a href="http://funding.hackeducation.com/"><img src="https://s3.amazonaws.com/kinlane-productions/hack-education/ed-tech-investment-research.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="http://funding.hackeducation.com/">My partner in crime is working on a large data aggregation project regarding ed-tech funding</a>. She is publishing data to Google Sheets, and I’m helping her develop Jekyll templates she can fork and expand using Github when it comes to publishing and telling stories around this data across her network of sites. Like API Evangelist, <a href="https://github.com/hackeducation/">Hack Education runs as a network of Github repositories</a>, with a common template across them–we call the overlap between API Evangelist, <a href="http://contrafabulists.com/">Contrafabulists</a>.</p>

<p>One of the smaller projects she is working on as part of her ed-tech funding research involves pulling the grants made by the Gates Foundation since the 1990s. Similar to my story a couple weeks ago about my friend David Kernohan, <a href="https://apievangelist.com/2017/06/28/i-have-two-interesting-apis-and-i-am-not-a-developer-what-do-i-do/">where he was wanting to pull data from multiple sources</a>, and aggregate into a single, workable project. Audrey is looking to pull data from a single source, but because the data spans almost 20 years–it ends up being a lot like aggregating data from across multiple sources.</p>

<p>A couple of the challenges she is facing trying to gather the data, and aggregate as a common dataset are:</p>

<ul>
  <li><strong>PDF</strong> - The enemy of any open data advocate is the PDF, and a portion of her research data data is only available in PDF format which translates into a good deal of manual work.</li>
  <li><strong>Search</strong> - Other portions of the data is available via the web, but obfuscated behind search forms requiring many different searches to occur, with paginated results to navigate.</li>
  <li><strong>Scraping</strong> - The lack of APIs, CSV, XML, and other machine readable results raises the bar when it comes to aggregating and normalizing data across many years, making scraping a consideration, but because of PDFs, and obfuscated HTML pages behind a search, even scraping will have a significant costs.</li>
  <li><strong>Format</strong> - Even once you’ve aggregated data from across the many sources, there is a challenge with it being in different formats. Some years are broken down by topic, while others are geographically based. All of this requires a significant amount of overhead to normalize and bring into focus.</li>
  <li><strong>Manual</strong> - Ultimately Audrey has a lot of work ahead of her, manually pulling PDFs and performing searches, then copying and pasting data locally. Then she’ll have to roll up her sleeves to normalize all the data she has aggregated into a single, coherent vision of where the foundation has put its money.</li>
</ul>

<p>Data research takes time, and is tedious, mind numbing work. I encounter many projects like hers where I have to make a decision between scraping or manually aggregating and normalizing data–each project will have it’s own pros and cons. I wish I could help, but it sounds like it will end up being a significant amount of manual labor to establish a coherent set of data in Google Sheets. Once, she is done though, she has all the tools in place to publish as YAML to Github, and get to work telling stories around the data across her work using Jekyll and Liquid. I’m also helping her make sure she has a JSON representation of each of her data projects, allowing others to build on top of her hard work.</p>

<p>I wish all companies, organizations, institutions, and agencies would think about how they publish their data publicly. It’s easy to think that data stewards will have ill intentions when it comes to publishing data in a variety of formats like they do, but more likely it is just a change of stewardship when it comes to managing and publishing the data. Different folks will have different visions of what sharing data on the web needs to look like, and have different tools available to them, and without a clear strategy you’ll end up with a mosaic of published data over the years. Which is why I’m telling her story. I am hoping to possibly influence one or two data stewards, or would-be data stewards when it comes to the importance of pausing for a moment and thinking through your strategy for standardizing how you store and publish your data online.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/12/challenges-when-aggregating-data-from-across-the-years/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/12/20k-40k-60k-and-80k-foot-levels-of-industry-api-design-guidance/">20K, 40K, 60K, and 80K Foot Levels Of Industry API Design Guidance</a></h3>
        <span class="post-date">12 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/definition-of-high-altitude.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p><a href="http://org.open.referral.adopta.agency/">I am moving my Human Services Data API (HSDA) work</a> forward and one of the top items on the list to consider as part of the move from version 1.1 to 1.2 is all around the scope of the API design portion of the standard. We are at a phase where the API design still very much reflects the Human Services Data Specification (HSDS)–basically a very CRUD (Create, Read, Update and Delete) API. With version 1.2 I need to begin considering the needs of API consumers a little more, looking to vendors and real world practitioners to help understand what the next version(s) of the API definition will/should contain.</p>

<p>The most prominent discussion in the move from version 1.1 to 1.2 centers around scope of API design at four distinct levels of this work, where we are looking to move forward a variety of API design concerns for a large group of API consumers:</p>

<ul>
  <li><a href="https://github.com/openreferral/api-specification/issues/22">Data Scope / Filtering</a> - Discussions around how to filter data, allowing API consumers to search across the contents of any HSDA implementation, getting exactly the data they need, no more, no less.</li>
  <li><a href="https://github.com/openreferral/api-specification/issues/21">Schema Scope / Filtering</a> - Considering the design of simple, standard, or full schema responses that can specified using a prefer header, parameter, or path levels.</li>
  <li><a href="https://github.com/openreferral/api-specification/issues/38">Path Scope / Filtering</a> - How are API paths going to be group and organized, allowing a large surface area to be shared via documentation (APIs.json) in a way that new API consumers can start simple, advanced users can get what they need, and serving as many needs in between as we can.</li>
  <li><a href="https://github.com/openreferral/api-specification/issues/40">Project Scope / Filtering</a> - Adding the fourth dimension to this scope / filtering discussion, I’m proposing we discuss how projects are defined and isolated, which can allow them to move forward at different rates, and be reflected in documentation, code, and other resources–allowing for filtering by consumers, as  well as prioritization by vendors involved in the API design discussion.</li>
</ul>

<p>In short I have a large number of desires put on the table by vendors and practitioners. There is a mix of desire to load up as much functionality and API design guidance as we can at the single path level–meaning /organizations, /locations, and /services will allow you to get as much, or as little, as you desire. In this same conversation I have to defend the interests of newcomers, allowing them to easily learn about, and get what they need from these three distinct API paths, without loading them up with too much functionality. While also defend the long tail of needs for mobile, voice, and other leading edge application developers.</p>

<p>I’m looking at this discussion in these four dimensions, but I am trying to apply a horizontal or vertical approach in all four dimensions. Meaning, do I access or filter the amount of data I receive vertically with parameters or headers at the single API path level, or do I access and filter the amount of data I want horizontally across many separate API paths. The same logic applies to the API schema level with accessing vertically at the same path, by adding many subpaths, or do we approach horizontally with new paths. This continues at the API path, and project levels–how do discuss, develop, evolve, and allow API consumers to filter and only get at the API paths and projects they need–limiting the scope for new users, but meeting the demand of vendors, implementors, analysts, and other power consumers.</p>

<p>Aight, ok. Phew. I just needed to get that out. Not 100% sure it makes sense, but it is a framework I’m running with for a group conversation I’m having tomorrow–so we’ll see how it goes. One significant difference in this API design process from others is that it is not about any single API implementation. It is focused on moving forward a single API definition, or in the case of this discussion, many little API definition discussions, with lots of overlap, and under a single umbrella–to support thousands of API implementations. I’ll be publishing another piece shortly which zooms out to the 100K level of my HSDA work, where I’d consider this to be a little 20K (data), 40K (schema), 60K (path), and 80K (project) levels. I just needed to get a handle on this piece–if you actually read this far in the post, you are pretty geeky, and probably need a hobby (HSDA is mine).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/12/20k-40k-60k-and-80k-foot-levels-of-industry-api-design-guidance/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/12/providing-solid-examples-that-api-consumers-can-learn-from-like-slack-app-blueprints/">Providing Solid Examples That API Consumers Can Learn From Like Slack App Blueprints</a></h3>
        <span class="post-date">12 Jul 2017</span>
        <p><a href="https://api.slack.com/best-practices/blueprints"><img src="https://s3.amazonaws.com/kinlane-productions/slack/slack-app-blueprints.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>People often learn through example. Before I’d ever consider myself a software engineer, I’d consider myself a reverse software engineer. 93% of what I know has been extracted from the work of others. Even with 7% being of my own creation, it is always heavily influenced by the work of others. People emulate what they know, what they see, and use. This is why as an API provider you should be showcasing best practices, positive examples, and healthy blueprints of what API consumers could (should) be doing.</p>

<p><a href="https://api.slack.com/best-practices/blueprints">You can see this in action with Slack’s best practice blueprints page</a>, where they provide six blueprints of applications that API consumers should be learning from. Slack doesn’t just provide a title, description and image of example applications, it is truly a blueprint–providing diagrams, links to documentation, code samples, and other essential knowledge you will need to successfully develop an application on Slack. Providing six solid examples that anyone can reverse engineer to understand how Slack application development could (should) work.</p>

<p>Slack app blueprints is just one component of <a href="https://api.slack.com/slack-apps">a pretty sophisticated getting started section offered as part of the Slack API ecosystem</a>. I am adding application blueprint as a building block to my <a href="http://getting-started.apievangelist.com/">getting started API research</a>, and adding it as a dimension to my <a href="http://documentation.apievangelist.com/">API documentation</a> &amp; <a href="http://sdk.apievangelist.com/">SDK research</a>–the overlap in these areas seem like it should be strong to me. Coming across Slack app blueprints, and writing this story has reminded me that I also need to write another piece on the Slack ecosystem, and generate an outline of all the building blocks they are using in their API ecosystem, and create an updated blueprint for successful API operations that other API providers can emulate.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/12/providing-solid-examples-that-api-consumers-can-learn-from-like-slack-app-blueprints/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/12/a-zapier-advocate-and-dedicated-api-resources-page-for-your-company/">A Zapier Advocate And Dedicated API Resources Page For Your Company</a></h3>
        <span class="post-date">12 Jul 2017</span>
        <p><a href="ttps://zapier.com"><img src="https://s3.amazonaws.com/kinlane-productions/zapier/zapier-icons.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I am spending time going through some of the most relevant APIs I know of online today, working to create some 101 training materials for average folks to take advantage of. I’m looking through these APIs: Twitter, Google Sheets, Github, Flickr, Instagram, Facebook, YouTube, Slack, Dropbox, Paypal, Weather Underground, Spotify, Google Maps, Reddit, Pinterest, NY Times, Twilio, Stripe, SendGrid, Algolia, Keen, Census, Yelp, Walgreens. I feel they are some of the most useful solutions in the average business person who is API curious.</p>

<p>With these new lessons I’m trying to continue my work evangelizing APIs amongst the normals, helping them understand what APIs are, and what is possible when you put them to work. Once I introduce folks to each API I’m left with the challenge of how do I actually onboard them with each API when they aren’t actually a programmer. The number one way I’m helping alleviate this problem is by including <a href="https://zapier.com">Zapier</a> examples with each of my API lessons, helping folks understand that they can quickly get up and running with each API using the Zapier integration platform as a service (iPaaS). I will be including one or more Zapier examples along with each of my API 101 lessons, helping normal folk put what they’ve learned about APIs to use–hopefully making each lesson a little more sticky.</p>

<p>One of the primary targets for my lessons is the average worker at small, medium, and enterprise businesses, trying to help them understand that APIs aren’t just for developers, and that they can be putting APIs to use in their world. I tried to pick a handful of APIs that are relevant and useful in their daily lives, and helping them become aware of useful Zapier recipes they can adopt in their daily work. I’m looking to encourage users to become more API-literate, and begin connecting and orchestrating using APIs in their daily work. I’m hoping that eventually they will become confident enough by leverage APIs using Zapier that they will eventually become an advocate within their companies and organizations.</p>

<p>In my opinion, each company could really use a Zapier advocate. To help incentivize this behavior I’m  going to show folks how they can become an advocate for APIs and Zapier at their company, and provide them with some templates for how they can publish API training material on a page dedicated to Zapier within the company firewewall, or on some sort of company portal that the rest of the company has access to. Similar to how <a href="http://apievangelist.com/2014/03/13/api-management-adding-reciprocity-building-blocks/">I’ve been advocating API providers to publish an integration page in their developer portals</a>, I’m looking to also encourage business users to publish a similar page of useful Zaps involving API that are relevant to their company–allowing other folks at a company to learn, explore, and implement useful recipes that can help them be more successful  in their work.</p>

<p>A significant portion of my work as API Evangelist is dedicated to pushing forward the conversation around APIs, telling stories about the leading and bleeding edge of APIs, but I’m trying to not forget my roots, and my original mission to help non-developers understand the API potential. I feel that a wealth of <a href="http://101.apievangelist.com">API 101 materials</a>, combined with examples of Zapier advocacy and storytelling, and pages dedicated to sharing Zapier recipes (Zaps) will help go a long ways to help encourage adoption amongst business users. My first API 101 lessons are rolling off the assembly line, and the next step is to create an example page where these lessons can be published, including other resources and recipes for using Zapier to exercise each lessons learned. If you would like to learn how to become a <a href="https://zapier.com">Zapier</a> advocate at your company please drop me a line, I’m looking for a few beta users to help me push forward this work in a meaningful way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/12/a-zapier-advocate-and-dedicated-api-resources-page-for-your-company/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/11/each-airtable-datastore-comes-with-complete-api-and-developer-portal/">Each Airtable Datastore Comes With Complete API and Developer Portal</a></h3>
        <span class="post-date">11 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/airtable/airtable-api-for-or2.png" width="40%" style="padding: 15px;" align="right" /></p>
<p>I see a lot of tools come across my desk each week, and I have to be honest I don’t alway fully get what they are and what they do. There are many reasons why I overlook interesting applications, but the most common reason is because I’m too busy and do not have the time to fully play with a solution. One application I’ve been keeping an eye on as part of my work is <a href="https://airtable.com">Airtable</a>, which I have to be honest, I didn’t get what they were doing, or really I just didn’t notice because I was too busy.</p>

<p>Airtable is part spreadsheet, part database, that operates as a simple, easy to use web application, which with a push of a button, you can publish an API from. You don’t just get an API by default with each Airtable, you get a pretty robust developer portal for your API complete with  good looking API documentation. Allowing you to go from an Airtable (spreadsheet / database) to API and documentation–no coding necessary. Trust me. Try it out, anyone can create an Airtable and publish an API that any developer can visit and quickly understand what is going on.</p>

<p>As a developer, API deployment still feels like it can be a lot of work. Then, once I take off my programmers hat, and put on my business user hat, I see that there are some very easy to use solutions like <a href="https://airtable.com">Airtable</a> available to me. Knowing how to code is almost slowing me down when it comes API deployment. Sure, the APIs that Airtable publishes aren’t the perfectly designed, artisanally crafted API I make with my bare hands, but they work just as well as mine. Most importantly, they get business done. No coding necessary. Something that anyone can do without the burden of programming.</p>

<p><a href="https://airtable.com">Airtable provides me another solution</a> that I can recommend that my readers and clients should consider using when managing their data, which will also allow them to easily deploy an API for developers to build applications against.<a href="https://airtable.com/integrations">I also notice that Airtable has a whole API integration part of their platform, which allows you to integrate your Airtables into other APIs</a>–something I will have to write about separately in a future post. I just wanted to make sure and take the time to properly add Airtable to my research, and write a story about them so that they are in my brain, available for recall when people are asking me for easy to use solutions that will help them deploy an API.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/11/each-airtable-datastore-comes-with-complete-api-and-developer-portal/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/11/when-you-publish-a-google-sheet-to-the-web-it-als-becomes-an-api/">When You Publish A Google Sheet To The Web It Also Becomes An API</a></h3>
        <span class="post-date">11 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/google-sheets/google-sheets-icon.jpg" align="right" width="30%" style="padding: 15px;" /></p>
<p>When you take any Google Sheet and choose to publish it to the web, you immediately get an API. Well, you get the HTML representation of the spreadsheet (shared with the web), and if you know the right way to ask, you also can get the JSON representation of the spreadsheet–which gives you an interface you can program against in any application.</p>

<p>Articles I curate, the companies, institutions, organizations, government agencies, and everything else I track on lives in Google Sheets that are published to the web in this way. When you are viewing any Google Sheet in your browser you are viewing it using a URL like:</p>

<p>https://docs.google.com/spreadsheets/d/[sheet_id]/edit</p>

<p>Of course, [sheet_id] is replaced with the actual id for your sheet, but the URL demonstrates what you will see. Once you publish your Google sheet to the web you are given a slight variation on that url:</p>

<p>https://docs.google.com/spreadsheets/d/[sheet_id]/pubhtml</p>

<p>This is the URL you will share with the public, allowing them to view the data you have in your spreadsheet in their browsers. In order to get at a JSON representation of the data you just need to learn the right way to craft the URL using the same sheet id:</p>

<p>https://spreadsheets.google.com/feeds/list/[sheet_id]/default/public/values?alt=json</p>

<p>Ok, one thing I have to come clean on is that the JSON available for each Google sheet is not the most intuitive JSON you will come across, but once you learn what is going on you can easily consume the data within a spreadsheet using any programming languages. Personally, I use a <a href="https://github.com/jsoma/tabletop">JavaScript library called tabletop.js</a> that quickly helps you make sense of a spreadsheet and get to work using the data in any (JavaScript) application.</p>

<p>The fastest, lowest cost way to deploy an API is to put some data in a Google Sheet, and hit publish to the web. Ok, its not a full blown API, it’s just JSON available at a public URL, but it does provide an interface you can program against when developing an application. I take all the data I have in spreadsheets and publish to Github as YAML, and then make static APIs available using that YAML in XML, CSV, JSON, Atom, or any other format that I need. Taking the load of Google, creating a cached version at any point in time that runs on Github, in a versioned repository that anyone can fork, or integrate into any workflow.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/11/when-you-publish-a-google-sheet-to-the-web-it-als-becomes-an-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/11/either-you-own-the-conversation-around-your-apis-or-someone-else-will/">Either You Own The Conversation Around Your APIs Or Someone Else Will</a></h3>
        <span class="post-date">11 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/rogue/tinder-api-google-search.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I was looking at how many of the top mobile applications in the iTunes story actually had a public API presence, and was finding it very telling what came up in the Google search results for each company when I searched [company name] + API. It tells a lot about how a company sees the world, when they don’t have a public API presence, but they have a very public mobile application that uses APIs.</p>

<p>An example of this is with Tinder, where the top listings are all Github rogue API repositories, when you Google “Tinder API”. Tinder doesn’t own the conversation when it comes to their own APIs. While the Tinder APIs are public, and well documented, Tinder prefers acting like they are private–they aren’t. Pinterest uses SSL pinning, but <a href="https://ritcsec.wordpress.com/2016/12/11/bypassing-certificate-pinning-on-tinder/">there is even a good amount of information out there at how to get around that</a>, making the mapping out and documenting of Tinder APIs a pretty doable thing.</p>

<p>Honestly, I don’t care about Tinder’s APIs. They are just an easy example to point a finger at and use as a poster child. I don’t even expect them to have fully public APIs that any developer could use without permission. Sure, lock that shit down, but provide a sandbox, and make sure every application gets approval before they can more access to live data. Make sure that you own the API conversation by having a developers portal, and provide information regarding what it takes to get access, and maybe some day actually become an approved partner.</p>

<p>I’m not saying that every company should have freely available public APIs. I’m saying every company should own the public conversation around their APIs, no matter what their strategy for developing applications around a platform’s APIs. Have a presence. Own the conversation. Have a door for application developers to walk, even if there is a waiting room. Not all applications will be competing with your own web, mobile, device, or network applications. Some will be about enabling data portability for you users, or maybe provide useful access aggregate data for use in visualizations–you never know what folks will be bringing to the table, why keep the door closed?</p>

<p>I understand. You may not be all team API like I am, but you are using APIs to drive your mobile experience. I just don’t get why you wouldn’t want to own the conversation around these APIs. You are leaving so much on the table. If your mobile app is finding success, people will want access to the goodness going on behind it–<a href="http://apievangelist.com/2011/02/08/instagram-launches-api/">a rogue API is what kickstarted the Instagram API in the early days</a>. It is pretty easy to reverse engineer any mobile application, and map out the surface area of the API behind, as well as the authentication in play. Either you own the conversation around your API, or someone will step up and do it for you in todays online world.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/11/either-you-own-the-conversation-around-your-apis-or-someone-else-will/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/11/locking-down-drones-and-iot-devices-by-manufacturers/">Locking Down Drones And IoT Devices By Manufacturers</a></h3>
        <span class="post-date">11 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/drones/drone-rock-outdoors.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I have been following stories about, as well as personally experiencing DJI restricting where their drones can fly, going beyond just warning you about restricted areas and actually locking down or restricting your drone capabilities. <a href="https://motherboard.vice.com/en_us/article/3knkgn/dji-is-locking-down-its-drones-against-a-growing-army-of-diy-hackers">So it was interesting to also read a post in Motherboard about the company also locking down drones to prevent against hacking, modifying, and tweaking your DJI drones as you wish</a>. Drones for me are a poster child for the entire Internet of Things (IoT), and I think DJI’s approach is a sign of what is to come for all Internet connected devices.</p>

<p>In coming years, there will be a lot that the IoT community can learn from the drone space. From the technical to regulatory, drones will be pushing forward conversations about our networks, cameras, security, privacy, surveillance, and corporate and government control over us, and our devices. Drones stimulate some interesting emotions within people associated with the industry, but more importantly people who know nothing about drones, and will be weighing in on regulation at the municipal, all the way up to the federal and international levels.</p>

<p>I thought it was interesting when DJI began enforcing the recommendations I get in the dashboard for my drones, and requiring that I update my drones, RC controller, and mobile applications to reduce their liability regarding what I an actually doing with my devices. However, locking down drones so people can’t modify, augment, or fix their own drones is a whole other layer to this discussion that isn’t just about stopping ISIS from strapping bombs to their drones, it is also about maintaining sovereignty over their creations, and limiting what we can do as owners when it comes to fixing our devices. <a href="https://www.theguardian.com/environment/2017/mar/06/nebraska-farmers-right-to-repair-john-deere-apple">We already see the right to fix conversation bubble up in the John Deere ecosystem</a>, but it is something we will continue to see showing up in IoT ecosystems across many different business sectors.</p>

<p><a href="http://kinlane.com/2017/01/26/the-digital-things-that-happen-in-the-privacy-of-our-homes/">The bold entry into our homes and lives that IoT device manufacturers are making amazes me</a>, but what amazes me even more is how consumers allow this to happen with little resistance. This is another outcome from the drone sector I believe we’ll see more of, is drone operators standing up to defend their right to fix, as well as push back own data, content, an algorithmic ownership over what is produced using devices. Sadly consumers do not understand the value of their data, but hobbyists and commercial operators of drones, and hopefully other devices, do see the value of it, and will begin to shift the balance when it comes to who is profiting off the data our devices are generating.</p>

<p>There will be many technical, business, and political lessons to be learned from the drone space in coming years. I’m strangely thankful that my <a href="http://dronerecovery.org">Drone Recovery project</a> happened, because before that summer I really was not interested in drones, but now I’m not just interested, I own three drones, and have an active interest in understanding what manufacturers like DJI are doing. I’m feel that what DJI is doing with their platform will set a precedent (good and bad) for other IoT operators to follow–something I’ll be keeping a close eye on.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/11/locking-down-drones-and-iot-devices-by-manufacturers/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/10/github-serverless/">Github Serverless</a></h3>
        <span class="post-date">10 Jul 2017</span>
        <p><a href="https://octodex.github.com/daftpunktocat-thomas"><img src="https://octodex.github.com/images/daftpunktocat-thomas.gif" align="right" width="30%" style="padding: 15px;" /></a></p>
<p>I run the entire front-end of my online presence using Github. <a href="http://apievangelist.com/api-lifecycle/">All my API Evangelist research lives as open repositories on Github, with the website running Jekyll, hosted on Github Pages</a>. My front-end is all HTML, JavaScript, and CSS, that leverages YAML data, and displayed using <a href="https://shopify.github.io/liquid/">Liquid</a>. It provides me a nice way to offload the public side of my operations to Github.</p>

<p>I am increasingly doing this with all of my data, by publishing it as YAML, and rendering a dynamic (static) API representation in JSON–all done with the same approach I’m using to publish my website(s). <a href="http://developer.apievangelist.com/">You can get at all of the data I use across my API research in a single API Evangelist developer portal</a>, which just aggregates all of the JSON APIs I’ve published across my network almost 100 Github repositories, and supporting sites.</p>

<p>Another thing I’m experimenting with is publishing simple JavaScript functions to individual pages within Github repositories. These scripts do a range of things from pulling items I’ve curated from <a href="https://developer.feedly.com/">the Feedly API</a>, fresh data from Google Sheets that I am using as data stores, and a variety of other jobs across my network of research sites, data projects, and API tooling. Some of these scripts I’m running manually, while others I run on a variety of schedules using <a href="https://www.easycron.com">EasyCron</a>.</p>

<p>The approach definitely has some significant limitations, but I find that I’m able to get quite a bit done with JavaScript by pulling data from external APIs and other feeds, and using each Github repo as storage, and the Github API as the read/write layer for this storage. I do not store any API keys, tokens, or other secrets in the Github repositories, I’m passing them all in via the URL, which isn’t the most secure, and could in theory be abducted in transit even though I’m using SSL–something I’d like to improve upon by passing a single token to unlock a private store. I have access to external systems via APIs, storage and compute via Github, and I can control everything through variety of functional JavaScripts I maintain using Github, and keep indexed using APIs.json.</p>

<p>It is becoming a kind of poor man’s serverless. I’m going to keep polishing my approach. Get better with my responses, and my approach to reading and writing data schema to the data storage folder in each of my repositories, which can then be read statically using JSON APIs I’ve pushed from this data, using Liquid. It is a pretty scrappy approach to serverless, but done in a way that takes the servers out of the equation for me, offloading the front-end and back-end work for my network of sites to Github. I am not sure where I’m going with this. Sometimes I get better results from a more straightforward API implementation on my Amazon infrastructure, but I am finding some interesting use cases, and seeing another side-effect I am enjoying–it is making my serverless infrastructure forkable and usable by others.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/10/github-serverless/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/10/having-the-right-commications-pipeline-for-your-api-platform/">Having The Right Communications Pipeline For Your API Platform</a></h3>
        <span class="post-date">10 Jul 2017</span>
        <p><a href="https://matthewreinbold.com/2017/07/04/SiteUpdate/"><img src="https://s3.amazonaws.com/kinlane-productions/matts-blog.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>My friend Matthew Reinbold, formerly of Vox Pop, and now the Lead for the Capital One API Center of Excellence, as well as the maintainer of <a href="http://webapi.events/">web API events</a> has shifted <a href="https://matthewreinbold.com/2017/07/04/SiteUpdate/">his blogging platform to use Github, using Jekyll</a>. Ok, yawn, why is this news? Someone is shifting the underlying platform for their blog. Well, first Matt is one of the leading API practitioners in the space, who is also a storyteller. Second, his approach highlights a set of tools that other API providers should be considering for their API communications pipeline.</p>

<p>Matt is using a pretty potent formula for his communications platform in my opinion, with a handful of essential ingredients:</p>

<ul>
  <li><strong><a href="https://github.com">Github</a></strong> - Using a Github repository as the open source folder for your website.</li>
  <li><strong><a href="https://pages.github.com/">Github Pages</a></strong> - Using Github Pages to publish the front-end for your website.</li>
  <li><strong><a href="https://jekyllrb.com/">Jekyll</a></strong> - The content management system that sits in the folder for your website.</li>
  <li><strong><a href="https://www.cloudflare.com/">CloudFlare</a></strong> - The DNS and SSL front-end for your website, complete with analytics.</li>
  <li><strong><a href="https://www.hover.com/">Hover</a></strong> - The registrar for the domain which you offload DNS management to CloudFlare.</li>
</ul>

<p>Matt is taking advantage of the benefits of static website development, which some of the benefits are, as Matt describes:</p>

<ul>
  <li><strong>SPEED</strong> - There’s no processing server side; posts have already been reduced to the essential atomic units of the web: HTML, Javascript, and CSS. There’s something poetic to me about that.</li>
  <li><strong>Security</strong> - While not so much an issue with my own coded CMS, I lived in constant fear of missing a zero-day Wordpress exploit patch and finding myself, along with clients, compromised. Reducing the number of moving parts significantly decreases the places where something might go wrong.</li>
  <li><strong>Hosting</strong> - Rather than having to find, research, and deploy to increasingly rare ColdFusion hosts (or port to another language), I can post my content to anywhere that supports HTTP/JS/CSS. hosting. This becomes very compelling given that Github Pages, one option, is free.</li>
</ul>

<p>This is the cheapest and quickest way for your API to get a blog stood up, and get publishing stories about the value your API is bringing to the table. This approach isn’t just limited to your developer portal or engineering team blog, this could be for partners, or any API related project that you are running. I publish a static Jekyll blog <a href="http://apievangelist.com/api-lifecycle/">for each area of my research</a>, and I try to always have one for each of my data, or API tooling project–telling the story of each project that is independent from the API Evangelist blog, providing a static log of everything that has happened.</p>

<p>Github isn’t just a pipeline for code, it can be a pipeline for your communications and storytelling. It also can be a pipeline for your documentation, how-to-guides, and other resources. I’m happy to see Matt putting it to be use. Another thing I like about his post, other than him mentioning me ;-), is that he also mentioned the benefits of this approach over using Medium, which is something I’ve been advising API providers against for some time. In my opinion you are better off publishing your blog like Matt has, and then syndicating to Medium if you want. <a href="https://matthewreinbold.com/2017/07/04/SiteUpdate/">There is a lot more detail available on Matt’s story behind his new blog strategy</a>, I recommend heading over and learning from what he’s done.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/10/having-the-right-commications-pipeline-for-your-api-platform/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/10/being-first-with-any-technology-trend-is-hard/">Being First With Any Technology Trend Is Hard</a></h3>
        <span class="post-date">10 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/iron-io/Iron-io-Platform_Diagram_V3-05.png" align="right" width="40%" style="padding: 15px;" /></p>
<p><a href="https://www.iron.io/ich-bin-ein-evangelist/">I first wrote about Iron.io back in 2012</a>. The are an API-first company, and they were the first serverless platform. I’ve known the team since they first reached out back in 2011, and I consider them one of my poster children for why there is more to all of this than just the technology. Iron.io gets the technology side of API deployment, and they saw the need for enabling developers to go serverless, running small scalable scripts in the cloud, and offloading the backend worries to someone who knows what they are doing.</p>

<p>Iron.io is what I’d consider to be a pretty balanced startup, slowly growing, and taking sensible amounts of funding they needed to grow their business. The primary area I would say that Iron.io has fallen short is when it comes to storytelling about what they are up to, and generally playing the role of a shiny startup everyone should pay attention to. They are great storytellers, but unfortunately the frequency and amplification of their stories has fallen short, allowing other strong players to fill the void–opening the door for Amazon to take the lion share of the conversation when it comes to serverless. Demonstrating that you can rock the technology side of things, but if you don’t also rock the storytelling and more theatrical side of things, there is a good chance you can come in second.</p>

<p>Storytelling is key to all of this. I always love the folks who push back on me saying that nobody cares about these stories, the markets only care about successful strong companies–when it reality, IT IS ALL ABOUT STORYTELLING! Amazon’s platform machine is good at storytelling. Not just their serverless group, but the entire platform. They blog, tweet, publish press releases, whisper in reporter ears, buy entire newspapers, publish science fiction patents, conduct road shows, and flagship conferences. Each AWS platform team can tap into this, participate, and benefit from the momentum, helping them dominate the conversation around their particular technical niche.</p>

<p>Being first with any technology trend will always be hard, but it will be even harder if you do not consistently tell stories about what you are doing, and what those who are using your platform are doing with it. Iron.io has been rocking it for five years now, and <a href="https://medium.com/travis-on-development/what-is-serverless-computing-and-why-is-it-important-3278b4ffe814">are continuing to define what serverless is all about</a>, they just need to turn up the volume a little bit, and keep doing what they are doing. I’ll own a portion of this story, as I probably didn’t do my share to tell more stories about what they are up to, which would have helped amplify their work over the years–something I’m working to correct with a little storytelling here on API Evangelist.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/10/being-first-with-any-technology-trend-is-hard/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/10/opportunity-to-develop-a-threat-intelligence-apis-json/">Opportunity To Develop A Threat Intelligence Aggregation API</a></h3>
        <span class="post-date">10 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/facing-cannon_copper_circuit.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I came across <a href="https://github.com/hslatman/awesome-threat-intelligence">this valuable list of threat intelligence resources</a> and think that the section on information sources should be aggregated and provided as a single threat intelligence API. When I come across valuable information repos like this my first impulse is to go through them, standardize and upload as JSON and YAML to Github, making all of this data forkable, and available via an API.</p>

<p>Of course if I responded to every impulse like this I would never get any of my normal work done, and actually pay my bills. A second option for me is to put things out there publicly in hopes that a) someone will pay me to do the work, or b) someone else who has more time, and the rent paid will tackle the work. With this in mind, this list of sources should be standardized, and publish to Github and as an API:</p>

<ul>
  <li><a href="http://s3.amazonaws.com/alexa-static/top-1m.csv.zip" target="_blank">Alexa Top 1 Million sites</a> - Probable Whitelist of the top 1 Million sites from Amazon(Alexa).</li>
  <li><a href="https://docs.google.com/spreadsheets/u/1/d/1H9_xaxQHpWaa4O_Son4Gx0YOIzlcBWMsdvePFX68EKU/pubhtml" target="_blank">APT Groups and Operations</a> - A spreadsheet containing information and intelligence about APT groups, operations and tactics.</li>
  <li><a href="https://www.autoshun.org/" target="_blank">AutoShun</a> - A public service offering at most 2000 malicious IPs and some more resources.</li>
  <li><a href="https://www.circl.lu/projects/bgpranking/" target="_blank">BGP Ranking</a> - Ranking of ASNs having the most malicious content.</li>
  <li><a href="https://intel.malwaretech.com/" target="_blank">Botnet Tracker</a> - Tracks several active botnets.</li>
  <li><a href="http://danger.rulez.sk/projects/bruteforceblocker/" target="_blank">BruteForceBlocker</a> - BruteForceBlocker is a perl script that monitors a server’s sshd logs and identifies brute force attacks, which it then uses to automatically configure firewall blocking rules and submit those IPs back to the project site, <a href="http://danger.rulez.sk/projects/bruteforceblocker/blist.php">http://danger.rulez.sk/projects/bruteforceblocker/blist.php</a>.</li>
  <li><a href="http://osint.bambenekconsulting.com/feeds/c2-ipmasterlist.txt" target="_blank">C&amp;C Tracker</a> - A feed of known, active and non-sinkholed C&amp;C IP addresses, from Bambenek Consulting.</li>
  <li><a href="http://cinsscore.com/list/ci-badguys.txt" target="_blank">CI Army List</a> - A subset of the commercial <a href="http://cinsscore.com/">CINS Score</a> list, focused on poorly rated IPs that are not currently present on other threatlists.</li>
  <li><a href="http://s3-us-west-1.amazonaws.com/umbrella-static/index.html" target="_blank">Cisco Umbrella</a> - Probable Whitelist of the top 1 million sites resolved by Cisco Umbrella (was OpenDNS).</li>
  <li><a href="https://intel.criticalstack.com/" target="_blank">Critical Stack Intel</a> - The free threat intelligence parsed and aggregated by Critical Stack is ready for use in any Bro production system. You can specify which feeds you trust and want to ingest.</li>
  <li><a href="https://www.c1fapp.com/" target="_blank">C1fApp</a> - C1fApp is a threat feed aggregation application, providing a single feed, both Open Source and private. Provides statistics dashboard, open API for search and is been running for a few years now. Searches are on historical data.</li>
  <li><a href="https://www.cymon.io/" target="_blank">Cymon</a> - Cymon is an aggregator of indicators from multiple sources with history, so you have a single interface to multiple threat feeds. It also provides an API to search a database along with a pretty web interface.</li>
  <li><a href="https://intel.deepviz.com/recap_network.php" target="_blank">Deepviz Threat Intel</a> - Deepviz offers a sandbox for analyzing malware and has an API available with threat intelligence harvested from the sandbox.</li>
  <li><a href="http://rules.emergingthreats.net/fwrules/" target="_blank">Emerging Threats Firewall Rules</a> - A collection of rules for several types of firewalls, including iptables, PF and PIX.</li>
  <li><a href="http://rules.emergingthreats.net/blockrules/" target="_blank">Emerging Threats IDS Rules</a> - A collection of Snort and Suricata <i>rules</i> files that can be used for alerting or blocking.</li>
  <li><a href="https://exonerator.torproject.org/" target="_blank">ExoneraTor</a> - The ExoneraTor service maintains a database of IP addresses that have been part of the Tor network.  It answers the question whether there was a Tor relay running on a given IP address on a given date.</li>
  <li><a href="http://www.exploitalert.com/" target="_blank">Exploitalert</a> - Listing of latest exploits released.</li>
  <li><a href="https://feodotracker.abuse.ch/" target="_blank">ZeuS Tracker</a> - The Feodo Tracker <a href="https://www.abuse.ch/" target="_blank">abuse.ch</a> tracks the Feodo trojan.</li>
  <li><a href="http://iplists.firehol.org/" target="_blank">FireHOL IP Lists</a> - 400+ publicly available IP Feeds analysed to document their evolution, geo-map, age of IPs, retention policy, overlaps. The site focuses on cyber crime (attacks, abuse, malware).</li>
  <li><a href="https://fraudguard.io/" target="_blank">FraudGuard</a> - FraudGuard is a service designed to provide an easy way to validate usage by continuously collecting and analyzing real-time internet traffic.</li>
  <li><a href="http://hailataxii.com/" target="_blank">Hail a TAXII</a> - Hail a TAXII.com is a repository of Open Source Cyber Threat Intelligence feeds in STIX format. They offer several feeds, including some that are listed here already in a different format, like the Emerging Threats rules and PhishTank feeds.</li>
  <li><a href="https://www.iblocklist.com/lists" target="_blank">I-Blocklist</a> - I-Blocklist maintains several types of lists containing IP addresses belonging to various categories. Some of these main categories include countries, ISPs and organizations. Other lists include web attacks, TOR, spyware and proxies. Many are free to use, and available in various formats.</li>
  <li><a href="https://majestic.com/reports/majestic-million" target="_blank">Majestic Million</a> - Probable Whitelist of the top 1 million web sites, as ranked by Majestic. Sites are ordered by the number of referring subnets. More about the ranking can be found on their <a href="https://blog.majestic.com/development/majestic-million-csv-daily/" target="_blank">blog</a>.</li>
  <li><a href="http://www.malshare.com/" target="_blank">MalShare.com</a> - The MalShare Project is a public malware repository that provides researchers free access to samples.</li>
  <li><a href="http://www.malwaredomains.com/" target="_blank">MalwareDomains.com</a> -   The DNS-BH project creates and maintains a listing of domains that are known to be used to propagate malware and spyware. These can be used for detection as well as prevention (sinkholing DNS requests).</li>
  <li><a href="https://www.metadefender.com/threat-intelligence-feeds" target="_blank">Metadefender.com</a> -   Metadefender Cloud Threat Intelligence Feeds contains top new malware hash signatures, including MD5, SHA1, and SHA256. These new malicious hashes have been spotted by Metadefender Cloud within the last 24 hours. The feeds are updated daily with newly detected and reported malware to provide actionable and timely threat intelligence.</li>
  <li><a href="https://services.normshield.com" target="_blank">NormShield Services</a> -   NormShield Services provide thousands of domain information (including whois information) that potential phishing attacks may come from. Breach and blacklist services also available. There is free sign up for public services for continuous monitoring.</li>
  <li><a href="http://www.openbl.org/lists.html" target="_blank">OpenBL.org</a> -   A feed of IP addresses found to be attempting brute-force logins on services such as SSH, FTP, IMAP and phpMyAdmin and other web applications.</li>
  <li><a href="https://openphish.com/phishing_feeds.html" target="_blank">OpenPhish Feeds</a> - OpenPhish receives URLs from multiple streams and analyzes them using its proprietary phishing detection algorithms. There are free and commercial offerings available.</li>
  <li><a href="https://www.phishtank.com/developer_info.php" target="_blank">PhishTank</a> - PhishTank delivers a list of suspected phishing URLs. Their data comes from human reports, but they also ingest external feeds where possible. It’s a free service, but registering for an API key is sometimes necessary.</li>
  <li><a href="http://ransomwaretracker.abuse.ch/" target="_blank">Ransomware Tracker</a> - The Ransomware Tracker by <a href="https://www.abuse.ch/" target="_blank">abuse.ch</a> tracks and monitors the status of domain names, IP addresses and URLs that are associated with Ransomware, such as Botnet C&amp;mp;C servers, distribution sites and payment sites.</li>
  <li><a href="https://isc.sans.edu/suspicious_domains.html" target="_blank">SANS ICS Suspicious Domains</a> - The Suspicious Domains Threat Lists by <a href="https://isc.sans.edu/suspicious_domains.html" target="_blank">SANS ICS</a> tracks suspicious domains. It offers 3 lists categorized as either <a href="https://isc.sans.edu/feeds/suspiciousdomains_High.txt" target="_blank">high</a>, <a href="https://isc.sans.edu/feeds/suspiciousdomains_Medium.txt" target="_blank">medium</a> or <a href="https://isc.sans.edu/feeds/suspiciousdomains_Low.txt" target="_blank">low</a> sensitivity, where the high sensitivity list has fewer false positives, whereas the low sensitivty list with more false positives. There is also an <a href="https://isc.sans.edu/feeds/suspiciousdomains_whitelist_approved.txt" target="_blank">approved whitelist</a> of domains. Finally, there is a suggested <a href="https://isc.sans.edu/block.txt" target="_blank">IP blocklist</a> from <a href="https://dshield.org">DShield</a>.</li>
  <li><a href="https://github.com/Neo23x0/signature-base" target="_blank">signature-base</a> - A database of signatures used in other tools by Neo23x0.</li>
  <li><a href="https://www.spamhaus.org/" target="_blank">The Spamhaus project</a> - The Spamhaus Project contains multiple threatlists associated with spam and malware activity.</li>
  <li><a href="https://sslbl.abuse.ch/" target="_blank">SSL Blacklist</a> -   SSL Blacklist (SSLBL) is a project maintained by abuse.ch. The goal is to provide a list of “bad” SSL certificates identified by abuse.ch to be associated with malware or botnet activities. SSLBL relies on SHA1 fingerprints of malicious SSL certificates and offers various blacklists</li>
  <li><a href="https://statvoo.com/dl/top-1million-sites.csv.zip" target="_blank">Statvoo Top 1 Million Sites</a> -   Probable Whitelist of the top 1 million web sites, as ranked by Statvoo.</li>
  <li><a href="https://strongarm.io" target="_blank">Strongarm, by Percipient Networks</a> - Strongarm is a DNS blackhole that takes action on indicators of compromise by blocking malware command and control. Strongarm aggregates free indicator feeds, integrates with commercial feeds, utilizes Percipient’s IOC feeds, and operates DNS resolvers and APIs for you to use to protect your network and business. Strongarm is free for personal use.</li>
  <li><a href="http://www.talosintelligence.com/aspis/" target="_blank">Talos Aspis</a> - Project Aspis is a closed collaboration between Talos and hosting providers to identify and deter major threat actors. Talos shares its expertise, resources, and capabilities including network and system forensics, reverse engineering, and threat intelligence at no cost to the provider.</li>
  <li><a href="http://www.threatglass.com/" target="_blank">Threatglass</a> - An online tool for sharing, browsing and analyzing web-based malware. Threatglass allows users to graphically browse website infections by viewing screenshots of the stages of infection, as well as by analyzing network characteristics such as host relationships and packet captures.</li>
  <li><a href="https://www.threatminer.org/" target="_blank">ThreatMiner</a> - ThreatMiner has been created to free analysts from data collection and to provide them a portal on which they can carry out their tasks, from reading reports to pivoting and data enrichment. The emphasis of ThreatMiner isn’t just about indicators of compromise (IoC) but also to provide analysts with contextual information related to the IoC they are looking at.</li>
  <li><a href="https://virusshare.com/" target="_blank">VirusShare</a> - VirusShare.com is a repository of malware samples to provide security researchers, incident responders, forensic analysts, and the morbidly curious access to samples of malicious code. Access to the site is granted via invitation only.</li>
  <li><a href="https://github.com/Yara-Rules/rules" target="_blank">Yara-Rules</a> -   An open source repository with different Yara signatures that are compiled, classified and kept as up to date as possible.</li>
  <li><a href="https://zeustracker.abuse.ch/" target="_blank">ZeuS Tracker</a> -   The ZeuS Tracker by <a href="https://www.abuse.ch/" target="_blank">abuse.ch</a> tracks ZeuS Command &amp; Control servers (hosts) around the world and provides you a domain- and a IP-blocklist.</li>
</ul>

<p>Ideally, <a href="https://github.com/hslatman/awesome-threat-intelligence">each source on this list</a> would be publishing a forkable version of their data on Github and/or deploying a simple web API, but alas it isn’t the world we live in. Part of the process to standardardize and normalize the threat intelligence from all of these source would be to reach out to each provider, and take their temperature regarding working together to improve the data source by itself, as well as part of an aggregated set of data and API sources.</p>

<p>Similar to what I’m trying to do across many of the top business sectors being impacted by APIs, we need to to work aggregating all the existing sources of threat intelligence, and begin identifying a common schema that any new player could adopt. We need an open data schema, API definition, as well as suite of open source server and client tooling to emerge, if we are going to stay ahead of the cybersecurity storm that has engulfed us, and will continue to surround us until we work together to push it back.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/10/opportunity-to-develop-a-threat-intelligence-apis-json/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/07/when-json-schema-is-seen-as-power/">When JSON Schema Is Seen As Power</a></h3>
        <span class="post-date">07 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/power-lines-empty-space_sunday.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>In a 30 year career as a database professional I’ve seen some extraordinary ways in which owning and controlling data is associated with power. Those who have the data leverage it against those who do not have it. Losing control means losing power, so people do whatever they can to stay in control, protecting the spreadsheets and databases at all costs. After 30 years of seeing this play out over and over again, I thought I’d seen it all, but sadly in an API era I’m just seeing new incarnations of data being wielded by those in power.</p>

<p>I recently came across an example where a company was holding back a series of JSON schema for a variety of public datasets, and standards in use as part of some government systems. From what I can tell company had been brought in to handle the systems and open data work a few years back, and with each version of the software and schema they slowly began to maintain tighter control over the schema, while they were also being mandated to be more open with the data–shifting from being controlling over the data, to being controlling of the schema.</p>

<p>They see the ability to be able to validate data, API requests and responses as something only a handful of people should be able to do. If you have the ability to validate, and say, “yes that data or API is compliant”, you are now in a position of power. This groups was mandated to be open with the data, allowing it flow freely between open source and proprietary systems, keeping in sync with laws and regulations, but they had found another way to remain as gatekeeper–I think this is what some folks call innovation, and thinking out of the box.</p>

<p>In my world, it is just another example of how power will always find ways to keep data from flowing, no matter how it learns to be perceived as playing nicely in an open data and API world. Many companies are still playing by the old rules and just hoarding, locking, up and controlling data–refusing to play along in the API game. However it is fascinating to see how power can shape shift and find new ways to protect its interest in this new landscape. After 30 years of doing this I am not surprised, but I do have to call it out when I see it because, well it is not right. Be open and share your schema, and let everyone be able to validate that data is what it should be.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/07/when-json-schema-is-seen-as-power/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/06/the-essential-api-elements-in-my-world/">The Essential API Elements In My World</a></h3>
        <span class="post-date">06 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/periodic-elements.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>In 2017 there seems to be an API for just about everything. You can make products available via an API, messing, images, videos, and any of the digital bits that make up our lives. I still get excited by some new APIs, but APIs have to have real usage, and deliver real value before I’ll get too worked up about them. I’m regularly looking down the <a href="http://apievangelist.com/2017/01/09/the-api-driven-marketplace-that-is-my-digital-self/">list of my digital bits</a> thinking about which are the most important to me, which ones I’ll keep around, and the services I’ll adopt to help me define and manage these bits.</p>

<p>This process has got me thinking really deeply about what I’d consider to be the three most important types of APIs in my life:</p>

<ul>
  <li><strong>Compute</strong> - In my world compute is all about AWS EC2 instances, but when I think about it, Github really handles the majority of the compute for my front-end, but EC2 is the scalable compute for the backend of my world that is driving my APIs.</li>
  <li><strong>Storage</strong> - Primarily storage is all about Amazon S3, but I also depend on Dropbox, Google Drive, and I also put Github into the storage bucket because I store quite a bit of JSON, YAML, and other data there.</li>
  <li><strong>DNS</strong> - apievangelist.com and kinlane.com are very important domains in my world–they are how I make my living, and share my stories. CloudFlare is how I manage this frontline of my world, making DNS an extremely important element in my world.</li>
</ul>

<p>I leverage compute, storage, and DNS APIs regularly throughout each day–making them very important APIs in my existence. However, these are also the essential ingredients of my APIs as well. I consume these APIs, but I also deploy my APIs with these three elements. Each API has a compute and storage layer, with DNS as the naming, addressing, and discovery for these valuable resources in my world. This makes these three aspects of operating online, the three most essential elements in my world–even beyond images, messaging, video, and other elements that are ubiquitous across my digital presence.</p>

<p>It is interesting for me to think about the importance of these elements in my world, as storage and compute were the first two APIs that turned on the light bulb in my head when it came to the importance of web APIs. When Amazon launched Amazon S3 and Amazon EC2, that is when I knew APIs were going to be bigger than Flickr or Twitter. You could deploy global infrastructure with APIs–you could deploy APIs with APIs! <a href="http://apievangelist.com/2017/01/09/the-api-driven-marketplace-that-is-my-digital-self/">I really enjoy thinking deeply about all my digital bits</a>, and the role APIs are playing–regularly reassessing the value of API-driven resources in my world. It helps me think through what is important, and what isn’t–showing the 98% of all of this tech doesn’t matter, but there is a 2% that does make an actual difference in my digital existence.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/06/the-essential-api-elements-in-my-world/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/06/openapi-leading-the-open-banking-api-conversations/">OpenAPI Leading The Open Banking API Conversation</a></h3>
        <span class="post-date">06 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/openapi/openapi-blue-icons.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’ve been looking through the ecosystems of banking API platforms trying to understand the technical, business, and political approach of banks when it comes to the API conversation. While <a href="http://apievangelist.com/2016/09/01/the-sustained-api-storytelling-assault-on-the-banking-industry/">Capital One is definitely leading the conversation in the U.S.</a>, I’ve also been looking to better understand what is happening around the PSD2 banking API conversation in the EU and UK.</p>

<p>I was pleased to find <a href="https://psd2-apiexplorer.openbankproject.com/?ignoredefcat=true&amp;tags=#2_2_0-getCurrentFxRate">OpenAPI present in the OpenBankProject PSD2 API Explorer</a>, as well as leading <a href="https://www.openbanking.org.uk/read-write-apis/">the specification standards conversation over at Open Banking in the UK</a>. The existence of the OpenAPI allows analysts like me to quickly load up the OpenAPI in an API client like Postman or Restlet, and become more intimate with what paths, and definitions are available–developing my awareness of where banking API standards are headed.</p>

<p>OpenAPI is proving to be a great way to facilitate a conversation about an API at the team, as well as industry level. While the learning curve involved with OpenAPI adoption is real, I’m finding it to be an essential diplomatic tool when it comes to harmonizing the industry level conversation around <a href="http://org.open.referral.adopta.agency/">my Human Services Data API work</a>. OpenAPI provides a central reference <a href="http://apievangelist.com/2017/06/15/zooming-out-to-the-100k-level-then-back-to-api-sea-level-with-openapi-and-apis-dot-json/">that business stakeholders can reference at the 100K view, while also enabling developers and architects can discuss at the nitty gritty technical level</a>.</p>

<p>I’m bookmarking all the OpenAPIs I find around PSD2, and I’m on the hunt for more OpenAPIs around FHIR. These are the two leading API standards conversation going on at the industry level, helping define a common API interface within two heavily regulated industries–banking and healthcare. While there is still a HUGE amount of work within these communities to truly achieve the adoption everyone is envisioning, I find the fact that their are OpenAPIs being used as a positive sign. It shows that we are moving towards more substance than just talk, and acknowledges the conversation stimulating powers of OpenAPI, in addition to the potential for delivering API deployment, management, testing, monitoring, SDKs, discovery, and other essential stops along the API lifecycle.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/06/openapi-leading-the-open-banking-api-conversations/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/06/does-your-api-sandbox-have-malicious-users/">Does Your API Sandbox Have Malicious Users?</a></h3>
        <span class="post-date">06 Jul 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/sand-hand_light_dali.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I have been going through <a href="http://virtualization.apievangelist.com/">my API virtualization research</a>, expanding the number of companies I’m paying attention to, and taking a look at industry specific sandboxes, mock APIs, and other approaches to virtualizing APIs, and the data and content they serve up. I’m playing around with some banking API sandboxes, getting familiar with PSD2, and learning about how banks are approaches their API virtualization–providing me with an example within a heavily regulated industry.</p>

<p>AS I’m looking through <a href="https://github.com/OpenBankProject/OBP-API/wiki/PSD2-Sandbox">Open Bank Project’s PSD2 Sandbox</a>, and playing with <a href="https://www.sandboxbanking.com/developers.html">services that are targeting the banking industry with sandbox solution</a>, I find myself thinking about <a href="https://github.com/Netflix/chaosmonkey">Netflix’s Chaos Monkey</a>, which is “a resiliency tool that helps applications tolerate random instance failures.” Now I am wondering if there are any API sandboxes out there that have simulated threats built in, pushing developers to build more stable and secure applications with API resources.</p>

<p>There are <a href="https://www.fortinet.com/products/sandbox/fortisandbox.html">threat detection solutions that have APIs</a>, and some interesting <a href="https://www.joesecurity.org/">sandboxes for analyzing malware that have APIs</a>, but I don’t find any API sandboxes that just have general threats available in them. If you know of any sandboxes that provide simulations, or sample data, please let me know. Also if you know of any APIs that specifically provide API security threats in their sandbox environments so that developers can harden their apps–I’d love to hear more about it. I depend on my readers to let me know of the interesting details from API operations like this.</p>

<p>I’m on the hunt for APIs that have sandboxes that assist application developers think about the resiliancy and security of their applications built on top of an API. Eventually I’d also love to see a sandbox emerge to emerge that could help API providers think about the resiliancy and security of their APIs. I’m feeling like this aspect of API virtualization is going to become just as critical as guidance on API design best practices, but helping API operaters better understand the threats they face as API operators, and quantify them against their API in a virtualized and simulated environment that isn’t going to freak them out about the availability of their production environment.</p>

<p>I’ll keep an eye out for more examples of this in the wild–if you know of anything please let me know–thanks!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/06/does-your-api-sandbox-have-malicious-users/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/06/standardizing-and-templatizing-api-design-editor-validation-tips/">Standardizing and Templatizing API Design Editor Validation Tips</a></h3>
        <span class="post-date">06 Jul 2017</span>
        <p><a href="http://www.apicur.io/"><img src="https://s3.amazonaws.com/kinlane-productions/apicurio/apicurio-feedback-loop.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I’ve been playing with <a href="http://www.apicur.io/">Apicurio</a>, the <a href="https://apievangelist.com/2017/05/30/apicurio-is-the-open-source-api-editor-i-was-looking-for/">open source API design editor I’ve been waiting for</a>, and saw a potential opportunity for design time collaboration, instruction, and feedback loop. When you are designing an API in Apicurio it gives you alerts based upon JSON schema validation of the underlying OpenAPI, providing a nice visual feedback loop–forcing you to complete your API definition until it properly validates.</p>

<p>Visual alerts and feedback based upon JSON schema validation isn’t really new or that interesting–you see it in the Swagger Editor, and many other JSON tooling. Where I see an opportunity is specifically when it comes to an open source visual API design editor like Apicurio, and when the JSON schema engine for the validation responses is opened up as part of the architecture. Allowing users to import and export JSON schema that goes beyond the default OpenAPI schema, which gets us to a minimum viable OpenAPI definition–while this is good, we can do better.</p>

<p>I’d like to see a marketplace of JSON schema to emerge helping API designers and architects push the completeness and precision of their OpenAPI definitions beyond the speed at which the core OpenAPI spec can move, and go in directions, and cover niche definitions that the core OpenAPI schema will never cover. I want to be able to load a schema that will help me push forward my API responses beyond just a default 200. I want to be able to load custom JSON schema crafted by API design experts who have more skills than I do, and learn from them. I want my API design editor to help me take my APIs to the next level, while also be pushing my API design skills forward along the way.</p>

<p>Apicurio takes does a good job at giving plain english responses to validation errors–much better than some tools I’ve used. You can click on the detail of each alert, to get more information about what is going on. I could see this entire structure opened up as part of Apicurio’s architecture allowing custom JSON schema templates that can be be imported, and made more informative with plain english responses, more detail, and even links to learn more about how you can improve your API. Turning the basic validation responses into more of an API design knowledge-base, and even structured curriculum walking you through best practices when it comes to API design, and what is working in the industry.</p>

<p>Just some thoughts as I’m playing with <a href="http://www.apicur.io/">Apicurio</a>. I’m very happy to see this API design editor emerge, and I have been having fun thinking about what is possible when it comes to the road map. I feel a common visual API design interface is an important part of the next step in the evolution of the API sector. Which is <a href="http://apievangelist.com/2015/08/13/a-common-open-source-api-design-editor-is-needed-for-api-service-providers/">why I have been advocating for an open source API design editor</a> that any API provider can use to design their APIs, and any API service provider can bake into their services and tooling–standardizing how we all craft and communicate around our API designs. The validation feedback loop during this phase will be an important channel for pushing API designers to do what is right, make their API definitions more complete, while educating them about common API design practices, and building a more literate API workforce.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/06/standardizing-and-templatizing-api-design-editor-validation-tips/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/05/enhancing-your-api-seo/">Enhancing Your API SEO</a></h3>
        <span class="post-date">05 Jul 2017</span>
        <p><a href="https://api-platform.com/"><img src="https://s3.amazonaws.com/kinlane-productions/api-portal/enhance-seo-and-interoperability.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>One question I’m regularly getting from my readers is regarding how you can increase the search engine optimization (SEO) for your APIs–yes, API SEO (acronyms rule)! While we should be investing in API discoverability by embracing hypermedia early on, I feel in its absence we should also be indexing our entire API operations with <a href="http://apisjson.org">APIs.json</a>, and making sure we describe individual APIs using <a href="http://openapis.org">OpenAPI</a>, the world of web APIs is still very hitched to the web, making SEO very relevant when it comes to API discoverability.</p>

<p>While I was diving deeper into “<a href="https://api-platform.com/">The API Platform</a>”, a VERY forward leaning API deployment and management solution, <a href="https://api-platform.com/">I was pleased to see another mention of API SEO using JSON-LD</a> (scroll down on the page). While I wish every API would adopt JSON-LD for their overall design, I feel we are going to have to piece SEO and discoverability together for our sites, as The API platform demonstrates. They provide a nice example of how you can paste a JSON-LD script into the the page of your API documentation, helping amplify some of the meaning and intent behind your API using JSON-LD + Schema.org.</p>

<p><a href="http://apievangelist.com/2017/03/14/thinking-about-schemaorgs-relationship-to-api-discovery/">I have been thinking about Schema.org’s relationship to API discovery for some time now</a>, which is something I’m hoping to get more time to invest in further during 2017. I’d like to see Schema.org get more baked into API design, deployment, and documentation, as well as JSON-LD as part of underlying schema. To help build a bridge from where we are at, to where we need to be going, I’m going to explore how I can leverage OpenAPI tags to help autogenerate JSON-LD Schema.org tags as part of API documentation. While I’d love for everyone to just get the benefits of JSON-LD, I’m afraid many folks won’t have the bandwidth, and could use an assist from the API documentation solutions they are already using–making APIs more SEO friendly by default.</p>

<p>If you are starting a new API I recommend playing with “<a href="https://api-platform.com/">The API Platform</a>”, as you get the benefits of Schema.org, JSON-LD, and MANY other SIGNIFICANT API concepts by default. Out of all of the API frameworks I’ve evaluated as part of my <a href="http://deployment.apievangelist.com">API deployment research</a>, “The API Platform” is by far the most advanced when it comes to leading by example, and enabling healthy API design practices by default–something that will continue to bring benefits across all stops along the life cycle if you put to work in your operations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/05/enhancing-your-api-seo/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/05/a-bot-that-does-useful-things-for-me/">A Bot That Actually Does Useful Things For Me</a></h3>
        <span class="post-date">05 Jul 2017</span>
        <p><a href="https://www.hashicorp.com"><img src="https://s3.amazonaws.com/kinlane-productions/hashicorp/hashicorp-logo.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I’m not a fan of the unfolding bot universe. I get it, you can do interesting things with them–the key word being interesting. Most of what I’ve seen done via Twitter, Facebook, and Slack Bots really isn’t that interesting. Maybe it’s that I’m old and boring, or maybe because people aren’t doing interesting things. When you hear me complain about bots, just remember it isn’t because I think the technology approach is dumb, it’s because I think the implementations are dumb.</p>

<p>After several dives into the world of bots, looking to understand how bots are using APIs, I’ve found some interesting Twitter bots, and an even smaller number of Slack bots I found to be useful–I have yet to find an interesting Facebook Bot. Honestly, I think it is the constaints of each platform that are incentivizing interesting things to be done, and also the not interesting, and even dangerous things to be done. So I find it interesting when the bot conversation moves to other platforms, bringing with it a new sets of constraints, like <a href="https://www.hashicorp.com/blog/introducing-the-hashibot-github-bot/">I just saw with a new bot out of Hashicorp</a>.</p>

<p>Hashicorp’s Bot does mundane Github janitorial work for me! This is automation (aka bot) activity I can get behind. I feel like much of the Slack automation I’ve seen is doing things that wouldn’t actually benefit me, and would be creating more noise than any solution it would bring–this is due to how I use Slack, or rather how I don’t use Slack. I’m a HEAVY Github user, and there are MANY tasks that are left undone. Things like tagging repos, README files, licensing, and the other things we either forget about, or just don’t have the time for. You fire up a bot to help me with these things, my ears are going to perk up a bit when it comes to the bot conversation.</p>

<p>In the end, I just need to remember that it is not bots that are boring and dumb–people are. ;-) That includes me. I find the concept of a Github bot infinitely more valuable than a Facebook, Twitter, or Slack Bot. I’m curious to see where Hashicorp takes this, and now that the concept of a Github Bot is on my radar, I’m guessing I will see other examples of it in the wild. I’m hoping this is an area we’ll see more bot development and investment, but I also understand Facebook, Twitter, and Slack have relevance in other peoples world, and that I’m the oddball here who finds Github a more interesting platform.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/05/a-bot-that-does-useful-things-for-me/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/05/an-api-change-log-and-road-map-visualization/">An API Change Log And Road Map Visualization</a></h3>
        <span class="post-date">05 Jul 2017</span>
        <p><a href="https://api-insights.qlik.com/#/overview-page"><img src="https://s3.amazonaws.com/kinlane-productions/qlik/qlik-api-insights.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I saw a blog post come across my feeds from the analysis and visualizaiton API provider Qlik, <a href="https://branch-blog.qlik.com/qlik-sense-api-insights-3e84b61602bd">about their Qlik Sense API Insights</a>. It is a pretty interesting approach to trying visualize the change log and road map for an API. I like it because it is an analysis and visualization API provider who has used their own platform to help visualize the evolution of their API.</p>

<p>I find the visualization for Qlik Sense API Insights to be a little busy, and not as interactive as I’d like to see it be, but I like where they are headed. It tries to capture a ton of data, showing the road map and changes across multiple versions of sixteen APIs, something that can’t be easy to wrap your head around, let alone capture in a single visualization. I really like the direction they are going with this, even though it doesn’t fully bring it home for me.</p>

<p><a href="https://api-insights.qlik.com/#/overview-page">Qlik Sense API Insights</a> is the first approach I’ve seen like this to attempt to try and quantify the API road map and change log–it makes sense that it is something being done by a visualization platform provider. With a little usage and user experience (UX) love I think the concept of analysis, visualizaitons, and hopefully insights around the road map, change log, and even open issues and status could be significantly improved upon. I could see something like this expand and begin to provide an interesting view into the forever changing world of APIs, and keep consumers better informed, and in sync with what is going on.</p>

<p>In a world where many API providers still do not even share a road map or change log I’m always looking for examples of providers going the extra mile to provide more details, especially if they are innovating thike Qlik is with visualizations. I see a lot of conversations about how to version an API, but very few conversations about how to communicate each version of your API. It is something I’d like to keep evangelizing, helping API providers understand they should at least be offering the essentials like a roadmap, issues, change log, and status page, but the possibility for innovation and pushing the conversation forward is within reach too!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/05/an-api-change-log-and-road-map-visualization/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/07/05/bringing-the-api-deployment-landscape-into-focus/">Bringing The API Deployment Landscape Into Focus</a></h3>
        <span class="post-date">05 Jul 2017</span>
        <p><a href="http://deployment.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-api-deployment.png" align="right" width="30%" style="padding: 15px;" /></a></p>
<p>I am finally getting the time to invest more into the rest of my API industry guides, which involves deep dives into core areas of my research like API <a href="http://definitions.apievangelist.com/">definitions</a>, <a href="http://design.apievangelist.com/">design</a>, and now <a href="http://deployment.apievangelist.com/">deployment</a>. The outline for my API deployment research has begun to come into focus and looks like it will rival my API management research in size.</p>

<p>With this release, I am looking to help onboard some of my less technical readers with API deployment. Not the technical details, but the big picture, so I wanted to start with some simple questions, to help prime the discussion around API development.</p>

<ul>
  <li>Where? - Where are APIs being deployed. On-premise, and in the clouds. Traditional website hosting, and even containerized and serverless API deployment.</li>
  <li>How? - What technologies are being used to deploy APIs? From using spreadsheets, document and file stores, or the central database. Also thinking smaller with microservices, containes, and serverless.</li>
  <li>Who? - Who will be doing the deployment? Of course, IT and developers groups will be leading the charge, but increasingly business users are leveraging new solutions to play a significant role in how APIs are deployed.</li>
</ul>

<p><strong>The Role Of API Definitions</strong>
While not every deployment will be auto-generated using an API definition like OpenAPI, API definitions are increasingly playing a lead role as the contract that doesn’t just deploy an API, but sets the stage for API documentation, testing, monitoring, and a number of other stops along the API lifecycle. I want to make sure to point out in my API deployment research that API definitions aren’t just overlapping with deploying APIs, they are essential to connect API deployments with the rest of the API lifecycle.</p>

<p><strong>Using Open Source Frameworks</strong>
Early on in this research guide I am focusing on the most common way for developers to deploy an API, using an open source API framework. This is how I deploy my APIs, and there are an increasing number of open source API frameworks available out there, in a variety of programming languages. In this round I am taking the time to highlight at least six separate frameworks in the top programming languages where I am seeing sustained deployment of APIs using a framework. I don’t take a stance on any single API framework, but I do keep an eye on which ones are still active, and enjoying usag bey developers.</p>

<p><strong>Deployment In The Cloud</strong>
After frameworks, I am making sure to highlight some of the leading approaches to deploying APIs in the cloud, going beyond just a server and framework, and leveraging the next generation of API deployment service providers. I want to make sure that both developers and business users know that there are a growing number of service providers who are willing to assist with deployment, and with some of them, no coding is even necessary. While I still like hand-rolling my APIs using my peferred framework, when it comes to some simpler, more utility APIs, I prefer offloading the heavy lifting to a cloud service, and save me the time getting my hands dirty.</p>

<p><strong>Essential Ingredients for Deployment</strong>
Whether in the cloud, on-premise, or even on device and even the network, there are some essential ingredients to deploying APIs. In my API deployment guide I wanted to make sure and spend some time focusing on the essential ingredients every API provider will have to think about.</p>

<p>-Compute - The base ingredient for any API, providing the compute under the hood. Whether its baremetal, cloud instances, or serverless, you will need a consistent compute strategy to deploy APIs at any scale.
-Storage - Next, I want to make sure my readers are thinking about a comprehensive storage strategy that spans all API operations, and hopefully multiple locations and providers.
-DNS - Then I spend some time focusing on the frontline of API deployment–DNS. In todays online environment DNS is more than just addressing for APIs, it is also security.
-Encryption - I also make sure encryption is baked in to all API deployment by default in both transit, and storage.</p>

<p><strong>Some Of The Motivations Behind Deploying APIs</strong>
In previous API deployment guides I usually just listed the services, tools, and other resources I had been aggregating as part of my monitoring of the API space. Slowly I have begun to organize these into a variety of buckets that help speak to many of the motivations I encounter when it comes to deploying APIs. While not a perfect way to look at API deployment, it helps me thinking about the many reasons people are deploying APIs, and craft a narrative, and provide a guide for others to follow, that is potentially aligned with their own motivations.</p>

<ul>
  <li>Geographic - Thinking about the increasing pressure to deploy APIs in specific geographic regions, leveraging the expansion of the leading cloud providers.</li>
  <li>Virtualization - Considering the fact that not all APIs are meant for production and there is a lot to be learned when it comes to mocking and virtualizing APIs.</li>
  <li>Data - Looking at the simplest of Create, Read, Update, and Delete (CRUD) APIs, and how data is being made more accessible by deploying APIs.</li>
  <li>Database - Also looking at how APIs are beign deployed from relational, noSQL, and other data sources–providing the most common way for APIs to be deployed.</li>
  <li>Spreadsheet - I wanted to make sure and not overlook the ability to deploy APIs directly from a spreadsheet making APIs are within reach of business users.</li>
  <li>Search - Looking at how document and content stores are being indexed and made searchable, browsable, and accessible using APIs.</li>
  <li>Scraping - Another often overlooked way of deploying an API, from the scraped content of other sites–an approach that is alive and well.</li>
  <li>Proxy - Evolving beyond early gateways, using a proxy is still a valid way to deploy an API from existing services.</li>
  <li>Rogue - I also wanted to think more about some of the rogue API deployments I’ve seen out there, where passionate developers reverse engineer mobile apps to deploy a rogue API.</li>
  <li>Microservices - Microservices has provided an interesting motivation for deploying APIs–one that potentially can provide small, very useful and focused API deployments.</li>
  <li>Containers - One of the evolutions in compute that has helped drive the microservices conversation is the containerization of everything, something that compliments the world of APis very well.</li>
  <li>Serverless - Augmenting the microservices and container conversation, serverless is motivating many to think differently about how APIs are being deployed.</li>
  <li>Real Time - Thinking briefly about real time approaches to APIs, something I will be expanding on in future releases, and thinking more about HTTP/2 and evented approaches to API deployment.</li>
  <li>Devices - Considering how APis are beign deployed on device, when it comes to Internet of Things, industrial deployments, as well as even at the network level.</li>
  <li>Marketplaces - Thinking about the role API marketplaces like Mashape (now RapidAPI) play in the decision to deploy APIs, and how other cloud providers like AWS, Google, and Azure will play in this discussion.</li>
  <li>Webhooks - Thinking of API deployment as a two way street. Adding webhooks into the discussion and making sure we are thinking about how webhooks can alleviate the load on APIs, and push data and content to external locations.</li>
  <li>Orchestration - Considering the impact of continous integration and deployment on API deploy specifically, and looking at it through the lens of the API lifecycle.</li>
</ul>

<p>I feel like API deployment is still all over the place. The mandate for API management was much better articulated by API service providers like Mashery, 3Scale, and Apigee. Nobody has taken the lead when it came to API deployment. Service providers like DreamFactory and Restlet have kicked ass when it comes to not just API management, but making sure API deployment was also part of the puzzle. Newer API service providers like Tyk are also pusing the envelope, but I still don’t have the number of API deployment providers I’d like, when it comes to referring my readers. It isn’t a coincidence that DreamFactory, Restlet, and Tyk are API Evangelist partners, it is because they have the services I want to be able to recommend to my readers.</p>

<p>This is the first time I have felt like <a href="http://deployment.apievangelist.com/">my API deployment research</a> has been in any sort of focus. I carved this layer of my research of <a href="http://management.apievangelist.com/">my API management research</a> some years ago, but I really couldn’t articulate it very well beyond just open source frameworks, and the emerging cloud service providers. After I publish this edition of my API deployment guide I’m going to spend some time in the 17 areas of my research listed above. All these areas are heavily focused on API deployment, but I also think they are all worth looking at individually, so that I can better understand where they also intersect with other areas like management, testing, monitoring, security, and other stops along the API lifecycle.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/07/05/bringing-the-api-deployment-landscape-into-focus/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/the-growing-importance-of-geographic-regions-in-the-api-economy/">The Growing Importance of Geographic Regions In API Operations</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><a href="https://cloud.google.com/about/locations/"><img src="https://s3.amazonaws.com/kinlane-productions/3D-Printing/regions/api-regions-global-map-from-google.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I have been revisiting <a href="http://apievangelist.com/2015/10/31/how-are-we-going-to-create-the-standard-and-poors-and-moodys-for-the-api-economy/">my earlier work on an API rating system</a>. One area that keeps coming up as I’m working is around the availability of APIs in a variety of regions, and the cloud platforms that are driving them. <a href="http://apievangelist.com/2011/02/04/launch-region-specific-apis/">I have talked about regional availability of APIs</a> for some time now, keeping an eye on <a href="http://apievangelist.com/2016/01/05/your-api-access-replicated-into-multiple-regions-around-the-globe-for-additional-charge/">how API providers are supporting multiple regions</a>, as well as <a href="http://apievangelist.com/2017/05/08/regional-availability-when-it-comes-to-api-access/">the expanding world of cloud computing</a> that is powering these regional examples of providing and consuming APIs.</p>

<p>I have been watching <a href="http://docs.aws.amazon.com/general/latest/gr/rande.html">Amazon rapidly expand their available regions</a>, as well as <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones">Google</a> and <a href="https://azure.microsoft.com/en-us/regions/">Microsoft</a> racing to catch up. But I am starting to see API providers <a href="https://developers.digitalocean.com/documentation/v2/#regions">like Digital Ocean providing APIs for getting at geographic region information</a>, and <a href="http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRegions.html">Amazon provides API methods for getting the available regions for Amazon EC2 compute</a>–I will have to check if this is standard across all services. <a href="https://www.twilio.com/docs/api/client/regions">Twilio has regions for their API client</a>, and <a href="https://www.runscope.com/docs/api/regions">Runscope has a region API for managing how you run API tests from a variety of regions</a>. The role of geographic regions when it comes to providing APIs, as well as consuming APIs is increasingly part of the conversation when you visit the most mature API platforms, and something that keeps coming up on my radar.</p>

<p>We are still far from the average company being able to easily deploy, deprecate, and migrate APIs seamlessly across cloud providers and geographic regions, but as APIs become smaller and more modular, and cloud providers add more regions, and APIs to support automation around these regions, we will begin to see more decisions being made at deploy and run time regarding where you want to deploy or consume your API resources. To be able to do this we are going to need a lot more data and common schema regarding the what geographic regions are available for deployment, what services operate in which regions, and other key considerations about exactly where our resources should operate. This is why I’m revisiting this work, to see what I can do to get API service providers to share more data from either the API provider or consumer side of the equation.</p>

<p>I am considering adding an area of my research dedicated to API regions, aggregating examples of how geographic regions are playing a role in API operations. I’m thinking region availability will be playing just as significant role as <a href="http://performance.apievangelist.com">performance</a>, <a href="http://plans.apievangelist.com">plans</a>, <a href="http://security.apievangelist.com">security</a>, <a href="http://reliablity.apievangelist.com">reliability</a>, and other areas of the API lifecycle when it comes to deciding where you deploy or consume your APIs. It feels like another one of the aspects of API operations that will overlap with many stops along the API lifecycle–not just <a href="http://deployment.apievangelist.com">deployment</a>. One of the areas of the API lifecycle I’m increasingly thinking about that will affect geographic API decisions is <a href="http://regulation.apievangelist.com">regulations</a>, and how governments are dictating what is acceptable when it comes to the storage, transmission, and access of digital resources. It feels like early notions of what the World Wide Web has been for the last 25 years is about to be blown out of the water, with the influences of digital nationalism, regulation, or even the Internet moving off planet, and increasingly driven by satellite infrastructure.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/the-growing-importance-of-geographic-regions-in-the-api-economy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api.-markdown/">Electronic Submission of Injury and Illness Records to OSHA</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><a href="https://www.osha.gov/injuryreporting/"><img src="https://s3.amazonaws.com/kinlane-productions/osha/osha-work-injury-form.jpg" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://www.osha.gov/injuryreporting/">I recently learned that Occupational Safety and Health Administration (OSHA) has issued guidance regarding the electronic submission of injury and illness records via an API, from an announcement that they has postponed the availability of electronic submissions for another six months</a>. Regardless of the delay, it is good to see them migrating towards an API-focused approach to allowing businesses to be compliant with safety regulations and reporting guidelines.</p>

<p>Here are the details of the OSHA guidance, broken down into some interesting buckets of guidance:</p>

<ul>
  <li><strong>Who</strong>: Establishments with 250 or more employees that are currently required to keep OSHA injury and illness records, and establishments with 20-249 employees that are classified in certain industries with historically high rates of occupational injuries and illnesses.</li>
  <li><strong>What</strong>: Covered establishments with 250 or more employees must electronically submit information from OSHA Forms 300 (Log of Work-Related Injuries and Illnesses), 300A (Summary of Work-Related Injuries and Illnesses), and 301 (Injury and Illness Incident Report). Covered establishments with 20-249 employees must electronically submit information from OSHA Form 300A.</li>
  <li><strong>When</strong>: The requirement becomes effective on January 1, 2017. The new reporting requirements will be phased in over two years. In 2017, all covered establishments must submit information from their completed 2016 Form 300A by July 1, 2017. In 2018, covered establishments with 250 or more employees must submit information from all completed 2017 forms (300A, 300, and 301) by July 1, 2018, and covered establishments with 20-249 employees must submit information from their completed 2017 Form 300A by July 1, 2018. Beginning in 2019 and every year thereafter, covered establishments must submit the information by March 2.</li>
  <li><strong>How</strong>: OSHA will provide a secure website that offers three options for data submission. First, users will be able to manually enter data into a web form. Second, users will be able to upload a CSV file to process single or multiple establishments at the same time. Last, users of automated record-keeping systems will have the ability to transmit data electronically via an API (application programming interface). We will provide status updates and related information here as it becomes available.</li>
</ul>

<p>I think the three options available are interesting. Manual website, and a CSV file upload–which is kind of a gateway to API-land, but they will also be providing the real deal when it comes to submitting forms using an API. All government agencies should be migrating towards this approach to handling forms, and OSHA provides us with one more blueprint to point at when convincing government to be more machine readable when it comes to forms–if there is a web form, or PDF form, there should also be an API for submitting as well.</p>

<p>Now that the federal agency is on my radar I will be keeping an eye out for when their API is ready, and maybe even offer some help when it comes to the portal and presence for the API. I like this example because it is a good reference for APIs being used to deliver government forms, but also because it is a good example of API driven regulatory compliance, which I think we need more of. Not because regulations automatically equal good, but because we need regulations and business compliance to be as observable as we possibly can–APIs will be how we do this.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api.-markdown/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/making-an-account-activity-api-the-default/">Making An Account Activity API The Default</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><a href="https://dev.twitter.com/webhooks/account-activity"><img src="https://s3.amazonaws.com/kinlane-productions/twitter/twitter-account-activity-api-.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://medium.com/@esfand/twitter-account-activity-api-8c59347380be">I was reading an informative post about the Twitter Account Activity API</a>, which seems like something that should be the default for ALL platforms. In today’s cyber insecure environment, we should have the option to subscribe to a handful of events regarding our account or be able to sign up for a service that can subscribe and help us make sense of our account activity.</p>

<p>An account activity API should be the default for ALL the platforms we depend on. There should be a wealth of certified aggregate activity services that can help us audit and understand what is going on with our platform account activity. We should be able to look at, understand, and react to the good and bad activity via our accounts. If there are applications doing things that don’t make sense, we should be able to suspend access, until more is understood.</p>

<p>The Twitter Account Activity API Callback request contains three level of details:</p>

<ul>
  <li>direct_message_events: An array of Direct Message Event objects.</li>
  <li>users: An object containing hydrated user objects keyed by user ID.</li>
  <li>apps: An object containing hydrated application objects keyed by app ID.</li>
</ul>

<p>The Twitter Account Activity API provides a nice blueprint other API providers can follow when thinking about their own solution. While the schema returned will vary between providers, it seems like the API definition, and the webhook driven process can be standardized and shared across providers.</p>

<p><a href="https://dev.twitter.com/webhooks/account-activity">The Twitter Account Activity API is in beta</a>, but I will keep an eye on it. Now that I have the concept in my head, I’ll also look for this type of API available on other platforms. It is one of those ideas I think will be sticky, and if I can kick up enough dust, maybe other API providers will consider. I would love to have this level of control over my accounts, and it is also good to see Twitter still rolling out new APIs like this.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/making-an-account-activity-api-the-default/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org.-markdown/">Shared Publishing Of Data and API Projects, Portals, and Dashboards Using Github</a></h3>
        <span class="post-date">29 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-github-continous-integration-orchestration.png" align="right" width="30%" style="padding: 15px;" /></p>
<p><a href="http://apievangelist.com/api-lifecycle/">Each one of the 80+ areas of my API Evangelist lifecycle research projects</a> is a single Github repository that I publish JSON or YAML data stores containing the news, organizations, tools, APIs, and patents that I’ve aggregated as part of my research. The home page of each site is a set of UI elements that take the data store and renders it into something that makes the data consumable by a human. I reference each project my storytelling, and it acts as a workbench as I craft my guides, white papers, and API strategy work as a consultant.</p>

<p>The news I have curated is published as a news listing. Organizations and tools are published as a listing with icons, title, description, and links. Listings of my partners, banner logos, and other elements are driven from YAML and JSON files I update as part of my continuous integration with Google Spreadsheets, Feedly, Twitter, Facebook, LinkedIn, and other services I use to manage my operations. I have a variety of manual, and automated processes that are run each day, publishing, syndicated and moving the API Evangelist platform.</p>

<p>All of this is open to anyone else who wants to publish to it via a Github commit, or via the API when you possess valid Github API token like I do. I publish data using a variety of Github accounts depending on which project or organization I am working on. In its simplest form it is collaborative website development. When you combine with YAML and JSON data, and a Jekyll presentation layer it can become collaborate dashboard publishing, with shared ownership of a forkable data engine. Each player can publish the YAML or JSON they are in charge of, and the Github hosted, Jekyll and Github Pages presentation layer displays as a website, dashboard, or even machine readable, static data feeds in YAML, JSON, Atom, CSV, or another format.</p>

<p>I have a variety of Github templates for managing my network of API research sites, as well as forkable projects that anyone can launch to support open data projects like my <a href="http://adopta-agency.github.io/adopta-blueprint/">Adopta.Agency blueprint</a>, or a <a href="http://developer.open.referral.adopta.agency/">human services API developer portal</a>. It’s not just me doing this, you can find [a forkable example of an API and developer over at the <a href="http://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/">General Services Administration(GSA)</a>, providing a baseline API definition that other government agencies can follow when launching an API, and be publishing an API developer portal. Github works well for the continous integration and deployment of open data, and API portals, projects, and dashboards that can be managed in a collaborative fashion out in the open, or behind a curtain with a private repository.</p>

<p>I’m working with a handful of API providers to experiment publishing API industry data in this way. Combining the organizations, news, tools, patents, and other data I aggregate from across the API industry with additional monitoring, search, discovery, security, and other relevant data into single project sites, data and API portals, and industry dashboards. I’m looking to draw out more API service providers and encourage them to share data that could benefit the entire community. I’ve been doing this for a while with API definitions, but will be expanding into other areas of the lifecycle, and hopefully encouraging more sharing, and forcing y’all to come out of your siloes a bit, and learn to work together–whether you like it or not.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org.-markdown/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org/">Shared Publishing To Github Org</a></h3>
        <span class="post-date">29 Jun 2017</span>
        

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/shared-publishing-to-github-org/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api/">Electronic Submission Of Injury And Illness Records To Osha Using Api</a></h3>
        <span class="post-date">29 Jun 2017</span>
        

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/29/electronic-submission-of-injury-and-illness-records-to-osha-using-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/algorithmic-transparency-in-policing/">Algorithmic Observability In Predictive Policing</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope/stories/crypto-machine-bletchley_copper_circuit.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>As I study the world of APIs I am always on the lookout for good examples of APIs in action so that I can tell stories about them, and help influence the way folks do APIs. This is what I do each day. As part of this work, I am investing as much time as I can into better understanding how APIs can be used to help with algorithmic transparency, and helping us see into the black boxes that often are algorithms.</p>

<p>Algorithms are increasingly driving vital aspects of our world from what we see in our Facebook timelines, to whether or not we would commit a crime in the eyes of the legal system. <a href="http://washingtonmonthly.com/magazine/junejulyaugust-2017/code-of-silence/">I am reading about algorithms being used in policing in the Washington Monthly</a>, and I learned about an important example of algorithmic transparency that I would like to highlight and learn more about. A classic argument regarding why algorithms should remain closed is centered around intellectual property and protecting the work that gives you your competitive advantage–if you share your secret algorithm, your competitors will just steal it. While discussing the predictive policing algorithm, Rebecca Wexler explores the competitive landscape:</p>

<blockquote>
  <p>But Perlin’s more transparent competitors appear to be doing just fine. <a href="https://www.cybgen.com/products/casework.shtml">TrueAllele’s</a> main rival, a program called STRmix, which claims a 54 percent U.S. market share, has an official policy of providing defendants access to its source code, subject to a protective order. Its developer, John Buckleton, said that the key to his business success is not the code, but rather the training and support services the company provides for customers. “I’m committed to meaningful defense access,” he told me. He acknowledged the risk of leaks. “But we’re not going to reverse that policy because of it,” he said. “We’re just going to live with the consequences.”</p>
</blockquote>

<blockquote>
  <p>And remember <a href="http://www.predpol.com/">PredPol</a>, the secretive developer of predictive policing software? <a href="https://www.hunchlab.com/">HunchLab</a>, one of PredPol’s key competitors, uses only open-source algorithms and code, reveals all of its input variables, and has shared models and training data with independent researchers. Jeremy Heffner, a HunchLab product manager, and data scientist explained why this makes business sense: only a tiny amount of the company’s time goes into its predictive model. The real value, he said, lies in gathering data and creating a secure, user-friendly interface.</p>
</blockquote>

<p>In my experience, the folks who want to keep their algorithms closed are simply wanting to hide incompetence and shady things going on behind the scenes. If you listen to individual companies like Predpol, it is critical that algorithms stay closed, but if you look at the wider landscape you quickly realize this is not a requirement to stay competitive. There is no reason that all your algorithms can’t be wrapped with APIs, providing access to the inputs and outputs of all the active parts. Then using modern API management approaches these APIs can be opened up to researchers, law enforcement, government, journalists, and even end-users who are being impacted by algorithmic results, in a secure way.</p>

<p>I will be continuing to profile the algorithms being applied as part of predictive policing, and the digital legal system that surrounds it. As with other sectors where algorithms are being applied, and APIs are being put to work, I will work to find positive examples of <a href="http://apievangelist.com/2016/08/04/pushing-for-more-algorithmic-transparency-using-apis/">algorithmic transparency</a> like we are seeing from STRmix and HunchLab. I’d like to learn more about their approach to ensuring observability around these algorithms, and help showcase the benefits of transparency and observability of these types of algorithms that are impacting our worlds–helping make sure everyone knows that black box algorithms are a thing of the past, and the preferred approach of snake oil salesman.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/algorithmic-transparency-in-policing/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/continue-to-explore-restaurant-menu-as-an-analogy-for-api-copyright-and-patents/">Continue To Explore Restaurant Menu as an Analogy for API Copyright and Patents</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><a href="https://portlandfoodcartadventures.com/2013/01/23/burger-guild-food-cart-a-portland-food-cart-review/"><img src="https://s3.amazonaws.com/kinlane-productions/burger-guild-menu1.jpg" align="right" width="35%" style="padding: 15px;" /></a></p>
<p>While working on my feedback to the EFF for the first response to the Oracle v Google API copyright case, <a href="https://apievangelist.com/2014/05/23/restaurant-menus-as-analogy-for-api-copyright/">one of the stories I published used the restaurant menu as an analogy for API copyright</a>. This example was used in the most recent response by Google’s lawyers as they defended themselves in court, and as I’m working on my API patent research, I wanted to revisit this analogy, in the same way, helping focus attention on why API patents are such a bad idea.</p>

<p>Building on my previous analogy, as a restaurant, imagine your restaurant specialty is delivering meat-centric dishes. Your burgers and steaks are da bomb! You literally have several “secret sauces”, some unique preparation processes, as well as some very appealing ways of naming and describing your dishes. Not that different from many API providers, who have some “secret sauces”, some unique process, as well as some very appealing ways of naming and describing the very useful APIs they are offering.</p>

<p>In regards to copyright, why would you want to lock up the naming and ordering of what you are offering? Even if your competitor copies the exact wording on their menu (documentation), their burgers and steaks do not have your secret sauce or unique processes. Also, why would you want to burden food delivery services from aggregating your menu (documentation) alongside other restaurants using copyright? Don’t restrict how the local paper or food rag can reference your menu (documentation), and publish it on and offline–it is unnecessary and will do nothing to protect your business.</p>

<p>In regards to patents, why would you want to lock up the menu to your burgers and steaks alongside your secret sauce(s) and unique process? Could you imagine if McDonalds sued everyone for patent infringement because they had a burger section on their menu? Someone comes up with a unique burger, and now nobody can have a specific meat dish sections on their menu? The menu and the ingredients of your recipe shouldn’t be included in your patent. If your process is truly that unique, and remarkable, then patent that, you shouldn’t be locking up the ingredients, and the ways of naming, describing, and providing a menu (documentation) for your dish (APIs).</p>

<p>I am not anti-patent (well almost), but am 100% anti API patent. APIs are not your secret sauce or process. The URL, parameters, headers, body, response, and other elements of your API are no more patentable than hamburger, buns, mustard and ketchup are for your killer burger. The reason we have so many API patents is that we have very greedy, short-sighted companies who are just racing to get a piece of the action, and they have been taught that patents are how you make a grab for all the digital dishes on the table, or even might possibly be on the table in the future. They see things moving in a particular direction, and rather than doing those things well, they focus on locking up the doing of that thing.</p>

<p>If you are in the business of patenting your companies technology, please focus on patenting your secret sauce and truly unique processes, not the method for exchanging, selling, and baking your solution into other systems and applications. APIs should not be patented. APIs, no matter how unique they might be, are not the thing you should be defending. You should be making them accessible, and defending the unique and valuable thing you do behind them. Stop including API in your patent filings please, it goes against everything that makes API even works.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/continue-to-explore-restaurant-menu-as-an-analogy-for-api-copyright-and-patents/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/api-preparation-at-the-bureau-for-the-2020-census/">API Preparation At The Bureau For The 2020 Census</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><a href="https://data.census.gov/cedsci/landing"><img src="https://s3.amazonaws.com/kinlane-productions/census/census-2020-mobile-preparation.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I was reading about what <a href="https://gcn.com/articles/2017/06/16/census-open-data.aspx">the Census is doing to prepare for the 2020 census over at GCN</a>. I’ve been <a href="https://apievangelist.com/2013/08/22/delivering-value-for-developers-is-first-when-it-comes-to-the-census-bureau-apis/">invested in what they are doing at Census for some time now</a>, so it makes me happy to see where they are headed with their preparation for the 2020 census. From what I’ve read, and what I’ve seen with their existing API efforts, they have really taken API to heart and are working to bake APIs into everything they do.</p>

<p>According to GCN: Through the site’s application programming interface, users will be able to download and manipulate the data to serve their own purposes; ensuring that the API can drive all of data.census.gov’s core functions means outside users will have more power as well. “The more that we make this API capable, then we can serve our customers better by providing them with ways to extend the API in their own platforms for their customer base” – said Census Bureau Chief Data Officer Zach Whitman. Continuing to show that the folks at Census get APIs.</p>

<p>The Census Bureau is the most important API out there for helping us understand the people of the United States, and how the economy is working, or not working for us. <a href="https://data.census.gov/cedsci/landing">When you look at the landing page there are working on in preparation of the 2020 Census you can tell they continue to work hard to find new ways of exploring and visualization the huge amount of data they have gathered through the censuses of the past</a>. I’m glad the Census Bureau has been on their API journey for several years now, as what they have learned will go a long way towards making the 2020 census make a more meaningful impact.</p>

<p>APIs are not just about providing access to data. They are also about allowing many 3rd parties to add, update, as well as access and put to use data. Having the infrastructure and practice will contribute to a more collaborative and interactive census in 2020. Allowing local and regional players to actively play a role in the census as it plays out. What the Census teams have learned over the last couple of years operating their API platform will improve the results and the reach of the 2020 census in a way that will make it inclusive and relevant for the average citizen across the country.</p>

<p>I’ve met the Census data and API teams, I’m not worried about their preparation for the 2020 census. I do worry about whether or not they will have the resources they need to get the job done. With current discussions around funding the agency, as well as supporting the proper leadership at the agency. Like every other API effort I’ve come across it, the success of the 2020 census won’t just be a technical thing, it will also be about having the right business and political platform to ensure APIs are done right and are serving all stakeholders–which in the case of the 2020 Census includes every citizen in the United States.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/api-preparation-at-the-bureau-for-the-2020-census/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/28/i-have-two-interesting-apis-and-i-am-not-a-developer-what-do-i-do/">I Have Two APIs I Am Interested In And I Am Not A Developer--What Do I Do?</a></h3>
        <span class="post-date">28 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/api-documentation-unistats.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>My friend David Kernohan (<a href="https://twitter.com/dkernohan">@dkernohan</a>) emailed me the other day asking me for some advice on where to get started working with some data APIs he had been introduced to. This is such a common question for me, and surprisingly seven years into API Evangelist they are questions I still do not have easy answers for. Partly because I spend the majority of my time writing about providing APIs, but also because API consumption is often times inconsistent, and just hard.</p>

<p>David provided me with two sources of data he wanted to work, which I think help articulate the differences between APIs, that can make things hard to work with when you are just getting started with any API. Let’s break down the two APIs he wants to work with:</p>

<ul>
  <li><strong>UNISTATS</strong>
    <ul>
      <li>Description: Compare official course data from universities and colleges.</li>
      <li>URL: <a href="http://dataportal.unistats.ac.uk/Pages/ApiDocumentation">http://dataportal.unistats.ac.uk/Pages/ApiDocumentation </a></li>
      <li>Details: It is an API with 8 separate paths to get what you need.</li>
      <li>Resources: Institution, Course, Stages, Accreditations, Locations, Statistics</li>
      <li>Data Type: XML &amp; JSON</li>
      <li>Authentication: Basic Auth</li>
    </ul>
  </li>
  <li><strong>Higher Education Funding Council for England (HEFCE) Register of Higher Education Providers</strong>
    <ul>
      <li>Description: The HEFCE Register is a searchable tool that shows how the Government regulates higher education providers in England.</li>
      <li>URL: <a href="http://www.hefce.ac.uk/reg/register/data/">http://www.hefce.ac.uk/reg/register/data/</a></li>
      <li>Details: Downloadable files with 6 urls available.</li>
      <li>Resources: Providers, Courses</li>
      <li>Data Type: XML, CSV</li>
      <li>Authentication: Auth: NONE</li>
    </ul>
  </li>
</ul>

<p>Here you have two sources of data that overlap. One is actually an API, which you can change paths, parameters, and get different JSON or XML results. The other is just a download of an XML or CSV file. One has authentication using <a href="https://en.wikipedia.org/wiki/Basic_access_authentication">BasicAuth</a>, which is a standard way of logging into websites, which often is reappropriated for accessing web APIs. You can start to see why API consumption can become pretty overwhelming, pretty quickly.</p>

<p><strong>CSV Is Easier</strong>
So where do we start? Well with the HEFCE downloads you get the results in CSV, something you can quickly upload into a spreadsheet and get to work. This is pretty straightforward data 101 stuff, making CSV and the spreadsheet still number one when it comes to working with data–a wide audience. However, the core dataset David wanted to work with from UNISTATS is an API, with JSON and XML returned. I know us API folk like to think of APIs as opening up access to data, but this chasm is one that many folks aren’t going to be able to step over.</p>

<p>XML is Harder
Let’s begin with the pulling a list of institutions in XML. Before I can get at the data <a href="http://dataportal.unistats.ac.uk/Account/Register">I need to sign up for an account</a>. After signing up I am given a key which I can use to authenticate the first time I try to load the URL <a href="http://data.unistats.ac.uk/api/v3/KIS/Institutions.xml">http://data.unistats.ac.uk/api/v3/KIS/Institutions.xml</a>–there are <a href="http://dataportal.unistats.ac.uk/Pages/ApiAuthentication">more details about authentication</a> as part of their documentation. As soon as I download this file, I double click on it to see which application will try to load it–Microsoft Word happily steps forward to assume the responsibility. However, it does me little good, and just loads a big XML blog in a documentation–what do I do with that? Next, I try with Microsoft Excel with the same results. Google Drive gives me the same response, uploads as XML, and loads as a blog with no recognition by Google Docs or Spreadsheet. So what now?</p>

<p>We have a set of CSV files, and potentially a set of XML files, after making our way through each available path of the UNISTATS API. We need to get the XML into Google Sheets, or Microsoft Excel. The CSV is easy, the XML is hard–we will need to convert from XML to CSV. We could accomplish this with the <a href="https://support.google.com/docs/answer/3093342?hl=en">Google Sheets importXML function</a>, but because the API requires authentication it would need some programming–I wanted to keep this code free if possible for now. We are able to authentication with the UNISTATS API via our browser and download the XML with this API, so writing code, even a Google Script seems over the top.</p>

<p><strong>XML To CSV Conversion</strong>
I recommend using a simple tool like <a href="http://www.convertcsv.com/xml-to-csv.htm">XML To CSV Converter</a>, and not overengineering this time. You can just download the XML returned from the UNISTATS API, save to desktop and upload to the XML to CSV Converter to get the CSV edition. Then the data from the UNISTATS API and the HEFCE downloads, all CSV format now can be uploaded to Google Sheets, or imported into Microsoft Excel for working with. This process can be repeated as necessary, whenever the data is updated on each of the sites–no coding necessary.</p>

<p><strong>Reusing This Process For Future APIs</strong>
This process worked with these two APIs. Next time you are working on a project the APIs could have different types of paths available, returning XML, JSON, CSV, or other configuration. They might have different types of authentication requiring API keys as a parameter, or maybe even OAuth–raising the bar even higher when it comes to connecting. Most importantly, sometimes the data returned might not be neat columns and rows, and not be compatible with working within a spreadsheet. Many APIs return “flat” data like we encountered this round, but an increasing number of APIs are returning much more structured forms of data that won’t simply import into a spreadsheet.</p>

<p>For this API exercise, we were able to take care of business using the browser. We were able to download the CSV, and the XML from the API using the browser as a client–no coding necessary. This is a really important element of understanding APIs. Websites return HTML for browsers to show to humans, and web APIs return XML, JSON, CSV, or another machine readable format for use in ANY application–in this case, it was a spreadsheet that will help us take things to the next level and figuring out what we want to do next with this data, to make sense of things.</p>

<p><strong>Look At Leading API Clients – No Code Necessary</strong>
For future API projects, I recommend taking a look at the <a href="https://www.getpostman.com/">Postman</a>, or <a href="https://restlet.com/modules/client/">Restlet API client</a>. Which will help act as a client for working with simple, and more complex APIs–helping you with authentication, headers, and other aspects of consuming a diverse range of APIs. These clients allow you to connect to APIs, and work with the XML, JSON, CSV, and other responses you will receive. Of course you will still have to download, convert, and upload resulting data into whatever application you intend to work with data within. These are simply clients, not applications that will help you transform, analyze, visualize, and make sense your data–it is up to you to do this.</p>

<p><strong>Some Final Thoughts On API Consumption</strong>
Despite almost 17 years of evolution web API consumption is still hard, and in the realm of programmers. Google Sheets and Microsoft Excel have tools to help you pull in data from APIs, but authentication and complex data structures will always be an obstacle in this environment. For more complex API integrations I recommend adopting an API client like Postman or Restlet, which will augment Google and Excel spreadsheets in your toolbox. Beyond that, I encourage using Github for publishing CSV, JSON, or YAML that is returned from APIs, and telling stories around the data using Github Pages. Github has been working hard to build in features for working with CSV, JSON, and YAML data, again making it possible to work with data returned form APIs with no, or minimal coding–Github employs <a href="https://jekyllrb.com/">Jekyll</a>, which in turn uses <a href="https://help.shopify.com/themes/liquid/filters/string-filters">Liquid</a> + HTML, but is something totally still within the realm of non-programmers.</p>

<p>Learning how to consume APIs is a journey, not a destination. APIs come in many shapes and sizes, but if you grasp the basic of the web, and have some of the right tools in your toolbox, you can navigate them and put them to work. I’m going to work on some more Google Spreadsheet examples, as well as some Postman and Restlet examples, using some of the most common APIs out there like Twitter, Flickr, and others. I’ll check back with David in a couple weeks to see how he is doing when it comes to onboarding with the APIs he has targeted for this project, and see where I can help him in his journey.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/28/i-have-two-interesting-apis-and-i-am-not-a-developer-what-do-i-do/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/the-open-service-broker-api/">The Open Service Broker API</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><a href="https://openservicebrokerapi.org/"><img src="https://s3.amazonaws.com/kinlane-productions/open-service-broker-api/osbapi_logo_concept3_wtm.png" align="right" width="40%" style="padding: 20px;" /></a></p>
<p>Jerome Louvel <a href="http://apis.how/5ytnitnakm">from Restlet</a> introduced me to <a href="https://openservicebrokerapi.org/">the Open Service Broker API</a> the other day, a “project allows developers, ISVs, and SaaS vendors a single, simple, and elegant way to deliver services to applications running within cloud-native platforms such as Cloud Foundry, OpenShift, and Kubernetes. The project includes individuals from Fujitsu, Google, IBM, Pivotal, RedHat and SAP.”</p>

<p>Honestly, I only have so much cognitive capacity to understand everything I come across, so I pasted the link into my super secret Slack group for API super heroes to get additional opinions. My friend James Higginbotham (<a href="https://twitter.com/launchany">@launchany</a>) quickly responded with, “if I understand correctly, this is a standard that would be equiv to Heroku’s Add-On API? Or am I misunderstanding? The Open Service Broker API is a clean abstraction that allows ‘services’ to expose a catalog of capabilities, as well as the ability to create, use and delete those services. Sounds like add-on support to me, but I could be wrong[…]But seems very much like vendor-to-vendor. Will be interesting to track.”</p>

<p>At first glance, I thought it was more of an aggregation and/or discovery solution, but I think James is right. It is an API scaffolding that SaaS platforms can plug into their platforms to broker other 3rd party API services. It allows any platform to offer <a href="https://devcenter.heroku.com/categories/extending-heroku">an environment for extending your platform like Heroku does</a>, as James points out. It is something that adds an API discovery dimension to the concept of offering up plugins, or I guess what could be an embedded API marketplace within your platform. Opening up <a href="http://apievangelist.com/2014/01/30/what-will-it-take-to-sell-my-api-as-a-wholesale-resource/">wholesale</a> and private label opportunities for API providers to sell their warez directly on other people’s platforms.</p>

<p>The concept really isn’t anything new. I remember developing document print plugins for Box back when I worked with the Mimeo print API in 2011. <a href="https://openservicebrokerapi.org/">The Open Service Broker API</a> is just looking to standardize this approach so hat  API provider could bake in a set of 3rd party partner APIs directly into their platform. <a href="http://plugin.apievangelist.com/">I’ve recently added a plugin area to my API research</a>. I will add the Open Service Broker API as an organization within this research. I’m probably also going to add it to my <a href="http://discovery.apievangelist.com/">API discovery research</a>, and I’m even considering expanding it into an API marketplace section of my research.  I can see add-on, plugin, marketplace, and <a href="http://apievangelist.com/2014/10/10/exploring-the-possibilities-of-being-an-api-broker/">API brokering like this grow into its own discipline</a>, with a growing number of definitions, services, and tools to support.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/the-open-service-broker-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/api-environment-portabiity/">API Environment Portability</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><a href="https://blog.runscope.com/posts/tutorial-copying-runscope-environments-using-runscope-api"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/runscope/1-runscope-env.jpg" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I was reading <a href="https://blog.runscope.com/posts/tutorial-copying-runscope-environments-using-runscope-api">the post from Runscope on copying environments using their new API</a>. I was looking through the request and response structure for their API, it looks like a pretty good start when it comes to what I’d call API environment portability. I’m talking about allowing us to define, share, replicate, and reuse the definitions for our API environments across the services and tools we are depending on.</p>

<p>If our API environment definitions shared a common schema, <a href="https://www.runscope.com/docs/api/environments">and API like Runscope provides</a>, I could take my Runscope environment settings, and use them in my Stoplight, <a href="https://restlet.com/modules/client/">Restlet Client</a>, Postman, and other API services and tooling. It would also help me templatize and standardize my development, staging, production, and other environments across the services I use. Assisting me in keeping my environment house in order, and also something that I can use to audit and turn over my environments to help out with security.</p>

<p>It is just a thought. An API environment API, possessing an evolving but common schema just seems like one of those things that would make the entire API space work a little smoother. Making our API environments exportable, importable, and portable just seems like it would help us think through when it comes setting up, configuring, managing, and evolving our API environments–who knows maybe someday we’ll have API service providers who help us manage our API environments, dictating how they are used across the growing number of API services we are depending on.</p>

<p><strong>Disclosure:</strong> Runscope and Restlet are API Evangelist partners.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/api-environment-portabiity/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/patent-number-us-20170153932-adapting-legacy-endpoints-to-modern-apis/">Patent #US 20170153932: Adapting Legacy Endpoints To Modern APIs</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/jetpack-patent.jpg" align="right" width="35%" style="padding: 15px;" /></p>
<p><a href="http://patents.apievangelist.com/#Patents">I made my API patent inventory a little more explorable this week</a>, allowing me to more easily discover new and interesting patents that will affect the world of APIs, which I can include in my research. An interesting patent from eBay quickly floated up to the top as a questionable idea for a patent.</p>

<p><a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;S1=09576314&amp;OS=09576314&amp;RS=09576314"><strong>Adapting legacy endpoints to modern APIs:</strong></a></p>

<p>Example methods and systems are directed to adapting legacy endpoints to modern application protocol interfaces (APIs). A legacy endpoint may provide a powerful and complex API. A modern application may desire access to the legacy endpoint. One or more layers may be added between the modern application and the legacy endpoint. Each layer may provide a different API. These layers of APIs may transform the interface from a powerful and complex interface to a more limited but simpler and easier to use interface. In some example embodiments, a proxy layer, an adapter layer, a facade layer, and a service layer may be used.</p>

<p>Pub Date: 2016/27/06
Number: 09576314
Owner: eBay Inc.
Location: San Jose, US
Details: <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;S1=09576314&amp;OS=09576314&amp;RS=09576314">Visit USPTO</a></p>

<p>Adapting legacy endpoints to modern APIs is a fundamental aspect of doing APIs in the first place. It is something that is useful and completely obvious. This is one of those patents that makes me question the competency of folks reviewing patents at the USPTO. If you at all are acquainted with the concept of web APIs, you know that this is something that is already done, and not worthy of the non-obvious aspect of being a patent.</p>

<p>APIs have no place in patents. I think this patent pretty clearly shows the system is broken, and the reasons why many companies are filing patents have reached an unhealthy level, as well as how broken the USPTO is. If they are approving a patent for adapting legacy endpoints to modern APIs in 2016 and 2017, they are pretty out of touch with the digital world that is unfolding around us.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/patent-number-us-20170153932-adapting-legacy-endpoints-to-modern-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/27/i-published-60k-patents-to-github-as-part-of-my-api-patent-research/">I Published 60K Patents To Github As Part Of My API Patent Research</a></h3>
        <span class="post-date">27 Jun 2017</span>
        <p><a href="http://patents.apievangelist.com/#Patents"><img src="https://s3.amazonaws.com/kinlane-productions/patents/api-evangelist-patent-listing-screenshot.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I’ve been migrating from my own homebrew CMS system over the last couple of weeks, ditching it for a variety of existing services, balancing my operations across a diverse set of platforms I’ve identified as useful. I’m using Github and Jekyll to manage my content system, storing thinks like blog, news, notes, and patents there. Github repos are well suited for storing this type data for free (if it is public), and Jekyll is well suited for helping me manage small to large repositories of content I need to use across my platform.</p>

<p>This last week I migrated 60K patents I had filtered out of all the <a href="http://patents.reedtech.com/pgrbft.php">XML dumps of patents I downloaded</a>, between the years of 2005 and 2016. I filtered out any patent with API or application programming interface in the title, abstract, or body of the patent. Once done importing, I clean up the body a little bit and publish each one as a Jekyll post within a Github repo. I had to break them down by year, as Github started getting wonky after 10K file, but the Jekyll structure works well for managing up to 10K patents. Once committed, I find the Jekyll post and data structure pretty easy to navigate and use for some API storytelling.</p>

<p><a href="http://patents.apievangelist.com/#Patents">I like having the full listing of title and abstract available to search in a single public HTML page</a>. I have also started publishing keyword filters for each area of my research. It is taking me a while to build the index for each JSON API, but it is allowing me to quickly get at <a href="http://patents.apievangelist.com/#Patents">cached searches for machine learning, API management</a>, and other patents that affect the areas of the API lifecycle I’m keeping a close eye on. I will keep adding filters and enhancing the ones that I have, but ultimately it takes me reading a large number of patents and then actually tagging each one, that will help me build a useful API patent catalog.</p>

<p>I feel that these relevant patents help tell an important story about each layer of the API lifecycle. Patents add another dimension to the story of what is going on when it comes to API design, deployment, management, discovery, and other areas that are growing in 2017, and in coming years. The products, services, and tooling I track on from organizations included in <a href="http://apievangelist.com/api-lifecycle/">my API lifecycle research</a> paint a significant part of the picture, but I feel that patents pull back the curtain just a little bit more when it comes to what companies are thinking. I will keep processing new files from the USPTO every couple of weeks, evolving my filters, and tagging patents for better recall in my API patent storytelling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/27/i-published-60k-patents-to-github-as-part-of-my-api-patent-research/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/three-new-api-industry-groups-on-the-horizon/">Three New API Industry Groups On The Horizon</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/industry/industry-work-group.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>Along with the growth of industry level API events for machine learning, healthcare, and beyond, I’m starting to see the emergence of more API specific working groups, something I’ve been asking for, for some time now. The API universe is expanding and we will need API specialists with domain expertise to help push forward the conversations in leading industries like healthcare, banking, education, transportation, and beyond.</p>

<p>I’ve been keeping an eye out for any movement within industries beyond <a href="https://www.hl7.org/fhir/overview.html">FHIR</a> and <a href="https://ec.europa.eu/info/business-economy-euro/banking-and-finance/consumer-finance-and-payments/payment-services_en">PSD2</a>, and now I”m adding three more efforts to my list:</p>

<ul>
  <li>Artificial Intelligence - <a href="https://www.nttdocomo.co.jp/english/info/media_center/pr/2017/0623_00.html">NTT DOCOMO’s new docomo AI Agent Open Partner Initiative</a> to facilitate collaborative development of all-new offerings implemented with a service-agnostic, device-agnostic speech interface based on AI Agent API, a newly developed artificial intelligence (AI) application programming interface (API) that DOCOMO plans to incorporate into a new AI agent service to be launched in early fiscal 2018.</li>
  <li>Payments - <a href="https://www.nacha.org/content/api-standardization-industry-group">The National Automated Clearing House Association (NACHA) API Industry Standardization Group</a> looking to “help improve the safety and transparency of transactions, increase efficiencies and speed of communications, and enhance support of payments innovations.”</li>
  <li>Hospitality - <a href="http://www.htng.org/?page=ActiveWorkgroups">The Hospitality Technology Next Generation (HTNG) API Registry</a> looking to address a number of inefficiencies in the Hospitality API space, including finding potential technology partners whose products and/or services that could add value to an hotelier’s offerings, by creating a registry of Hospitality API’s to help modernize this space.</li>
</ul>

<p>These three efforts provide some interesting models for how companies and existing industry organizations are stepping up to provide leadership when it comes to API definitions, standards, and discovery in a particular business sector. There are no signs of whether these organizations will get off the ground and become sustainable, or that their stewards understand the wider API space, and have their industries best interest in mind. It does provide us with a glimpse at what is coming though, and the opportunity for companies, organizations, institutions, and government agencies to step up and take the lead when it comes to API standards.</p>

<p><a href="http://org.open.referral.adopta.agency/">I am taking my Open Referral Human Services API work which helps lead the discussion around the 211 API standard</a>, while also looking to help my friend Phil Ashlock move forward <a href="http://www.open311.org/">the Open311 standard</a> in a similar fashion. These are community efforts that are looking to help standardize how municipal agencies and organizations share information. I’m hoping to take this work, and merge with what I’m seeing in other industries and eventually establish a blueprint that anyone looking to start an API standards organization can take and put to work–hopefully, it is something that will forkable and deployable using Github like any API project should be.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/three-new-api-industry-groups-on-the-horizon/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/healthcare-api-interoperability-at-hl7-fhir-dev-days-in-amsterdam/">Healthcare API Interoperability At HL7 FHIR Dev Days In Amsterdam</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><a href="https://www.fhirdevdays.com/"><img src="https://s3.amazonaws.com/kinlane-productions/fhir/fhir-devdays-2017-amsterdam.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://apievangelist.com/2017/06/07/a-conference-focused-on-machine-learning-apis/">I wrote about a machine learning specific API event a couple weeks back</a>, and today I wanted to highlight the growth of conferences dedicated to <a href="https://www.hl7.org/fhir/">FHIR, or the Fast Healthcare Interoperability Resources</a>. FHIR is larger than just it’s API, but it is one very important example of how APIs and open industry API specifications can help move forward the API conversation in large industries.</p>

<p>As part of my healthcare API research, I bookmarked <a href="https://www.fhirdevdays.com/">HL7 FHIR DEVDAYS 2017</a>, a conference dedicated to standardizing healthcare APIs, and increasing interoperability across the global healthcare system. I went through <a href="https://www.fhirdevdays.com/schedule/">the three-day schedule for the conference</a>, following speakers on Twitter, and learning more about what being presented when it came to healthcare interoperability–expanding my awareness of what is going on when it comes to connecting healthcare systems and pushing forward this important API definition.</p>

<p>FHIR is right there with <a href="https://www.eba.europa.eu/regulation-and-policy/payment-services-and-electronic-money/regulatory-technical-standards-on-strong-customer-authentication-and-secure-communication-under-psd2">PSD2 for banking</a>. While not perfect examples, they are the two most significant examples we have when it comes moving forward an API standard for a large industry that are critical to our society. I don’t have the time to become an expert on every detail of FHIR or PSD2, but I do think it is important as an API professional to understand what is going on in these communities. Much like we’ve done with the API sector with the <a href="http://events.linuxfoundation.org/events/apistrat">API Strategy &amp; Practice Conferenc</a>, we are going to need more industry level API-focused conferences to emerge, helping industries come together and hammer out a common API definition, as well as the services and tooling that will be putting these definitions to work on the ground across the API economy.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/healthcare-api-interoperability-at-hl7-fhir-dev-days-in-amsterdam/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/budget-transparency-at-the-county-level-with-open-data-and-apis/">Budget Transparency At The County Level With Open Data And APIs</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><a href="https://socrata.com/blog/douglas-county-open-budget-invites-public-explore-annual-budget/"><img src="https://s3.amazonaws.com/kinlane-productions/socrata/douglas-county-operating-budget-768x485.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>As we find ourselves darker times when it comes to transparency within the federal government in the United States, I’m always on the hunt for any positive signs of transparency at the other levels of government. I can usually depend on my friends <a href="https://socrata.com">over at Socrata</a> to help out, and <a href="https://socrata.com/blog/douglas-county-open-budget-invites-public-explore-annual-budget/">they came through this week with a story on Douglas County, Kansas publishing their budget online</a>.</p>

<p>“This week, Douglas County, Kansas, home to 117,000 residents, launched an <a href="http://budget.douglascountyks.org/">Open Budget site</a>, which provides the public with access to one of the county’s most crucial documents: the annual operating budget.” Jill Jolicoeur, Assistant to the County Administrator stated that “our goal is for Open Budget to replace the time-intensive process of developing and publishing the annual budget in a hard-copy format.” Open data and APIs is one way for resource-strapped companies can open things up, allowing external groups help share the load when it comes to auditing, analysis, visualization, and many other areas county government could use some assistance.</p>

<p>Douglas County provides us with another example of how we can make government more <a href="http://observability.apievangelist.com/">observable</a>. There is no reason that county government can’t open up their budgets like this, and let a little sunlight into the operations. In my experience, the primary reason you want to keep things closed is when you are looking to hide corruption, incompetence, and poor technological and business decisions. I’m concerned with the bar being set by the White House right now when it comes to transparency and observability, but it doesn’t mean we can’t resist at the local level, and leverage open data and APIs to get things done more efficiently–like Douglas County is doing, and <a href="https://socrata.com">Socrata</a> is enabling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/budget-transparency-at-the-county-level-with-open-data-and-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/26/the-competitive-advantage-of-api-agility-over-any-secret-saurce/">The Competitive Advantage Of API Agility Over Any Secret Sauce</a></h3>
        <span class="post-date">26 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algorotoscope/stories/machine-road_blue_circuit_5_bw.jpg" align="right" width="45%" style="padding: 15px" /></p>
<p>I was talking to a VC about one of my favorite API upstarts the other day, and one of the closing questions I received was if the API upstart had a secret sauce that made their position defensible. To which I responded, no…but they are API first, and API definition-driven in everything they do, so they will ultimately move faster than any competitor can.</p>

<p>Agility is one of the classic things you hear people tell companies regarding why they should be doing APIs. The benefit is definitely overused and overstated in situations it shouldn’t be, but when APIs are fully embraced, and done properly, the agility is real. I’ve seen companies be able to shift, pivot, and add new features in a fraction of the time of their competitors, allowing them to in new ways that nobody had intended just months before–APIs allow for the type of shape shifting you need to remain competitive in today’s environment.</p>

<p>APIs do not automagically mean a company, institution, organization, or agency will be agile by default. Organizationally, and culturally the entity behind an API needs to be in sync with the API frontline, or agility will never be fully realized. However, when you can dial all this in I’ve seen something that is more potent than any secret sauce or proprietary approach, allowing you to move more confidently and flexibly. I don’t think API agility is a competitive advantage that all companies or investors fully grasp, but once they see in action, I think they’ll realize APIs are more effective than locking something up and keeping it secret.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/26/the-competitive-advantage-of-api-agility-over-any-secret-saurce/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/22/i-would-love-to-reference-github-data-across-repos-with-org-data-object/">I Would Love To Reference Github Data Across Repos With [org].data.[object]</a></h3>
        <span class="post-date">22 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-github-icon.png" align="right" width="30%" style="padding: 15px;" /></p>
<p>I am a big fan of Jekyll and Github when it comes to managing data-driven projects. All of my research runs on Github, and I use Jekyll to serve up YAML and JSON representations of my research for a variety of purposes. I store all data that supports my research in the _data folder for each research project’s repository. From there I will create HTML, Atom, and JSON representations for use in my API Evangelist storytelling.</p>

<p>When I am referencing any YAML data store I have in the _data folder I just use site.data.[object] to reference it. From there I can loop through collections, filter and show fields and other elements on the page using Liquid syntax. I love having all the data at my fingertips, but I’m thinking about the next step of data management at scale, as I work to build more data-driven repositories, housed within Github organizations, I want to be able to reach outside of each repo, into other repos stored within a single organization.</p>

<p>I would love it if Github allowed me to reference my data within an organization using [org].data.[object]. This way I could reference my <a href="http://design.apievangelist.com">API design</a> research within my <a href="http://hypermedia.apievangelist.com">hypermedia API</a> research. I have my API industry research segregated by topic for several reasons. Often it is just a logical separator, but sometimes the research is too big to fit into a single repository, and I’ll shard thing by year, topic, or another logical separator. It would be nice if I could reach across the repository line, into other organizations within an organization, or maybe someday reach out into other organizations as well.</p>

<p>Just some thoughts as I’m working with YAML data at scale across hundreds of Github repositories. I handle this cross-repo access using JavaScript currently but would love it if it was natively built into Jekyll, allowing me to publish in a static way. The amount of Liquid YAML and JSON voodoo I could unleash would be pretty huge if I could reach across all my data drive projects and reference in a structured way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/22/i-would-love-to-reference-github-data-across-repos-with-org-data-object/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/22/api-plans-arent-sustainable-for-my-small-business/">API Plans Are Not Sustainable For My Small Business</a></h3>
        <span class="post-date">22 Jun 2017</span>
        <p><a href="https://imageoptim.com/api/pricing"><img src="https://s3.amazonaws.com/kinlane-productions/imageoptim/imageoptim-api-pricing.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="http://apievangelist.com/2017/05/09/pricing-tiers-works-for-saas-but-not-really-for-apis/">I’ve already written about how I just don’t like class pricing tiers for API consumption</a>, but I want to keep beating this drum until service providers hear what I’m singing. I think pricing tiers worked well to onboard the world with SaaS but for an API-driven world we a lot more flexibility and scalability when it comes to t
he business model.</p>

<p>As a small business I just can’t take another monthly payment, without some deep consideration, and bank account consultation. I’m looking at <a href="https://imageoptim.com/api/pricing">the ImageOptim API</a>, which is already a desktop tool I use, but the opportunity to automate my image optimization is very appealing. However, their entry level pricing tier is $9 a month for $1,000.00 calls. I might be able to add another monthly fee, but it damn well better be generating some value, or directly bringing in some new revenue.</p>

<p>My Amazon bill is always around $350.00, and I just downsized my Dropbox from $75 to $15 a month, and my CloudFlare is up to $75, and on and on. I have a whole list of monthly bills for a variety of services I depend on. The pricing tier based services are almost always the first to go when I have to downsize–Dropbox, gone. However, the ones that let me pay for what I use, tend to actually grow and are sustained. Overall I have about $1K a month to spend on SaaS and API solutions, but increasingly I’m favoring utility-based services over plan-based ones.</p>

<p>I think it is easy for API providers to look at their plans and pricing in a silo, exclusively from their perspective, and by itself the structure makes sense, but when you look at in the context of an entire portfolio of services for a small business, it just doesn’t make a lot of sense when you are using tens or hundreds of services. I know that all you business owners are looking for some stability when it comes to your business revenue, but you know what? So am I…</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/22/api-plans-arent-sustainable-for-my-small-business/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/21/patent-api-matchmaking-using-feature-models/">Patent US9639404: API Matchmaking Using Feature Models</a></h3>
        <span class="post-date">21 Jun 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/uspto.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>Here is another patent in my series of API related patents. I’d file this in the category as the other similar one from IBM–<a href="http://apievangelist.com/2017/06/08/patent-automated-assessment-of-terms-of-service-in-an-api-marketplace/">Patent US 8954988: Automated Assessment of Terms of Service in an API Marketplace</a>. It is a good idea. I just don’t feel it is a good patent idea.</p>

<blockquote>
  <p>Title: API matchmaking using feature models
Number: 09454409
Owner: International Business Machines Corporation
Abstract: Software that uses machine logic based algorithms to help determine and/or prioritize an application programming interface’s (API) desirability to a user based on how closely the API’s terms of service (ToS) meet the users’ ToS preferences. The software performs the following steps: (i) receiving a set of API ToS feature information that includes identifying information for at least one API and respectively associated ToS features for each identified API; (ii) receiving ToS preference information that relates to ToS related preferences for a user; and (iii) evaluating a strength of a match between each respective API identified in the API ToS feature information set and the ToS preference information to yield a match value for each API identified in the API ToS feature information set. The ToS features include at least a first ToS field. At least one API includes multiple, alternative values in its first ToS field.</p>
</blockquote>

<p>Honestly, I don’t have a problem with a company turning something like this into a feature, and even charging for it. I just wish IBM would help us solve the problem of making terms of service machine readable, so something like this is even possible. Could you imagine what would be possible if everybody’s terms of service were machine readable, and could be programmatically evaluated? We’d all be better off, and matchmaking services like this would become a viable service.</p>

<p>I just wish more of the energy I see go into these patent would be spent actually doing things in the API space. Providing low cost, innovative API services that businesses can use, <a href="http://apievangelist.com/2017/06/19/the-six-dimensions-of-api-patents-I-dwell-on/">instead of locking up ideas, filing them away with the government, so that they can be used at a later date in litigation and backdoor dealings</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/21/patent-api-matchmaking-using-feature-models/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/21/validating-api-schema-as-part-of-security-process/">Validating My API Schema As Part of My API Security Practices</a></h3>
        <span class="post-date">21 Jun 2017</span>
        <p><a href="https://arstechnica.com/information-technology/2017/06/psa-commenting-on-fcc-net-neutrality-plan-could-make-your-e-mail-public/"><img src="https://s3.amazonaws.com/kinlane-productions/fcc/fcc-makes-net-neutrality-commenters-email-addresses-public-through-api.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://apievangelist.com/2017/06/20/unknown-unknown-with-api-security/">I am spending more time thinking about the unknown unknowns when it comes to API security</a>. This means thinking beyond the usual suspects when thinking about API security like encryption, API keys, and OAuth. As I monitor the API space I’m keeping an eye out for examples of what might be security concerns that not every API provider is thinking about. [I found one recently in ARS Technica, about the Federal Communication Commission (FCC) leaking the email addresses through the <a href="https://arstechnica.com/information-technology/2017/06/psa-commenting-on-fcc-net-neutrality-plan-could-make-your-e-mail-public/">CC API for anyone who submitted feedback as part of any issues like the recent Net Neutrality discussion</a>.</p>

<p>It sounds like the breach with the <a href="https://www.fcc.gov/ecfs/public-api-docs.html">FCC API</a> was unintentional, but it provides a pretty interesting example of a security risk that could probably be mitigated with some basic API testing and monitoring, using common services like <a href="https://www.runscope.com/">Runscope</a>, or <a href="https://restlet.com/">Restlet Client</a>. Adding a testing and monitoring layer to your API operations helps you look beyond just an API being up or down. You should be validating that each endpoint is returning the intended/expected schema. Just this little step of setting up a more detailed monitor can give you that brief moment to think a little more deeply about your schema–the little things like whether or not you should be sharing the email addresses of thousands, or even millions of users.</p>

<p><a href="https://openreferral.github.io/api-specification/definition/">I’m working on a JSON Schema for my Open Referral Human Services API right now</a>. I want to be able to easily validate any API as human services compliant, but I also want to be able to setup testing and monitoring, as well as security checkups by validating the schema. When it comes to human services data I want to be able to validate every field present, ensuring only what is required gets out via the API. I am validating primarily to ensure an API and the resulting schema is compliant with HSDS/A standards but seeing this breach at the FCC has reminded me that taking the time to validate the schema for our APIs can also contribute to API security–for those attacks that don’t come from outside, but from within.</p>

<p><strong>Disclosure:</strong> <a href="https://restlet.com/">Restlet Client</a> and <a href="https://www.runscope.com/">Runscope</a> are API Evangelist partners.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/21/validating-api-schema-as-part-of-security-process/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/21/making-machine-learning-acessible-to-spreadsheet-power-users/">Making Machine Learning Accessible To Spreadsheet Power Users</a></h3>
        <span class="post-date">21 Jun 2017</span>
        <p><a href="https://blog.algorithmia.com/google-sheets-algorithmia-machine-learning-spreadsheets/"><img src="https://s3.amazonaws.com/kinlane-productions/algorithmia/AlgorithmiaSpreadsheets.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>My friends <a href="https://algorithmia.com">over at Algorithmia</a> are up to some good things–<a href="http://blog.algorithmia.com/google-sheets-algorithmia-machine-learning-spreadsheets/">making their algorithms available within a spreadsheet</a>. Algorithmia has created a set of open source scripts and walkthrough to help you inject the algorithms from their marketplace into your Google Spreadsheets.</p>

<p>They have seven useful algorithms to inject into spreadsheets:</p>

<ul>
  <li><a href="https://algorithmia.com/algorithms/timeseries/LinearDetrend">Linear Detrend</a> – removes increasing or decreasing trends in time series</li>
  <li><a href="https://algorithmia.com/algorithms/timeseries/AutoCorrelate">Autocorrelate</a> – used to analyze the seasonality of a time series</li>
  <li><a href="https://algorithmia.com/algorithms/timeseries/OutlierDetection">Outlier Detection</a> – flags unusual data points</li>
  <li><a href="https://algorithmia.com/algorithms/timeseries/Forecast">Forecast</a> – predict a given time series into the future</li>
  <li><a href="https://algorithmia.com/algorithms/nlp/Summarizer">Summarizer</a> – creates a text summary by extracting key topic sentences</li>
  <li><a href="https://algorithmia.com/algorithms/nlp/SocialSentimentAnalysis">Social Sentiment Analysis</a> – assigns sentiment ratings of “positive”, “negative” and “neutral”</li>
  <li><a href="https://algorithmia.com/algorithms/web/ShareCounts">Count Social Shares</a> – returns the number of times that URL has been shared on various social media sites</li>
</ul>

<p><a href="https://github.com/kenburcham/algorithmia-google">The Google scripts are available on Github</a>, thanks to the hard work of Ken Burcham. It provides yet another interesting example of how a spreadsheet can be used as an API client but it also provides an interesting example of how machine learning API providers can get their ML warez in front of the average business user. Developers building applications with your ML APIs is one thing but getting the average business spreadsheet power user to put your ML API to work in their everyday workflow is a whole other world of API integration opportunity.</p>

<p><a href="http://spreadsheets.apievangelist.com/">I have been preaching the spreadsheet to API connection for a while now</a>. I know that many API developers want to do away with the spreadsheet, but I think they would be better off focusing on injecting their API solutions into spreadsheets like Algorithmia is doing. When you are designing your algorithmic-centric APIs, providing access to your machine learning models, make sure you keep your APIs simple and doing one thing well like Algorithmia does, then your ML APIs can be injected into the spreadsheets around the globe that are driving business each day.</p>


        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/21/making-machine-learning-acessible-to-spreadsheet-power-users/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/i-am-working-with-elastic-beam-to-help-define-api-security/">I Am Working With Elastic Beam To Help Define API Security</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><a href="https://www.elasticbeam.com/"><img src="https://s3.amazonaws.com/kinlane-productions/elastic-beam/elasticbeam-vertical.jpg" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>Security is the number one concern companies, organizations, institutions, and government agencies have when I’m talking with them about doing APIs. Strangely it is also one of the most deficient, and underinvested areas of API operations. Companies are just learning to design, deploy, and manage their APIs, and monitoring, testing, and security are still on the future road map for many API providers I know.</p>

<p>Security is one of the important areas I’ve been trying to find more time and resources to invest into my research, and I’ve been on the hunt for interesting providers to partner with when it comes to defining security as it applies to APIs. There are a number of web and infrastructure security companies out there, but there aren’t enough that are only focused on just APIs. With the number of APIs increasing, we need more eyeballs on the problem, and even more services and tools to stay ahead of the curve.</p>

<p>I finally found a worthwhile partner to help explore API security as part of my regular work as the API Evangelist, a new API security focused startup <a href="https://www.elasticbeam.com/product/#api-behavioral">called Elastic Beam</a>. They are a brand new effort exclusively focused on API security, who are hitting all the buzzworthy areas of the tech space (Artificial Intelligence, Machine Learning, etc), while also doing one thing and doing it well–API security. ElasticBeams core products are:</p>

<ul>
  <li><a href="https://www.elasticbeam.com/product/#api-behavioral">API Behavioral Security</a> - Keeping an eye on the unknown unknowns when it comes to API threats.</li>
  <li><a href="https://www.elasticbeam.com/product/#deep">Deep API Insight</a> - Access insights extracted from data ingested across all Elastic Beam implementations.</li>
  <li><a href="https://www.elasticbeam.com/product/#api-security">API Security Enforcer</a> - Actually blocking and providing a smokescreen for threats against an API.</li>
  <li><a href="https://www.elasticbeam.com/product/#hybrid">Hybrid Cloud API Security</a> - Plugs into existing API service and infrastructure providers.</li>
  <li><a href="https://www.elasticbeam.com/product/#secure">Secure MQTT Proxy</a> - Focused on API security when it comes to the Internet of Things.</li>
</ul>

<p><img src="https://s3.amazonaws.com/kinlane-productions/elastic-beam/infographic-products.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’ve seen Elastic Beam in action, and have a copy to play with as I’m exploring a variety of scenarios in alignment with my API security research. Elastic Beam is going to invest in API Evangelist so I can pay attention to API security more, producing stories, guides, and white papers, and I’m going to help translate what it is they are offering, and help keep them focused on API security, and doing it well.</p>

<p><a href="https://www.elasticbeam.com">Elastic Beam is live</a>. If you want to talk to them about security let me know, or just head over <a href="https://www.elasticbeam.com">to their website</a>. Also, if there are any specific areas of my API security research you’d like me to focus on, let me know. I’ve been having weekly calls with their team and advising them on their release. We’ll see where the relationship goes, but I’m stoked to finally have someone I can partner with to focus on API security. It is an area that needs more research, discussion, as well as storytelling, to help bring awareness to API providers–this stuff takes time, and we need more smart people on the case as soon as possible.</p>

<p>From the time I’ve spent with them, the Elastic Beam team seems to get the problem, and have invested in the right technology. I’m looking forward to working with them to continue to map out the API security space, identify and share information on the most common threats facing API providers. Stay tuned for more about API security, thanks to the Elastic Beam team.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/i-am-working-with-elastic-beam-to-help-define-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/internet-as-example-of-markets-working-things-out/">Internet As Example Of Markets Working Things Out</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p>Is this writing?</p>

<p>Rural Broadband
Mobile</p>

<p>Not worth investing</p>

<p>Left behind</p>

<p>Vote in people who make it worst.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/internet-as-example-of-markets-working-things-out/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/tensor-flow-object-recognition/">API Wrappers To Help Bring Machine Learning Into Focus</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/tensorflow/kites_detections_output.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I was taking a look a<a href="https://github.com/tensorflow/models/tree/master/object_detection">t the Tensorflow Object Detection API</a>, and while I am interested in the object detection, the usage of API is something I find more intriguing. It is yet another example of how diverse APIs can be. This is not a web API, but an API on top of a single dimension of <a href="https://www.tensorflow.org/">the machine learning platform TensorFlow</a>.</p>

<p>“The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models.” It is just a specialized code base helping abstract away the complexity of one aspect of using TensorFlow, specifically for detecting objects in images. You could actually wrap this API with another web API and run on any server or within a single container as a proper object recognition API.</p>

<p>For me, it demonstrates one possible way of wrapping a single or cross section of a machine learning implementation to abstract away the complexity and helping you train and deploy ML models in this particular area. This approach to deploying an API on top of ML shows that you can use to APIs to help simplify and abstract ML for developers. This can be done to help satisfy business, regulatory, privacy, security, and other real or perceived concerns when it comes to artificial intelligence, machine learning, or any other digital voodoo that resembles magic.</p>

<p>No matter how complex the inputs and outputs of an algorithm are, you can always craft an API wrapper, or series of API wrappers that help others make sense of those inputs, from a technical, business, or even political perspective. I just wanted to highlight this example of ML being wrapped with an API, even if it isn’t for all the same reasons that I would be doing it. It’s just part of a larger toolbox I’m looking to create to help me make the argument for <a href="http://apievangelist.com/2016/08/04/pushing-for-more-algorithmic-transparency-using-apis/">more algorithmic transparency in the machine learning platforms</a> we are developing.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/tensor-flow-object-recognition/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/tight-coupling-to-our-mobile-phones/">Tightly Coupled To Our Mobile Phones</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-mobile-apps.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>I had ditched my phone last year after being with AT&amp;T for just shy of 20 years. Not having a phone made me realize how much you need a phone number to exist online these days. Facebook, Twitter, Google, all needed me to have a phone number which I can verify from time to time, to keep my accounts active.</p>

<p>In addition to just needing it for an account, I also need it regularly to secure my world via two-factor authentication. Sometimes I need it for SMS, but mostly I just need the authenticator app–both requiring at least having the mobile device in my presence. I’m not very tightly coupled with my phone, but it feels like it increasingly like it is always coupled to me.</p>

<p>I’m guessing that if it isn’t our mobile phones, in the future there will always be at least one device we will be required to have as part of our identity, and be helping us secure both our physical and digital worlds. It isn’t something I enjoy but like pretty everyone else, it is not a cord I am going to be able to cut anytime soon.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/tight-coupling-to-our-mobile-phones/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/unknown-unknown-with-api-security/">The Unknown Unknowns Of API Security</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><a href="http://security.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-security-unknown.png" align="right" width="25%" style="padding: 15px;" /></a></p>
<p>I am trying to wrap my head around the next steps in the evolution of <a href="http://security.apievangelist.com/">API security</a>. I am trying to help separate some of the layers of what we collectively call API security, into some specific building blocks I can reference in my storytelling. I’m ramping up my API security research as I onboard a new API service provider partner, and will have more resources to invest in the API security discussion.</p>

<p>Let’s start with the easy “Known Knowns”:</p>

<ul>
  <li>Encryption - Using encryption across all aspects of API operations from portal to base URL.</li>
  <li>API Keys - Making sure everyone who is accessing an API is keying up and passing along with each request.</li>
  <li>OAuth - Getting more granular with access by applying OAuth when there is access to 3rd party data and content.</li>
  <li>Rate Limiting - Limiting how much of a resource any single API consumer can access using rate limiting.</li>
</ul>

<p>These are the first things that come to mind when the topic of API security is brought up. I’d say most conversation begin with encryption, but as someone progresses on their API journey they begin to understand how they can key things up, using OAuth, rate limiting, and other aspects of API management to secure their API operations.</p>

<p>Next, I want to think about some the “Known Unknowns”, things like:</p>

<ul>
  <li>Freeloaders - People with multiple accounts, and generally aren’t healthy consumers.</li>
  <li>Errors - Errors, misconfigured, and malformed requests, responses, and anything that generally gums up the gears of operations.</li>
  <li>Vulnerabilities - Making sure all known software and hardware vulnerabilities are patched and communicated as part of operations.</li>
  <li>Attacks - Defending against the known attacks, staying in tune with OWASP and other groups who are actively identifying, studying, and sharing attacks.</li>
</ul>

<p>These are the things we might not totally understand or have implemented, but they are known(ish). With the right amount of resources and expertise, any API team should be able to mitigate against these areas of security. There is always a lot of work to turn the unknowns into knowns in this area, but they are doable.</p>

<p>Now I want to think a little about the “Unknown Unknowns”, likes like:</p>

<ul>
  <li>DNS - What is happening at the DNS level as it pertains to my API security?</li>
  <li>Relationship - Relationship between requests, even if they are using different keys, IP addresses, and other elements–where is the overlap?</li>
  <li>Threats - What information is available to me regarding new and emerging threats that I’m only beginning to see, or maybe my partners and others in same space are seeing?</li>
  <li>Sharing - Are there opportunities to share information and see a bigger picture when it comes to vulnerabilities and threats?</li>
</ul>

<p>These are just a handful of my initial thoughts on what the unknown unknowns might be. Things that are currently off the radar of my known API security practices. API management seems to dominate and in some cases terminate the API security conversation, but I have the feeling there are numerous other considerations out there that we are not seeing. I’m just looking to begin defining this new bucket of security considerations so I can keep adding items to it as I’m doing my research.</p>

<p>From your perspective, what are the biggest threats out there for API security that many API providers are completely unaware of? I’m looking to keep expanding on this frontline of API security and turn up the heat beneath <a href="http://security.apievangelist.com">my research</a> while I have the resources to do so. I feel like the API security conversation has kind of stagnated after the last wave of API management growth, leaving many providers thinking they have everything covered.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/unknown-unknown-with-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/the-general-services-administration-api-strategy-considers-how-to-generate-revenue/">The General Services Administration API Strategy Considers How To Generate Revenue</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/gsa/gsa-api-strategy-diagram.png" align="right" width="40%" style="padding: 15px;" /></p>
<p><a href="https://tech.gsa.gov/assets/downloads/GSAAPIStrategy.pdf">The General Services Administration(GSA) has an API strategy</a>, which describes “GSA’s future direction for agency­wide API management including design, development, architecture, operations, and support, and security.” Ok, let’s pause there. I want to point out that this isn’t just an API design guide. That is a portion of it, but it also touches on some of the most obvious (deployment), and the most critical aspects (security) of API operation–important stuff.</p>

<p>The objectives for the GSA crafting an API strategy are:</p>

<p>­* Harness API management to maximize customer value and technical efficiencies.
­* Adopt industry best practices with API design, development, and management.
­* Consider opportunities for revenue through API offerings.</p>

<p>I always enjoy seeing federal agencies talk about efficiencies and best practices, but it gives me hope that all of this might actually work when I see federal agencies actually “considering opportunities for revenue through API offerings”. Especially at the GSA, who provides technical guidance to the other 400+ federal agencies, as well as at the state and municipal level. I am not excited about our government charging money for digital resources, I am excited about our government exploring how it will generate revenue to sustain itself in the future.</p>

<p>I know there are a lot of open data advocates who can’t wrap their mind around this, but this is how the government will generate needed tax revenue to operate in the future–using APIs. Our government currently generates a portion of its revenue from the sale of physical resources like timber, mining, and agriculture, why should things be different when it comes to taxing and regulating digital resources being made available via the web, mobile, and device applications. While there is still lots to figure out on this front, I am glad to see the GSA putting some thought into the role APIs will play in the future of funding the government services we all depend on each day.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/the-general-services-administration-api-strategy-considers-how-to-generate-revenue/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/20/idks-are-always-first-step-in-api-integration/">IDK Is Always The First Step To API Integration</a></h3>
        <span class="post-date">20 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-shared.png" align="right" width="35%" style="padding: 15px;" /></p>

<p>I spend a lot of time trying to figure out what technology does. I read press releases, pitch emails, documentation, and marketing materials trying to get an idea of what is possible. While many of the APIs I come across are intuitive, and just make sense there is still a significant portion of them that leave me scratching my head regarding what it even does.</p>

<p>As developers, it can be easy to think about the SDKs you will need to support API integration with your API, but I think you are making a lot of assumptions about your consumers when you focus your initial energy here. The first step in any API integration begins with IDK and not the SDK. When a potential API consumer comes across your API, the first question to be answered is: what does this API do? If the answer is I Don’t Know (IDK), we have a problem. A problem no amount of SDKs will solve, no matter how many languages you create them in.</p>

<p>Every API begins with an IDK. What does the Twilio API do? What does the Stripe API do? The answer to this initial question for your API cannot be IDK! As soon as I read your press release, land on the home page of your developer area, I should know what your API does in 5 seconds or less. If I walk away from our first interaction with an IDK, the chances I’ll be coming back are pretty slim. Make sure you always address the IDK, before you get to work on your SDK, for your API(s).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/20/idks-are-always-first-step-in-api-integration/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/the-six-dimensions-of-api-patents-I-dwell-on/">The Six Dimensions Of API Patents I Dwell On</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/supreme-court-statues.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>Each story I publish about API patents will usually get a comment, Tweet, LinkedIn, or other comments letting me know that the owner of the patent is only doing it in a defensive pattern. I fully grasp that this is the predominant stance when it comes to defending a patent portfolio, but I prefer seeing six dimensions to this discussion–looking beyond this single position.</p>

<p>When thinking about why a patent exists I see it in six dimensions:</p>

<ul>
  <li><strong>Idea</strong> - That someone has an idea, thinks it is theirs and feels that this should exist as a patent.</li>
  <li><strong>Patent</strong>- That some have the resources to craft the patent application, and file it with the patent office.</li>
  <li><strong>Filing</strong> - That the patent authority thinks an idea is patent-worthy, and something that should be approved.</li>
  <li><strong>Litigation</strong> - When someone wields a patent as part of litigation, either in an offensive, or defensive stance.</li>
  <li><strong>Public Deals</strong> - When patent shows up as part of an acquisition, partnership, and wielded publicly as part of some deal.</li>
  <li><strong>Backroom Deals</strong> - When patents are leveraged as part of backroom deals when negotiating with companies and investors, and sizing up the value on the table.</li>
</ul>

<p>We only have insight into the middle four dimensions. We really don’t have any view into the individual reasons behind a patent, and we do not get access to how they are wielded and leveraged behind closed doors. I think that defending yourself as part of any court case makes sense, but I’m discussing API patents to help shine a light and understand what is happening within the other dimensions.</p>

<p>Overall I find that the existence of patents to speak volumes about a company’s motivations. The way they showcase or do not showcase their API portfolio contributes to this conversation in important ways. Sadly we will never get a full picture of the individual and backroom aspects of how API patents are used. However, I’m confident I can extract enough meaning from the existence of a patent, the information within the application, and any litigation that has occurred to paint a pretty clear picture of the motivations behind having a patent on your API(s).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/the-six-dimensions-of-api-patents-I-dwell-on/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/three-rules-of-my-api-communication-strategy/">Three Rules Of My API Communication Strategy</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><a href="http://communications.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/three-rules-for-a-communication-strategy.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>Communicating effectively around API operations is the number one illness I see across the API space. Engineers are good at writing code and devopping their way to a usable API, but often fall short when it comes to telling the story of what the API does, and consistently beating this drum until people become familiar with what is going on.</p>

<p>An effective API communication strategy is more art than it is science, and I’d like to share three of my rules when it comes to telling stories on the API Evangelist platform.</p>

<ul>
  <li><strong>Honesty</strong> - Be honest with yourself, you’re readers, and those you are writing about. If you can’t find a way to be honest in your writing go find a new job–it won’t be sustainable.</li>
  <li><strong>Consistent</strong> - Communicate every day. Ok, maybe every other day. Regardless of frequency, make sure you are communicating on a consistent basis, setting the tone for what your audience can expect.</li>
  <li><strong>Compelling</strong> - Make it compelling. No, not every single post will be compelling, but make it your primary goal to tell a compelling story that you would read yourself, if it was on someone else’s blog.</li>
</ul>

<p>That is it. Don’t sweat all the technical details. Just write on the blog, spend the time on Twitter, participate in threads on Github, and regularly dive into the bowels of the Slack. Don’t spend all your time worrying about your communication strategy, just make sure you give it a sensible amount of time, and follow these three rules–the rest will come.</p>

<p>As of this moment, there are 2,680 blog posts on API Evangelist, with the first entry in September 2010. These three rules have kept me on track when I was taking money from bigcos like Intel and Mulesoft, and kept me from losing my shit when I was traveling and drinking too heavily. These three rules are what keep me doing this effectively after seven years.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/three-rules-of-my-api-communication-strategy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/i-would-like-to-see-more-api-test-drives/">I Would Like To See More API Test Drives</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><a href="https://azure.microsoft.com/en-us/blog/azure-marketplace-test-drive/?v=17.23h"><img src="https://s3.amazonaws.com/kinlane-productions/c627d90c-1615-4750-b45c-9658b45596bc.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://azure.microsoft.com/en-us/blog/azure-marketplace-test-drive/?v=17.23h">The Azure Marketplace has the ability to test drive anything that is deployed in the Azure Marketplace</a>. As someone who has to sign up for an endless number of new accounts to be able to play with APIs and API services, I’m a big fan of the concept of a test drive–not just for web applications, or backend infrastructure, but specifically for individual APIs and microservices.</p>

<p>From the Azure site:  <em>Test Drives are ready to go environments that allow you to experience a product for free without needing an Azure subscription. An additional benefit with a Test Drive is that it is pre-provisioned - you don’t have to download, set up or configure the product and can instead spend your time on evaluating the user experience, key features, and benefits of the product.</em></p>

<p>I like it. I want more of these. I want to be able to test drive, then deploy any API I want. I don’t want to sign up for an account, enter my credit card details, talk to sales, or signup for 30 day trial–I want to test drive. I want it to have data in it, and be pre-configured for a variety of use cases. Helping me understand what is possible.</p>

<p>I want all the friction between me finding an API (discovery via marketplace) understanding what an API does, test driving, then deployment of the API in any cloud I want. I think we are still a little bit off from this being as frictionless as I envision in my head, but I hope with enough nudging we will get there very soon.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/i-would-like-to-see-more-api-test-drives/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/unknown-unknown-with-api-security/">The Unknown Unknowns Of API Security</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><a href="http://security.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-security-unknown.png" align="right" width="25%" style="padding: 15px;" /></a></p>
<p>I am trying to wrap my head around the next steps in the evolution of <a href="http://security.apievangelist.com/">API security</a>. I am trying to help separate some of the layers of what we collectively call API security, into some specific building blocks I can reference in my storytelling. I’m ramping up my API security research as I onboard a new API service provider partner, and will have more resources to invest in the API security discussion.</p>

<p>Let’s start with the easy “Known Knowns”:</p>

<ul>
  <li>Encryption - Using encryption across all aspects of API operations from portal to base URL.</li>
  <li>API Keys - Making sure everyone who is accessing an API is keying up and passing along with each request.</li>
  <li>OAuth - Getting more granular with access by applying OAuth when there is access to 3rd party data and content.</li>
  <li>Rate Limiting - Limiting how much of a resource any single API consumer can access using rate limiting.</li>
</ul>

<p>These are the first things that come to mind when the topic of API security is brought up. I’d say most conversation begin with encryption, but as someone progresses on their API journey they begin to understand how they can key things up, using OAuth, rate limiting, and other aspects of API management to secure their API operations.</p>

<p>Next, I want to think about some the “Known Unknowns”, things like:</p>

<ul>
  <li>Freeloaders - People with multiple accounts, and generally aren’t healthy consumers.</li>
  <li>Errors - Errors, misconfigured, and malformed requests, responses, and anything that generally gums up the gears of operations.</li>
  <li>Vulnerabilities - Making sure all known software and hardware vulnerabilities are patched and communicated as part of operations.</li>
  <li>Attacks - Defending against the known attacks, staying in tune with OWASP and other groups who are actively identifying, studying, and sharing attacks.</li>
</ul>

<p>These are the things we might not totally understand or have implemented, but they are known(ish). With the right amount of resources and expertise, any API team should be able to mitigate against these areas of security. There is always a lot of work to turn the unknowns into knowns in this area, but they are doable.</p>

<p>Now I want to think a little about the “Unknown Unknowns”, likes like:</p>

<ul>
  <li>DNS - What is happening at the DNS level as it pertains to my API security?</li>
  <li>Relationship - Relationship between requests, even if they are using different keys, IP addresses, and other elements–where is the overlap?</li>
  <li>Threats - What information is available to me regarding new and emerging threats that I’m only beginning to see, or maybe my partners and others in same space are seeing?</li>
  <li>Sharing - Are there opportunities to share information and see a bigger picture when it comes to vulnerabilities and threats?</li>
</ul>

<p>These are just a handful of my initial thoughts on what the unknown unknowns might be. Things that are currently off the radar of my known API security practices. API management seems to dominate and in some cases terminate the API security conversation, but I have the feeling there are numerous other considerations out there that we are not seeing. I’m just looking to begin defining this new bucket of security considerations so I can keep adding items to it as I’m doing my research.</p>

<p>From your perspective, what are the biggest threats out there for API security that many API providers are completely unaware of? I’m looking to keep expanding on this frontline of API security and turn up the heat beneath <a href="http://security.apievangelist.com">my research</a> while I have the resources to do so. I feel like the API security conversation has kind of stagnated after the last wave of API management growth, leaving many providers thinking they have everything covered.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/unknown-unknown-with-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/19/idks-are-always-first-step-in-api-integration/">IDK Is Always The First Step To API Integration</a></h3>
        <span class="post-date">19 Jun 2017</span>
        <p><img src="­https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-mark.png" align="right" width="20%" style="padding: 15px;" /></p>
<p>I spend a lot of time trying to figure out what technology does. I read press releases, pitch emails, documentation, and marketing materials trying to get an idea of what is possible. While many of the APIs I come across are intuitive, and just make sense there is still a significant portion of them that leave me scratching my head regarding what it even does.</p>

<p>As developers, it can be easy to think about the SDKs you will need to support API integration with your API, but I think you are making a lot of assumptions about your consumers when you focus your initial energy here. The first step in any API integration begins with IDK and not the SDK. When a potential API consumer comes across your API, the first question to be answered is: what does this API do? If the answer is I Don’t Know (IDK), we have a problem. A problem no amount of SDKs will solve, no matter how many languages you create them in.</p>

<p>Every API begins with an IDK. What does the Twilio API do? What does the Stripe API do? The answer to this initial question for your API cannot be IDK! As soon as I read your press release, land on the home page of your developer area, I should know what your API does in 5 seconds or less. If I walk away from our first interaction with an IDK, the chances I’ll be coming back are pretty slim. Make sure you always address the IDK, before you get to work on your SDK, for your API(s).</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/19/idks-are-always-first-step-in-api-integration/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/data-access-and-api-strategy-in-the-european-union/">Data Access and API Strategy in the European Union</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p>http://dret.typepad.com/dretblog/2017/06/data-access-and-api-strategy-in-the-european-union.html</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/data-access-and-api-strategy-in-the-european-union/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/making-your-api-available-in-marketplaces/">Publishing Your API In The AWS Marketplace</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/box/box-platform-cloud-content-management-apis-aws-marketplace.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’ve been watching the conversation around how APIs are discovered since 2010 and I ave been working to understand where things might be going beyond ProgrammableWeb, to the Mashape Marketplace, and even investing in my own <a href="http://apisjson.org">API discovery format APIs.json</a>. It is a layer of the API space that feels very bipolar to me, with highs and lows, and a lot of meh in the middle. I do not claim to have “the solution” when it comes to API discovery and prefer just watching what is happening, and contributing where I can.</p>

<p>A number interesting signals for API deployment, as well as API discovery,  are coming out of Amazon Marketplace lately. I find myself keeping a closer eye on <a href="https://aws.amazon.com/marketplace/search/results?searchTerms=API&amp;page=1&amp;ref_=nav_search_box">the almost 350 API related solutions in the marketplace</a>, and today <a href="https://aws.amazon.com/marketplace/pp/B06XY1XHGV/?ref=_ptnr_awsblg">I’m specifically taking notice of the Box API availability in the AWS Marketplace</a>. I find this marketplace approach to not just API discovery via an API marketplace, but also API deployment very interesting. AWS isn’t just a marketplace of APIs, where you find what you need and integrate directly with that provider. It is where you find your API(s) and then spin up an instance within your AWS infrastructure that facilitates that API integration–a significant shift.</p>

<p>I’m interested in the coupling between API providers and AWS. AWS and Box have entered into a partnership, but their approach provides a possible blueprint for how this approach to API integration and deployment can scale. How tightly coupled each API provider chooses to be, looser (proxy calling the API), or tighter (deploying API as AMI), will vary from implementation to implementation, but the model is there. The Box AWS Marketplace instance dependencies on the Box platform aren’t evident to me, but I’m sure they can easily be quantified, and something I can get other API providers to make sure and articulate when publishing their API solutions to AWS Marketplace.</p>

<p><a href="http://apievangelist.com/2014/01/30/what-will-it-take-to-sell-my-api-as-a-wholesale-resource/">AWS is moving towards earlier visions I’ve had of selling wholesale editions of an API</a>, helping you <a href="http://apievangelist.com/2017/04/25/your-wholesale-api-for-sale-in-the-major-api-marketplaces/">manage the on-premise and private label API contracts for your platform</a>, and <a href="http://apievangelist.com/2017/01/03/exploring-the-economics-of-wholesale-and-retail-algorithmic-apis/">helping you explore the economics of providing wholesale editions of your platforms</a>, either tightly or loosely coupled with AWS infrastructure. Decompiling your API platform into small deployable units of value that can be deployed within a customer’s existing AWS infrastructure, seamlessly integrating with existing AWS services.</p>

<p><a href="https://developer.box.com/page/box-platform-and-aws">I like where Box is going with their AWS partnership</a>. I like how it is pushing forward the API conversation when it comes to using AWS infrastructure, and specifically the marketplace. I’ll keep an eye on where things are going. Box seems to be making all the right moves lately <a href="http://apievangelist.com/2017/05/22/box-goes-all-in-on-openapi/">by going all in on the OpenAPI Spec</a>, and decompiling their API platform making it deployable and manageable from the cloud, <a href="http://apievangelist.com/2017/06/16/serverless-blueprints-for-your-api/">but also much more modular and usable in a serverless way</a>. Providing us all with one possible blueprint for how we handle the technology and business of our API operations in the clouds.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/making-your-api-available-in-marketplaces/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/serverless-blueprints-for-your-api/">Serverless Blueprints For Your API</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/amazon/lambda_find_box_blue_1.png" width="40%" align="right" style="padding: 15px" /></p>
<p><a href="http://serverless.apievangelist.com/">Serverless</a> is spreading across the API sector, and is something that leading API providers are beginning to embrace as part of their operations. I saw an interesting example of this out of AWS and Box lately, with <a href="https://aws.amazon.com/blogs/aws/box-platform-on-aws-marketplace-lambda-blueprints-sample-code/">the announcement of Lambda blueprints and code for integrating with the Box API via the AWS platform</a>.</p>

<p>The Box serverless blueprints show you how to call the Box APIs and connect a Box webhook to a Lambda function via the Amazon API Gateway–providing some pretty interesting use cases for using Box via serverless functions:</p>

<ul>
  <li><a href="https://medium.com/box-developer-blog/manage-user-authentication-with-box-platform-using-amazon-cognito-8828b5f1d1c9">Manage User Authentication with Box Platform using Amazon Cognito</a> – How to use Amazon Cognito to power a login page for application users.</li>
  <li><a href="https://medium.com/box-developer-blog/add-deep-learning-based-image-recognition-to-your-box-app-with-amazon-rekognition-1878ab148b70">Add Deep Learning-based Image Recognition to your Box App with Amazon Rekognition</a> – How to build an image tagging application that is powered by Amazon Rekognition.</li>
</ul>

<p>They are some pretty basic use cases, but it is the approach that opens up an entirely new door for API integration for me–Serverless Development Kits (SDK). Every API providers should have a whole catalog of open source serverless scripts that are deployable to Lambda, and other serverless platforms. <a href="http://apievangelist.com/2016/09/12/where-is-the-deploy-to-aws-and-google-button/">Of course, there are one-click buttons deploy each individual script to the cloud platform of your choice</a>.</p>

<p>I’m diving into the other side of this story for me, where Box is embracing a tighter coupling with the AWS platform as part of their operations. <a href="https://aws.amazon.com/marketplace/pp/B06XY1XHGV/?ref=_ptnr_awsblg">I am looking at how Box is providing a copy of the Box API for deployment on AWS</a>. This all reflects how I see things working in the future, where you can deploy individual API integration scripts, as well as deploy APIs to a serverless environment like this–empowering anyone to become both API consumer and provider via the AWS, or any other cloud ecosystem.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/serverless-blueprints-for-your-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/16/github-helping-set-the-bar-for-your-api-community-code-standards/">Github Helping Set The Bar For Your API Community Code Standards</a></h3>
        <span class="post-date">16 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/github/github-community-standards.png" align="right" width="40%" style="padding: 15px;" /></p>
<p><a href="https://github.com/blog/2380-new-community-tools">Github has released an interesting new feature to help users better manage some of the community elements of the repositories they use to manage code, definitions, data, and content across API operations</a>. For each repository, you now have a community profile tab, where you’ll see a checklist showing how your project compares to Github recommended community standards.</p>

<p>If you are lacking one of these common elements, it gives you an option to quickly add one of the missing pieces. I still have some repositories where I don’t properly have licensing dictated, even a handful without a README (I know). Almost none of my repositories have a code of conduct or contributing agreement. The new feature adds another task to my list of maintenance items I’ll be tackling to help standardize the projects I manage on Github (which is everything I do).</p>

<p>I like where Github is going with this. <a href="http://portal.minimum.apievangelist.com/">It resembles what I am trying to do with API projects by identifying the common building blocks of API deployments, providing a checklist that API providers can follow when publishing their APIs–which is often done using Github</a>. One way that API providers can help standardize these common elements across groups is to create a working API portal prototype that is forkable on Github, <a href="https://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/">similar to what the GSA is doing for the federal government with their working API prototype</a>.</p>

<p>Most of the time API architects and eveloper just need a friendly reminder, or possibly a working example they can follow when it comes to standardizing how we deploy and manage the community elements of our API operations. I hope what Github is doing with their community standards baseline will keep evolving, spreading, and eventually be something that Github organizations can templatize, standardize, and define their own criteria regarding the minimum viable aspects of community operations for the repositories they have on Github.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/16/github-helping-set-the-bar-for-your-api-community-code-standards/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/15/zooming-out-to-the-100k-level-then-back-to-api-sea-level-with-openapi-and-apis-dot-json/">Zooming Out To The 100K Level Then Back To API Sea Level With OpenAPI And APIs.json</a></h3>
        <span class="post-date">15 Jun 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/drone_control_sunset.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I’m wrestling with the different levels of conversations I’m having around <a href="https://openreferral.github.io/api-specification/definition/">my human services API work</a>. Some of my audience are more technical and are pushing for discussion at the granular level, while other parts of my audience are more about the business of things at the 100K. I appreciate these types of projects, but when there are many different conversations going on at many different levels, it is a lot of work to wrestle things into something coherent that everyone involved will appreciate.</p>

<p>One day I’m thinking about which individual fields are required, then next I will considering how multiple human services API integrators will be syndicating and sharing information between clusters of human service API implementations. While I’m relying on Github, and Slack to facilitate conversations that going on, I am ultimately relying on <a href="https://www.openapis.org/">OpenAPI</a> and <a href="http://apisjson.org">APIs.json</a> to help me hammer out the contract that will speak to the developers at the granular level but can also communicate the business and political terms of the API contract.  It will describe which fields are required as well as describe the webhooks I need to define how to syndicate and share between implementations.</p>

<p>OpenAPI is pretty focused on helping me with things happening at API sea level, but I’m exploring using APIs.json to help me organize conversations all the way up to the 100K foot level. Things like, where do I signup for my API keys, access partnership levels of access, find the terms of service, or possibly someone to contact and answer a question. Then using the OpenAPI I can publish documentation for developers to understand the surface area of the API (sea level), and while the APIs.json includes a pointer to this discussion, it also provides pointers to other discussions going on around support, communications, changes, privacy, security, so that I can generate documentation for business and partner stakeholders as well.</p>

<p>I’m working on an example of doing this for <a href="https://openreferral.github.io/api-specification/definition/">my Open Referral Human Services API</a>. An APIs.json + OpenAPI that helps articulate what is happening with any single human services API implementation from sea level to 100K. The trick is I also need to articulate how this will work at scale across clusters of human services API implementations, allowing vendors and partners to syndicate and federate. With everything defined as a machine readable index (using APIs.json and OpenAPI), which can be used to generate very technical API documentation, as well as more business-friendly aspects of operations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/15/zooming-out-to-the-100k-level-then-back-to-api-sea-level-with-openapi-and-apis-dot-json/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/15/a-community-approval-dimension-when-adding-updating-and-deleting-via-api/">A Community Approval Dimension When Adding, Updating, And Deleting Via API</a></h3>
        <span class="post-date">15 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-community-join.png" align="right" width="30%" style="padding: 15px;" /></p>
<p>One of the projects I’m working on as part my <a href="https://openreferral.github.io/api-specification/definition/">Human Services API</a> work is trying to define the layer that allows developers to add, update, and delete data via the API. We ultimately want to empower 3rd party developers, and external stakeholders to help curate and maintain critical human services data within a community, through trusted partners.</p>

<p>The Human Services API allows for the reading and writing of organizations, locations, and services for any given area. I am looking to provide guidance on how API implementors can allow for POST, PUT, PATCH, and DELETE on their API, but require approval before any changing transaction is actually executed. Requiring the approval of an internal system administrator to ultimately give the thumbs up or thumbs down regarding whether or not the change will actually occur.</p>

<p>A process which immediately begs for the ability to have multiple administrators or even possibly involving external actors. How can we allow organizations to have a vote in approving changes to their data? How can multiple data stewards be notified of a change, and given the ability to approve or disprove, logging every step along the way? Allowing any change to be approved, reviewed, audited, and even rolled back. Making public data management a community affair, with observability and transparency built in by default.</p>

<p>I am doing research into different approaches to tackling this, ranging from community approaches like Wikipedia, to publish and subscribe, and other events or webhook models. I am looking for technological solutions to opening up approval to the API request and response structure, with accompanying API and webhook surface area for managing all aspects of the approval of any API changes. If you know of any interesting solutions to this problem I’d love to hear more, so that I can include in my research, future storytelling, and ultimately the specification for <a href="https://openreferral.org/">the Open Referral Human Services Data Specification and API</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/15/a-community-approval-dimension-when-adding-updating-and-deleting-via-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/15/my-api-communication-stack-for-the-human-services-api-specification/">My API Communication Stack For The Human Services API Specification</a></h3>
        <span class="post-date">15 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/open-referral/human-services-data-specification-draft-snapshot.png" align="right" width="40%" style="padding: 15px" /></p>
<p>I’m refining my approach to moving forward the discussion around <a href="https://openreferral.github.io/api-specification/definition/">the Human Services Data Specification and API</a> in an attempt to include more vendors and implementors in the conversation. Part of this work is to streamline how we move forward an increasing number of conversations regarding the schema and API definition.</p>

<p>I am looking help solidify our communication strategy around the human services API, and help make clear which channels participants can tune into:</p>

<ul>
  <li><strong>Github</strong> - Github Issues is where the specific conversation around a variety</li>
  <li><strong>Slack</strong> - A variety of Slack channels for discussing the evolution of API.</li>
  <li><strong>Blog</strong> - Storytelling via API Evangelist, and specific project level blogs.</li>
  <li><strong>GHangouts</strong> - Virtual gatherings to discuss the API via video conferencing.</li>
</ul>

<p>These are the channels where the HSDS/A conversations are occurring. It is spread unevenly across these synchronous and asynchronous digital channels. We are using a variety of signals including Github issues, Slack messaging as well as video conference calls, blog posts, and semi-regular virtual gatherings.</p>

<p>I am heavily using the blog post to organize my ideas, distilling down the explosion of information, ideas, and technical details in smaller, coherent, bite-size chunks. This helps me organize and better communicate what’s going on, which includes having a single URL to share with new players. In fact, this blog post is part of me pulling together my communication around the API communications strategy for the human services API project and will be the most current URL I share with people.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/15/my-api-communication-stack-for-the-human-services-api-specification/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/">The GSA API Standards With A Working Prototype API And Portal</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/"><img src="https://s3.amazonaws.com/kinlane-productions/gsa/gsa-prototype-api-portal.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>One way to help API developers understand API design is to provide them with a design guide, helping set a standard for how APIs should be designed across an organization or group. Another way to help developers follow best practices when it comes to API design is to provide them with a working example they can follow when developing their API(s). In my experience people learn API design best practices through following what they know–emulating what they see.</p>

<p>Hang on to that thought, cause now I’m going to blow your mind. Guess how API providers learn how to provide API design guide and working examples? By showcasing working examples of companies, institutions, and government agencies publishing API design guides, working APIs, and portal prototypes. So that other API providers can learn by example! BOOM! Mind blown. :-) An example of this can be found over at the General Service Administration (GSA), <a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/">with their API standards guide, API prototype, and forkable API portal and documentation</a>–complete with the essential API building blocks.</p>

<p>The GSA’s simple approach to providing a working example of their <a href="https://github.com/GSA/prototype-city-pairs-api/blob/master/standards.md">API standards</a> is refreshing. They have taken an existing GSA data set and launched a prototype API, then they published the API in a complete, working <a href="https://github.com/GSA/api-documentation-template">API developer portal</a> with all the essential building blocks of a basic API presence.</p>

<ul>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/getting_started.html">Getting Started</a> - What you need to get started with the API.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/console/">Documentation</a> - OpenAPI driven interactive API documentation.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/fields.html">Schema</a> - A reference of the fields / schema used for API responses.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/FAQ.html">FAQ</a> - Some basic questions about the API, and more importantly the API prototype.</li>
  <li><a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/contact_us.html">Contact Info</a> - Using Github issues for support, with an accompanying email.</li>
</ul>

<p><a href="https://github.com/GSA/prototype-city-pairs-api-documentation">The whole things runs on Github so it is forkable</a>. What is great, is that they also have <a href="https://github.com/GSA/prototype-city-pairs-api">the source code for the API on Github</a>, essentially providing a working, forkable representation of what is expected in the GSA API design guide. This is how you plant seeds for consistent API design across an organization. An API design guide setting standard, with a working example of what you would like to see as the finished product.</p>

<p>I’m really getting into this approach to defining the API conversation within an organization. <a href="http://drone.prototype.apievangelist.com/">I’m working with a handful of large organizations right now to develop API prototypes</a>, evolve <a href="http://portal.minimum.apievangelist.com/">my current API portal definition</a>, as well as working to influence the GSA’s approach. If you aren’t familiar with the <a href="https://www.gsa.gov">General Services Administration (GSA)</a>, a significant portion of their mission is dedicated to delivering technology services to the over 430 departments, agencies, and sub-agencies in the federal government. The GSA API design guide, prototype, and portal provide a working example other agencies can follow when defining, designing, deploying, and managing their API presence–important stuff.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/gsa-api-standards-with-working-prototype-api-and-portal/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/the-yes-i-would-like-to-talk-button-signing-up-for-api-platform/">The Yes I Would Like To Talk Button When Signing Up For An API Platform</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><a href="https://www.reprezen.com/"><img src="https://s3.amazonaws.com/kinlane-productions/reprezen/the-yes-id-like-to-talk-button.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>There are never enough hours in the day. I have an ever growing queue of APIs and API related services that I need to play with for the first time, or just make sure and take another look at. I was FINALLY making time to take another look at the <a href="https://www.reprezen.com/">RepreZen API Studio</a> again when I saw that they were now supporting OpenAPI 3.0.</p>

<p>I am still driving it around the block, but I thought the second email I got from them when I was signing up was worth writing about. I had received a pretty standard getting started email from them, but then I got a second email from Miles Daffin, their product manager, reminding me that I can reach out, and providing me with a “Yes I Would Like To Talk Button”. I know, another pretty obvious thing, but you’d be surprised how a little thing like this can actually break us from our regular isolated workspace, and make the people behind an API, or API related service more accessible. The email was pretty concise and simple, but what caught my eye when I scanned was the button.</p>

<p>Anyways, just a small potential building block for your API communication strategy. I’ll be adding the list I am cultivating. I’m not a big hard sell kind of guy, and I appreciate soft outreach like this–leaving it up to me when I want to connect. I’ll keep playing with RepreZen API Studio and report back when I have anything worth sharing. I just wanted to make sure this type of signup email was included in my API communication research.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/the-yes-i-would-like-to-talk-button-signing-up-for-api-platform/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/the-successes-and-mostly-failures-of-a-developer-evangelist/">The Successes And (Mostly) Failures Of A Developer Evangelist</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><a href="https://www.getrevue.co/profile/ashleyintexas"><img src="https://s3.amazonaws.com/kinlane-productions/stitch-data/the-evangelism-compendium.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I am a big fan of companies who share their API journey publicly. The comment I hear from readers, as well as attendees of @APIStrat often, is that they want to hear more honest stories from API practitioners regarding every stop along the API lifecycle from defining to deprecation. I encourage API providers to actively share their stories publicly on their blog, and even semi-privately via email newsletters.</p>

<p>Ash Hathaway (<a href="https://twitter.com/ash_hathaway">@ash_hathaway</a>) over at <a href="https://www.stitchdata.com/">Stich Data</a> asked me what I thought about her doing an evangelism email newsletter based on her experiences–to which I responded with, “hell yeah, it is a great idea!”. So she has launched <a href="https://www.getrevue.co/profile/ashleyintexas">The Evangelism Compendium, the successes and (mostly) failures of a developer evangelist email newsletter</a>. She will be sharing her regular thoughts from the trenches, as she is evangelizing for <a href="https://www.stitchdata.com/">the data integration platform</a>.</p>

<p>Sharing stories from the API trenches like this is a great way to generate content for your operations, while also working through your thoughts on what is working (or not), when it comes to evangelism and outreach for your platform. I think the email newsletter has two audiences 1) data stewards looking to learn more about managing your data in today’s online cloud environment, and 2) other data and API service providers who are looking to learn, and hopefully share thoughts on evangelizing your platform. Many folks think I’m crazy for encouraging this type of real-time transparency into your operations, something that can make some feel vulnerability and exposed, but I find it to the best way to generate honest and compelling content.</p>

<p>API Evangelist is the result of me doing this for the last seven years. Sharing my thoughts as I do my work. I find it is a helpful part of my regular workflow to tell stories in this way, as it helps me refine and articulate my approach. It also generates valuable SEO and SMM exhaust for my platform, while also hopefully helping educate others along the way–even stimulating conversation. I encourage all API providers, and service providers to <a href="https://www.getrevue.co/profile/ashleyintexas">tune into what Ash is doing over at Stitch Data</a>, and make sure you are telling your story via your blog and/or email newsletter–no matter which stops along the API lifecycle you are looking share with the community.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/the-successes-and-mostly-failures-of-a-developer-evangelist/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/14/proprietary-views-of-your-taxonomy/">Proprietary Views Of Your Taxonomy</a></h3>
        <span class="post-date">14 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-taxonomy.png" align="right" width="25%" style="padding: 15px" /></p>
<p>I’ve been investing a lot more energy into open data and APIs involved with city government, something I’ve dabbled in as long as I’ve been doing API Evangelist, but is something I’ve ratcheted up pretty significantly over the last couple of years. As part of this work, I’ve increasingly come across some pretty proprietary stances when it comes to data that is part of city operations–<a href="http://apievangelist.com/2011/09/06/every-city-county-and-state-should-have-an-api/">this stuff has been seen as gold, long before Silicon Valley came along, with long lines of folks looking to lock it up and control it</a>.</p>

<p><a href="http://apievangelist.com/2017/04/24/separating-the-licensing-layers-of-your-valuable-data-using-apis/">Helping civic data stakeholders separate the licensing layers around their open data and APIs is something I do as the API Evangelist</a>. Another layer I will be adding to this discussion is around taxonomy. How city data folks are categorizing, organizing, and classifying the valuable data needed to make our cities work. I’ve been coming across more vendors in the city open data world who feel their taxonomy is their secret sauce and falls under intellectual property protection. I don’t have any wisdom regarding why this is a bad idea, but I will keep writing about as part of my wider <a href="http://licensing.apievangelist.com/">API licensing</a> work to help flesh out my ideas, and create a more coherent and precise argument.</p>

<p>I understand that some companies put a lot of work into taxonomies, and the description behind how they organize things, but like API definitions and schema, these are aspects of your open data and API operations you want to be a widely understood, shared, and reusable knowledge within your systems, as well as the 3rd party integration of your partners and customers. Making your taxonomy proprietary isn’t going to help your brand, or get you ahead in the game. I recommend focusing on other aspects of the value you bring to the table and keep your taxonomy as openly licensed as you possibly can, encouraging adoption by others. I’ll work on a more robust argument as I work through a variety of projects that will potentially be hurt by the proprietary views on taxonomy I’m seeing.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/14/proprietary-views-of-your-taxonomy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/13/weekly-roundups-vs-short-stories/">Weekly Roundups vs Short Stories</a></h3>
        <span class="post-date">13 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-versus.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>I process a lot of stories each week, which I do not think is at all unique. While I tend to read short, medium, and longer form pieces, I notice that people tend to tune into my shorter, more concise pieces. I’m an aggregator, analyst, so people probably are looking to me to understand what is going on and in turn I’m looking for individual API providers and service providers to help me keep in tune with what is going on with their operations–I depend on blog posts, change logs, and other common building blocks to do my work.</p>

<p>One recommendation I have for API providers and service providers when it comes to their communication strategies is to provide short concise blog posts regarding specific goings on. Make your blog posts like your API resources–doing one thing and doing it well. You can still do a round-up at the end of the week providing an executive summary, but don’t cut out the short individual blog posts. In my experience, people tend to read titles, tweets, and don’t have much attention span beyond 300 to 500 words. Personally, if I am busy, the first thing I cut out each week is the lengthy weekly roundups from providers–I will scan, but really do not read much of the detail if something catches my eyes.</p>

<p>This advice isn’t for other aggregators and analysts. Your job is to round up and provide and overview of what is going on. My advice is for individual API providers looking to update everyone with what is going on with their API operations, services, tooling, customers, and other common things you should be evangelizing and communicating as part of your regular operations. This is just some feedback from someone who is passionate about consuming as much information as I possibly can each week. Many short stories are better than just a single round-up, and you tend to get better search and social media bang for your buck when you have well-crafted titles, and a short body, that focuses on a single topic. Think of your API communication strategy similar to your microservices approach and I think you’ll get the reach you are looking for.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/13/weekly-roundups-vs-short-stories/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/13/setting-the-rules-for-api-automation/">Setting The Rules For API Automation</a></h3>
        <span class="post-date">13 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/twitter/twitter-automation-rules.png" align="right" width="40%" style="pading: 15px;" /></p>
<p>Twitter released some automation rules this spring, laying the ground rules when it comes to building bots using the Twitter API. Some of the rules overlap with their existing terms of service, but it provides an interesting evolution in how platform providers need to be providing some direction for API consumers in a bot-driven conversational landscape.</p>

<p>They begin by laying the ground rules for automation using the Twitter API:</p>

<p>Do!</p>

<ul>
  <li>Build solutions that automatically broadcast helpful information in Tweets</li>
  <li>Run creative campaigns that auto-reply to users who engage with your content</li>
  <li>Build solutions that automatically respond to users in Direct Messages</li>
  <li>Try new things that help people (and comply with our rules)</li>
  <li>Make sure your application provides a good user experience and performs well — and confirm that remains the case over time</li>
</ul>

<p>Don’t!</p>

<ul>
  <li>Violate these or other policies. Be extra mindful of our rules about abuse and user privacy!</li>
  <li>Abuse the Twitter API or attempt to circumvent rate limits</li>
  <li>Spam or bother users, or otherwise send them unsolicited messages</li>
</ul>

<p>Twitter is just evolving their operation by providing an automation update to the <a href="https://support.twitter.com/articles/18311">Twitter rules</a> and the <a href="https://dev.twitter.com/overview/terms/agreement-and-policy">developer agreement and policy</a>, outlining what is expected of automated activity when it comes to engaging with users account, when bots are tweeting, direct messages, and other actions you take when it comes to Tweets or Twitter accounts. Providing an interesting look at the shift in API platform terms of service as the definition of what is an application continues to evolve.</p>

<p>While there were may automated aspects to the classic interpretation of web or mobile applications, bots are definitely bringing an entirely new meaning to what automation can bring to a platform. I think any API driven platform that is opening up their resources to automation is going to have to run down their list of available resources and think deeply about the positive and negative consequences of automation in the current landscape. Whether it is bots, voice, iPaaS, CI, CD, or any other type of API driven automation, the business, and politics of API operations are shifting rapidly, and the threats, risks, and stakes are only going to get higher.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/13/setting-the-rules-for-api-automation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/13/i-wish-usa-facts-had-embeddable-and-sharing-strategy/">I Wish USA Facts Had A More Sophisticated API Embeddable And Sharing Strategy</a></h3>
        <span class="post-date">13 Jun 2017</span>
        <p><a href="https://usafacts.org/"><img src="https://s3.amazonaws.com/kinlane-productions/usa-facts/usa-facts-federal-business-spending.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I love what the folks over at <a href="https://usafacts.org/">USAFacts</a> have done with their effort to educate everyone regarding how the US works (or doesn’t). I commend Steve Ballmer for the money he’s put into the project and the obviously huge amount of work they have put into making some pretty complex things understandable. However, I just have one critique: I wish they had an API, accompanied with a more sophisticated sharing and embeddable approach to publishing the wealth of valuable information contained within the site.</p>

<p>You can share links to specific sections of USAFacts, but it is just a generic image with a link to each area of the site. The site is exactly what we need in a Trump era, and is full of valuable factoids about how things work, but we need more eye candy for sharing, and the ability to share more granular level details about what is contained within the project. Journalists should be able to craft stories around finance and population via a graph, chart, or other detail that links back to the site. In the current state, you have to be pretty motivated and truly care about this stuff to visit the site and get involved–this represents a pretty light portion of the US population (maybe we could get a chart ;-).</p>

<p>All it would take to accomplish this is a pretty simple JSON API with some <a href="https://d3js.org/">D3.js</a> or other <a href="http://visualization.apievangelist.com/">API visualization</a> magic. With an API, data-savvy journalists, and other 3rd party developers could help carry the load when it comes to developing storytelling tooling that could help USAFacts make a bigger impact. Think about the impact that Facebook and Twitter cards had on the election when it came to sharing news (or fake news) with the public–we need USAFacts to be richly embedded in everyone’s timeline, with meaningful storytelling behind when a user is looking to know more. The facts have to be portable, shareable, visual, and tell a story–this is something an API excels at being an engine for.</p>

<p>I understand that USAFacts is just getting started, and maybe they are working on, but without any sort of road map, I have no way of knowing. If the folks behind the important project want to ensure the site lives on beyond the last wave of press releases they need to invest heavily in an API, as well as an embeddable and social sharing strategy that will help spread the valuable facts across the web where they need to be.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/13/i-wish-usa-facts-had-embeddable-and-sharing-strategy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/13/more-evangelism-and-less-sales-is-needed-to-move-forward-banking-api-conversation/">More Evangelism Will Be Needed To Move Banking API Conversation Forward</a></h3>
        <span class="post-date">13 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/kin-lane/api-evangelist-speaking.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I was reading <a href="https://www.cujournal.com/news/whats-behind-the-hold-up-of-api-adoption-at-credit-unions">what’s behind the hold up of API adoption at credit unions</a> and I’m reminded (again) of the critical need for API evangelists in the space. I am not talking about advocates for a single API, but more evangelists that reflect my mission as the API Evangelist, but dialed in for specific industries.</p>

<p>To set the stage for you, let me share why I started API Evangelist seven years ago. I began writing about the business, and eventually the politics of APIs because I saw the potential with APIs, but I also saw that things were not evolving as fast as they could because technologists were dominating the API conversation. We needed more discussion around the business of doing APIs, and many of the finer political details like security, terms of service, branding, and other concerns of the business leaders who actually controlled the purse strings that would move the space forward at the speed and scale everyone desired.</p>

<p>To help break the log jam within the federal government, healthcare, and other industries someone needed to help assure business and technical stakeholders of the benefits of doing APIs, with sensible discussion regarding how they could mitigate the risk involved. The problem in the banking space is that you only have the vendors and hype pundits dominating the conversation, and much-needed trust is never established. Banks are extremely risk adverse because of money, but also because of regulations, and when you have just technologist, vendors, and hype analysts stirring the pot, nobody ever really helps alleviate bank’s actual concerns around security, privacy, and other areas that keep them up at night.</p>

<p>I remember sitting down at a table in Vegas with Anthem, Kaiser Permanente, and other health insurance providers who were all about business when I sat down, but after an hour or so I convinced them they weren’t in my sales pipeline, and the tone changed completely. They are so used to be sold to and pushed vendor solutions to their problems, they were just seeing APIs as the next vendor product. I help show them I didn’t have a product to sell, and genuinely wanted to help them understand the API potential, and break down the security, business, and other concerns they faced as major players in the space. I have seen this play out over and over, across many different industries over the last seven years, and is something that the waves of enterprise sales teams, vendors, and analysts never fully grasp is actually gumming up the gears of their progress–a bi-product being so narrowly focused.</p>

<p>For the last five years, I have been trying to groom up evangelists who could tackle specific industries like finance, healthcare, education, and others, but it is really, really difficult to patch together a consistent paycheck to keep anyone engaged. Plus, it seems to take a certain type of obsessive-compulsive personality to stay dedicated to what is going on. If folks are really interested in clearing some of the gunk that is slowing the progress in the banking and credit union API space, you all should get together and establish some sort of vendor-neutral group to help fund and provide a platform for financial sector API evangelist(s) to work independently with banks to help alleviate their concerns, and help showcase the positive motion forward when it comes to banking APIs–otherwise things are going to continue to sputter and jerk forward at an uncomfortable pace.</p>

<p>P.S. The evangelists have to actually give a shit about what is going on and be personally invested, otherwise it won’t be sustainable.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/13/more-evangelism-and-less-sales-is-needed-to-move-forward-banking-api-conversation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/12/revisiting-graphql-as-part-of-my-api-toolbox/">Revisiting GraphQL As Part Of My API Toolbox</a></h3>
        <span class="post-date">12 Jun 2017</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-tools-school.png" alt="" width="40%" align="right" /></p>

<p>I’ve been reading and curating information on GraphQL as part of my regular research and monitoring of the API space for some time now. As part of this work, I wanted to take a moment and <a href="http://apievangelist.com/2016/09/02/i-am-keeping-my-mind-open-and-looking-forward-to-learning-more-about-graphql/">revisit my earlier thoughts about GraphQL</a>, and see where I currently stand. Honestly, not much has changed for me, to move me in one direction or another regarding the popular approach to providing API access to data and content resources.</p>

<p><a href="http://apievangelist.com/2017/03/31/rest-linked-data-hypermedia-graphql-and-grpc/">I still stand by my cautionary advice for GraphQL evangelist regarding not taking such an adversarial stance when it comes to the API approach, and I feel that GraphQL is a good addition to any API architect looking to have a robust and diverse API toolbox</a>. Even with the regular drumbeat from GraphQL evangelists, and significant adoption like the Github GraphQL API I am not convinced it is the solution for all APIs and is a replacement for simple RESTful web API design.</p>

<p>My current position is that the loudest advocates for GraphQL aren’t looking at the holistic benefits of REST, and too wrapped in ideology, which is setting them up for similar challenges that linked data, hypermedia, and even early RESTafarian practitioners have faced. I think GraphQL excels when you have a well educated, known and savvy audience, who are focused on developed web and mobile applications–especially the latest breed of single page applications (SPA). I feel like in this environment GraphQL is going to rock it, and help API providers reduce friction for their consumers.</p>

<p>This is why I’m offering advice to GraphQL evangelists to turn down the anti-REST, and complete replacement/alternative for REST–it ain’t helping your cause and will backfire for you. You are better to off educating folks about the positive, and being honest about the negatives. I will keep studying GraphQL, understanding the impact it is making, and keeping an eye on important implementations. However, when it comes to writing about GraphQL you are going to see me continuing to hold back, just like I did when it came to hypermedia and linked data because I prefer not to be in the middle of ideological battles in the API space. I prefer showcasing the useful tools and approaches that are making a significant impact across a diverse range of API providers–not just echoing what is coming out of a handful of big providers, amplified by vendors and growth hackers looking for conversions.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/12/revisiting-graphql-as-part-of-my-api-toolbox/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/12/recent-api-paths/">Recent API Paths</a></h3>
        <span class="post-date">12 Jun 2017</span>
        <p><a href="https://developer.box.com/v2.0/reference#recent-item-object"><img src="https://s3.amazonaws.com/kinlane-productions/box/box-recent-item-object.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I was learning about <a href="https://developer.box.com/v2.0/reference#recent-item-object">a new API path for the document platform Box, that was designed specifically for showing recently updated objects</a>. I think that the concept of having API paths dedicated to showing recently changed elements makes sense, helping eliminate the need for API consumers to learn about which parameters are needed to achieve their immediate goals, helping expose useful aspects of the platform through API design.</p>

<p>As an API consumer, it can be a lot of work to get at the meaningful and relevant context of an API Platform if you do not know all the right knobs and levers to pull on. This is where API design comes in handy, helping surface the most relevant and contextual aspects of what is going on. While this may not be the approach all API providers should be taking, especially if you have a savvy API consumer audience, in times when you have a wider, more unknown audience who may be looking to just get at what is going on with their users platform integrations, this type of API design can be a good way to reduce friction.</p>

<p>I am writing about the concept of recent API paths, to think about how this can be added to my <a href="http://design.apievangelist.com">API design toolbox</a>. While not a REST, hypermedia (wait maybe) design pattern, I think that in some scenarios, having a recent API path makes a lot of sense. Some platforms are only relevant for a specific time period, and the rest of what is happening can be dealt with through search, taxonomy, and other ways of archiving. Once I write about an API design pattern I come across it kinds of activates it in my brain and makes it something I will be thinking about as I review other APIs, as well as design my own APIs, and who knows, maybe it will do the same for you!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/12/recent-api-paths/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/12/tweeting-out-api-forum-conversations/">Tweeting Out Your API Forum Conversations</a></h3>
        <span class="post-date">12 Jun 2017</span>
        <p><a href="https://twitter.com/OxfordWordsAPI/status/872375851580624899"><img src="https://s3.amazonaws.com/kinlane-productions/oxford-dictionaries/oxford-dictionaries-support-forum-tweet.png" align="right" width="35%" style="padding: 15px;" /></a></p>
<p>It is a lot of work to keep the API evangelism drumbeat going each day on your blog, Twitter, and other social media channels you use for your API operations. Each Tweet, Facebook or LinkedIn Post is one possible signal that might reach existing developers, or possibly reach a potentially new API consumer–educating them about what your API does.</p>

<p>My friends over at the Oxford Dictionaries APIs are getting really good at this API evangelism song and dance, and <a href="https://twitter.com/OxfordWordsAPI/status/872375851580624899">one of the tactics in their toolbox is regularly Tweeting out relevant threads from their API forum</a>. It is a great way to expose conversations that are going on within your API support forum, and help make other developers aware that these conversations are going on in a way that will also boost your overall SEO, making your API support operations more visible to the public.</p>

<p>Another benefit of sending out these regular API signals is that there is always the potential that I will write up what you are doing, and you’ll get the additional exposure of being on API Evangelist. When people ask me what is the #1 thing they can do to be more successful with evangelism for their API, it is always consistency. Regular, consistent drumbeats about what is going on with your platform, the problems it solves is always the best way to make sure your valuable API resources will be found and put to use in meaningful ways.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/12/tweeting-out-api-forum-conversations/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/12/if-oracle-wants-to-be-taken-seriously-with-apis-it-needs-to-drop-api-copyright-case/">If Oracle Wants To Be Taken Seriously With Its API Campaign It Needs To Drop API Copyright Case</a></h3>
        <span class="post-date">12 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/oracle/the-oracle-in-the-matrix.jpg" align="right" width="35%" style="padding: 15px;" />&lt;,/p&gt;Oracle is investing a serious amount resources to become a contender in the API space lately. [They've acquired Apiary](http://apievangelist.com/2017/01/19/oracle-acquiring-apiary/), and are beating a regular PR drum regarding API design, deployment, management, and everything API. The tech giant shows up on my API monitoring daily with new waves of messaging about how it is the platform of choice when it comes to APIs. The problem is these are always from meaningless outlets who publish every press release they get, not the sources the community looks to for answers.

The company is facing an uphill battle because it is extremely late to the game, but also because of it's ongoing API copyright lawsuit against Google. I know from their vantage point they think they can just change their tune when it comes to marketing and PR, and many enterprise zombies will gladly follow along. They also can flex their financial resources and the venture capital behind startups like Apiary will also fall in line, but when it comes to gaining significant mindshare amongst the core API community, they will never be taken seriously until they drop their lawsuit, and make a public announcement demonstrating their commitment to the community.

I'll get the regular wave of haters for this post asking who I think I am. I'm nobody. It's true. Although I must be a micro blip on the radar because Oracle's API team had reached out to me. I asked them if they knew who I was, and had read my work? They said they had, but I think they really hadn't because after a while they stopped responding to me emails regarding their request for a sit-down. I get it. I'm nobody at the Oracle scale, but I am listened to in the API community, which is a different software community than the enterprise world. I'm under no delusions that the enterprise community gives a shit about what I have to say, but many in the API community do, and I'm not backing down when it comes to fighting to keep the API space open and interoperable--even if I end up losing. I'm not in this game to win.

I'm not sure strategically what value Oracle is getting out of their fight with Google. I am sure that they are completely oblivious to the damage the court case has done to their brand. I am also quite sure that Oracle DOES NOT understand API, despite what their current marketing barrage might say. They do not understand the interoperability, reuse, remix, and innovation that APIs afford when done right. I'm sure they seem them as yet another tech trend train they need to ride and need to pay lip service to. I'm sure they have enough cash to throw into the wind on this, but the cost of continuing to sue Google, and throw endless money into marketing and advertising has to be pretty huge.

I know Oracle thinks it is invincible in the face of the API economy, but I'm sure other bigcos from previous generations of the software world thought the same as well. There are elements at play when it comes to APIs that are hard for bigcos like Oracle to fully grasp, and think they can just throw their weight around to get what they want. No matter how many resources they throw at it, Oracle will never be taken seriously by the core API community until it backtracks from the Oracle v Google API copyright case. They damn sure will never appear in a positive light on a blog post or Tweet from @apievangelist until they publicly apologize for the damage they've done--bwahahahaa, but who the hell am I right?
</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/12/if-oracle-wants-to-be-taken-seriously-with-apis-it-needs-to-drop-api-copyright-case/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/09/i-like-apicurios-road-map/">I Like The Apicurio Road Map</a></h3>
        <span class="post-date">09 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/apicurio/apicurio-road-map.png" align="right" width="40%" style="padding: 15px" /></p>
<p>I have been learning more about Apicurio, <a href="http://apievangelist.com/2017/05/30/apicurio-is-the-open-source-api-editor-i-was-looking-for/">which is the open source API design editor I have been waiting for</a>. There are a number of things I’m interested in when it comes to Apicurio, but <a href="http://www.apicur.io/roadmap/">one side element that caught my attention was their road map</a>.</p>

<p>I am a big fan of encouraging folks to share their roadmap. It is an important part of helping establish a shared future between API provider and API consumer. Apicurio is an API tool, without any APIs (yet), but the roadmap purpose remains the same. I like how Apicurio shares their tech preview, beta, and 1.x plan, in a coherent and organized way–you do not have to be a developer to understand what they are planning.</p>

<p>As I was using Apicurio I had a lot of questions about what it didn’t do. I had a lot of ideas about what it should do, and before I set out writing these ideas on my blog I spent some time with their road map, syncing items on my list with items on their roadmap. After I was done, I had reduced my list of questions and ideas to just a handful of items–which I will write about shortly. Their proactive, coherent, and complete road map saved me time, but also will save them time when it comes to listening to my feedback (if they do).</p>

<p>Complete, coherent, and plain English road maps are another one of those super simple, captain obvious ideas that over 50% of the APIs I review DO NOT HAVE. Which is why I’m writing about it and showcasing a positive example like <a href="http://www.apicur.io/">Apicurio</a>. Please do not forget to share road map with your community–it will save us both time.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/09/i-like-apicurios-road-map/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/09/trade-dot-gov/">The APIs.json For Trade.gov</a></h3>
        <span class="post-date">09 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/trade-gov/deverlop_trade_logo_tall.png" align="right" width="35%" style="padding: 15px;" /></p>
<p>There are a growing number of API providers who have published <a href="http://apisjson.org">an APIs.jso</a>n for their API operations, providing a machine-readable index of not just their API, but for their API entire operations. My favorite example to use in my talks and conversations when I’m showcasing the API discovery format is the one for <a href="http://developer.trade.gov/">the International Trade Administration at developer.trade.gov</a>.</p>

<p><a href="http://trade.gov/">The International Trade Administration (ITA)</a> is the government agency that “strengthens the competitiveness of U.S. industry, promotes trade and investment, and ensures fair trade through the rigorous enforcement of our trade laws and agreements”, provides an index of where you can find their developer portal, documentation, terms of service, as well as a machine readable OpenAPI for their trade APIs.</p>

<p>I couldn’t think of a more shining example of APIs when it comes to talking about the API economy. I am pleased to have helped influenced their API efforts and helping them see the importance of providing a machine readable index of their API operations with APIs.json, as well as their APIs using OpenAPI. <a href="http://developer.trade.gov/apis.json">If you need a well maintained, and meaningful example of how APIs.json works head over to developer.trade.gov and take a look</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/09/trade-dot-gov/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/08/temporary-interaction-limits/">Temporary Interaction Limits</a></h3>
        <span class="post-date">08 Jun 2017</span>
        <p><a href="https://github.com/blog/2370-temporary-interaction-limits"><img src="https://s3.amazonaws.com/kinlane-productions/github/769c0c3c-34af-11e7-9b76-96396c81f051.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I spend a lot of time thinking about API rate limits. How they can hurt API providers, or as my friend Tyler Singletary (<a href="https://twitter.com/harmophone">@harmophone</a>) says incentivize creativity. I think your view on rate limits will vary depending on which side of the limit you stand, as well as your own creative potential and limitations. I agree with Tyler that they can incentivize creativity, but it doesn’t mean that all limitations imposed will ultimately be good, or all creativity will be good.</p>

<p><a href="https://github.com/blog/2370-temporary-interaction-limits">I found myself contemplating Github’s recent introduction of temporary interaction limits which means “maintainers can temporarily limit who can comment, create pull requests, and open issues among existing users, collaborators, and prior contributors.”</a> While this isn’t directly about API rate limiting, it does overlap, and provide us with some thoughts we can apply to our world of API consumption, and how we sensibly moderate the access to the digital resources we are making available online.</p>

<p>When it comes to real-time fetishism around the digital world those with the loudest bullhorn often get heard and think real-time is good, while <a href="http://kinlane.com/2016/09/01/real-time-is-often-more-about-what-they-desire-than-what-we-want/">I am becoming less convinced that anything gets done in a 24-hour time frame</a>. Despite what many want you to believe, <a href="http://kinlane.com/2016/08/23/fine-tuning-my-real-time-for-maximum-efficiency/">real-time does not always mean good</a>. Sometimes it might do you some good to chill out for 24 hours before you continue commenting, posting, or increase your consumption of a digital resource, whether you want to admit it or not.</p>

<p>Our digital overlords have convinced us that more is better and real time is always ideal. Temporary interaction limits may not be the right answer in all situations, but it does give us another example of rate limiting by a major provider that we can consider and follow when it comes to crafting limitations around our digital resources. This is what rate limitations are all about for me, thoughtful consideration about how much of a good thing you will need each second, minute, day, week, or month. It is a great way to turn a quality digital resource into something better or possibly maintain the quality and value of a seemingly infinite resource by imposing just a handful of limitations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/08/temporary-interaction-limits/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/08/kdl-a-graphical-notation-for-kubernetes-api-objects/">KDL: A Graphical Notation for Kubernetes API Objects</a></h3>
        <span class="post-date">08 Jun 2017</span>
        <p><a href="https://blog.openshift.com/kdl-notation-kubernetes-app-deploy/"><img src="https://s3.amazonaws.com/kinlane-productions/openshift/kubernetes-kdl-deploy-image19-24.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="https://blog.openshift.com/kdl-notation-kubernetes-app-deploy/">I am learning about the Kubernetes Deployment Language (KDL) today</a>, trying to understand their approach to defining their notion of Kubernetes API objects. It feels like an interesting evolution in how we define our infrastructure, and begin standardizing the API layer for it so that we can orchestrate as we need.</p>

<p>They are standardizing the Kubernetes API objects into the following buckets:</p>

<p>Cluster - The orchestration level of things.
Compute - The individual compute level.
Networking - The networking layer of it all.
Storage - Storage behind our APIs.</p>

<p>This has elements of <a href="http://dev.apievangelist.com/api-lifecycle/">my API lifecycle research</a>, as well as a containerized, clustered, BaaS 2.0 in my view. Standardizing how we define and describe the essential layers of our API and application infrastructure. I could also see standardizing the testing, monitoring, performance, security, and other critical aspects of doing this at scale.</p>

<p>I’m also fascinated at how fast YAML has become the default orchestration template language for folks in the cloud containerization space. I’ll add KDL to my <a href="http://definitions.apievangelist.com">API definition</a> and <a href="http://containers.apievangelist.com">container research</a> and keep an eye on what they are up to, and keep an eye out for other approaches to standardizing the API layer for deploying, managing, and scaling our increasingly containerized API infrastructure.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/08/kdl-a-graphical-notation-for-kubernetes-api-objects/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/08/patents-as-a-measure-of-individual-success/">Patents As A Measure Of Individual Success</a></h3>
        <span class="post-date">08 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/raven-fence.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I read a lot of patents as part of my work as the API Evangelist, and I tend to stalk and tune into the social media accounts of some of the authors. I have noticed that some of them work at large companies, and are counting each patent they file and are announcing each one like it is a badge of honor. I’m fascinated by this. Each company’s approach to showcasing or downplaying their patent portfolio tells a lot about the company, something that I feel trickles down to each individual author.</p>

<p>The theater of showcasing the number of patents is fascinating to me. I’m not saying it’s a bad thing, just something I think is worthy of more discussion in the modern age. I don’t showcase the number of patents I have filed because 1) I don’t have any patents 2) I cannot afford to file any patents 3) I don’t showcase my ideas, I showcase things I do and the stories I tell. Ok, maybe a patent is a story right? A story about what is possible, that you’ve paid a fee to file with the government, and convinced them that the story is true? I’m just trying to get at the thinking behind this theater production, and why some folks feel that it is a badge of honor.</p>

<p>The biggest differentiator here for me is that I cannot afford to file patents. It is a rich man’s game. Is this why people showcase? To declare they are part of the elite?
 Even if I could afford to file one patent, I definitely cannot afford to file many patents, and I cannot ever afford to litigate and defend a patent in a court of law. Making patents completely useless to me, even if I wanted to legally define my stories and ideas like this. Another thing that I notice is that there are no individuals filing patents, it is always an individual filing on behalf of a large company who has the money to file, and to litigate on behalf of the patent portfolio, which for me diminishes the individual merit of showcasing–look ma, I got a new patent (for my company)!!</p>

<p>A patent feels like one of those carrots that get dangled in front of individuals to get them to perform while on the hamster wheel. You get told in high school and college by your mentors that the number of patents you have is a badge of honor. However, you never get told that it is your organization that owns the portfolio, and made aware of the closed door dealings or litigation that will occur around your patent portfolio. IDK, it could be that I’m naive and uneducated about the wider world of patents, and how revenue is generated from patent portfolios–it won’t be the first time I’ve spouted off about something I don’t get, nor will it be the last. I write to understand.</p>

<p>Ultimately I think patents are a rich person game, and how a significant amount of ideas are locked up and made part of larger flows of power, or rendered a non-threat. It isn’t a game I’m part of because I don’t operate at that level, which is why it is foreign to me. I’ve never heard someone tell me that they respect someone for their patent portfolio, or that they were an author on a patent. I think patents are one of those legacy stories that used to have meaning and purpose in the industrial world, and long ago became the game of rich folks, while also becoming pretty distorted in the translation from the physical to the digital. It is a game people still showcase as a badge of honor because of mythical stories they have heard those in power tell–they have little to do with your own success or the value of your ideas.</p>

<p>For me, I measure my success based on the stories I tell about my ideas, and the stories others retell about my ideas. I also measure my success based upon the number of my ideas that become real, and are part of everyday practice in an industry, even if I do not receive royalty checks, or able to litigate and make deals based upon my idea portfolio…but, this is just me. I’m an oddball like that.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/08/patents-as-a-measure-of-individual-success/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/08/the-support-elements-of-your-api-service-level-agreement/">The Support Elements Of Your API Service Level Agreement</a></h3>
        <span class="post-date">08 Jun 2017</span>
        <p><a href="https://www.zendesk.com/blog/keeping-word-support-sla/"><img src="https://s3.amazonaws.com/kinlane-productions/zendesk/keeping-your-word-the-support-sla.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>Zendesk gave me some valuable building blocks to add to both my <a href="http://support.apievangelist.com/">API support</a> and API service level agreement research, with <a href="https://www.zendesk.com/blog/keeping-word-support-sla/">their support SLA</a>. This is why I keep an eye on not just how API providers are handling their support, but also how leading support software as a service API providers are setting the bar for how we do support.</p>

<p>The <a href="https://www.zendesk.com/blog/keeping-word-support-sla/">Zendesk support SLA</a> provides us with some valuable information about setting a service level objective, developing support SLA workflow, dealing with a breach, and even some key performance indicators (KPIs) to help you measure success. I will be taking the bullet points from each area and adding to the overlap of my API support and service level research, and I’ll even begin flushing out my API breach research with its first handful of building blocks regarding how to handle a really bad situation.</p>

<p><a href="http://apievangelist.com/2017/04/14/gearing-up-for-enterprise-sales-with-an-api-service-level-agreement/">I’m seeing an uptick in the number of SLAs with leading API providers</a>, so it makes sense to start considering how other aspects of API operations should be reflected in our API service level agreements. How you support and communicate with your customers can be just as important as the technical bullets of your SLA. Most of the SLAs I’ve read in the API space focus on the technical, business, and legal considerations of integration, but Zendesk reminds us of the actual human elements of setting and meeting a specific level of service when it comes to API integration.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/08/the-support-elements-of-your-api-service-level-agreement/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/08/patent-automated-assessment-of-terms-of-service-in-an-api-marketplace/">Patent US 8954988: Automated Assessment of Terms of Service in an API Marketplace</a></h3>
        <span class="post-date">08 Jun 2017</span>
        <p><a href="http://terms-of-service.apievangelist.com/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-terms-conditions.png" align="right" width="25%" style="padding: 15px;" /></a></p>
<p>I’m reading a lot of <a href="http://patents.apievangelist.com/">API patents</a> lately trying to understand the variety of approaches these “innovative” patent authors are using to help define the API space. Many of the API patents I have historically objected to tend to patent the technical detail that make the web work or significantly contributes to the integration benefits that an API delivers. Today’s patent does all of this but is focused on patenting the legal details that are needed to make this whole API thing work at scale.</p>

<p>Title: <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=/netahtml/PTO/search-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN/8954988">Automated assessment of terms of service in an API marketplace</a>
Number: 08954988
Owner: International Business Machines Corporation
Abstract: An embodiment of the invention comprising a method is associated with an API marketplace, wherein one or more API providers can each supply an API of a specified type, and each provider has a set of ToS for its API of the specified type. The method includes, responsive to an API consumer having a need for an API of the specified type, obtaining the ToS of each of the API providers. The method further includes implementing an automated process to determine differences between the ToS of a given API provider, and a ToS required by the API consumer. The ToS differences determined for respective API providers are used to decide whether to select a particular one of the API providers to supply an API of the specified type to the API consumer.</p>

<p>Don’t get me wrong. I think this is an innovative idea. I just don’t think it is something that should be patented. It should be an open standard, with a wealth of open (and proprietary) tooling developed to enable it to be a reality. If you are patenting the thing we need to make the legal partnership details in API marketplace, and ideally on the open web across API implementations more streamlined, you are just slowing meaningful API adoption and integration–it isn’t something you are going to get rich doing.</p>

<p>Imagine if every technical, business and legal detail of the web was patented early on–it wouldn’t exist as it does today. We do need an automated way to assess the terms of service that govern API consumption. We need this now, but we need it to be an open standard that anyone can implement as part of any API marketplace or single API implementation. This is similar to what we are trying to accomplish with <a href="http://apicommons.org/">API Commons</a>, trying to make the licensing portion of platform operations machine readable and digestible at integration, as well as at runtime.</p>

<p>I just wish the innovation and resources that went into this patent had gone into an open standard for helping define terms of services so that there could be any innovation when it comes to automating the assessment of API terms of service. It feels like this patent author is just counting on the fact that the API space will eventually mature and reach a point where automating the assessment of terms of service is possible, and then cash in on the fact that they hold a patent on this valuable aspect of the API economy.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/08/patent-automated-assessment-of-terms-of-service-in-an-api-marketplace/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/07/apis-for-monitoring-the-performance-of-your-apis/">APIs For Monitoring The Performance Of Your APIs</a></h3>
        <span class="post-date">07 Jun 2017</span>
        <p><a href="https://blog.runscope.com/posts/monitoring-api-performance-new-api-metrics-endpoint"><img src="https://s3.amazonaws.com/kinlane-productions/runscope/1-dashboard-test-performance.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p><a href="http://apievangelist.com/2015/12/15/easier-to-offer-ops-apis-to-your-devs-if-your-api-service-provider-has-apis/">I am a big fan of API providers who also have APIs</a>. It may sound silly to say, but you would be surprised how many companies are selling services to API providers and do not actually have an API themselves. So, anytime I find a good example of API service providers launching new APIs that help API providers be more successful, I’m all over it with a story.</p>

<p><a href="https://www.runscope.com/docs/api/metrics">Today’s example is from my friends over at Runscope with their API Metrics API</a> that lets you “retrieve your API tests performance metrics for each individual test, keep a pulse on your API’s performance over time, and create custom internal or external dashboards with it”. You can filter the request by using 3 different parameters:</p>

<ul>
  <li>region - The service region you’re using to run your tests (e.g. us1, us2, eu1, etc.)</li>
  <li>timeframe - Hour, day, week, or month. Depending on the timeframe you use, the interval between the response times will be different.</li>
  <li>environment_uuid - Filter by a specific environment, such as test, production, etc.</li>
</ul>

<p>That is a pretty healthy example of everything that is API for me–an API that helps you make sure your APIs are performing as expected. You can not just understand how well your API responds, you can dial that in by region, and paint a clear picture of how well you are doing over time. I like that you can create internal dashboards for communicating this with your organization, but I also like their approach to providing external API performance dashboards so much I am going to add it to my list of building blocks I track on as part of <a href="http://performance.apievangelist.com/#BuildingBlocks">my API performance research</a>.</p>

<p>Aight. That concludes today’s showcase of an API service provider making sure they are practicing what they preach and providing APIs for their valuable services. Honestly, I find this to be a fascinating layer of the API sector–the API layer that can orchestrate APIs. I enjoy thinking about what is possible when your APIs have APIs–it makes something like API performance a much more obtainable, scalable, and as Runscope does it, something you can easily communicate with your internal stakeholders and your API community.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/07/apis-for-monitoring-the-performance-of-your-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/07/a-conference-focused-on-machine-learning-apis/">A Conference Focused On Machine Learning APIs</a></h3>
        <span class="post-date">07 Jun 2017</span>
        <p><a href="http://www.papis.io/"><img src="https://s3.amazonaws.com/kinlane-productions/papis/papis-api-screenshot.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I try to pay attention to events going on in the API space beyond just APIStrat in Portland this fall (<a href="http://events.linuxfoundation.org/events/apistrat/program/cfp">submit your CFP!!</a>), and I saw a notification for <a href="http://www.papis.io/">PAPIs in São Paulo in two weeks, as well as Boston in October</a>. I’m glad we’ve always kept @APIStrat a wider community thing, but if I had to pick one vertical to focus on in 2017 and on, it would definitely be machine learning APIs.</p>

<p><a href="http://www.papis.io/">PAPIs has been on my radar for a while now</a>, but I think their foresight is going to start paying off this year. While there are a number of trends moving the API space forward, things like microservices, serverless, and GraphQL, nothing will compare to what is happening with machine learning (ML). I think 90% of the ML will be BS, but there will be 5-10% of it that will actually move industries forward in any meaningful way, and the scope of the investment into everything ML is going to be dizzying for the foreseeable future.</p>

<p>Conferences like PAPIs are going to become increasingly important to help us sit down and have conversations about what ML and AI APIs do, or do not do. I see machine learning, cognitive, artificial intelligence and the buzzwords everybody likes to use just as the algorithmic evolution of the API industry. Where we will be moving beyond just data and content APIs as the default, and having a robust toolbox of algorithmic resources to bake into all of our applications will become standard operating procedure. I’m guessing we’ll see an increased presence of PAPIs conferences in cities around the globe, as well as waves of other ML and AI API-focused events pop up.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/07/a-conference-focused-on-machine-learning-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/07/transparency-around-every-company-who-has-access-to-our-social-data-via-an-api/">Transparency Around Every Company Who Has Access To Our Social Data Via An API</a></h3>
        <span class="post-date">07 Jun 2017</span>
        <p><a href="https://applymagicsauce.com/business.html"><img src="https://s3.amazonaws.com/kinlane-productions/university-of-cambridge/university-of-cambridge-api-transparency.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I believe that APIs can bring some important transparency to the web, mobile, and device applications that seem to be invading our life. I hesitate using the word transparency because it has been weaponized by Wikileaks and others in the current cyber(in)secure landscape, but for the purposes of this story, it will work. APIs by default do not mean transparency, but when done in the right way they can pull back the curtain a little on what is going on when a company, organization, institution, or agency behind is truly committed to transparency.</p>

<p><a href="http://transparency.apievangelist.com/">I’ve long had a portion of my research dedicated to studying intentional transparency efforts by API providers</a>, giving me a place to publish any organizations, links, and stories that I publish on the subject of API transparency. As part of my API research I was looking at some university API efforts the other day when I came across <a href="https://applymagicsauce.com">the Apply Magic Sauce API</a>, a personalisation engine that accurately predicts psychological traits from digital footprints of human behavior, <a href="https://applymagicsauce.com/business.html">which had a pretty interesting section dedicated to the subject of transparency</a>. Here is some background on their approach:</p>

<p>Our methods have been peer-reviewed and published in open access journals since 2013, and new services that sound similar to Apply Magic Sauce API (AMS) are springing up every day. As this technology becomes more accessible and its impact increases, we would like to ensure that citizens have clarity on who we do and do not work with. We are therefore committed to keeping an up to date list of every organisation that we have formally authorised to use AMS for commercial purposes. These clients are advised to follow our ethical guidelines and are bound by our terms and conditions regarding the need to obtain the informed consent of individuals about whom predictions are made. We encourage other providers of predictive technologies to honour the principles of privacy, transparency and relevance and publish a similar list of their own.</p>

<p>The Apply Magic Sauce API provides me with a solid example of an existing institution, “…committed to keeping an up to date list of every organization that we have formally authorised to use AMS for commercial purposes”, and encouraging their partners to “publish a similar list of their own”. What an important example to set when it comes to APIs, especially APIs that involve the amount of personally identifiable information (PII) that a social network possesses. It provides a positive model that ANY application who allows for the OAuth’ing of a user via their Twitter, Facebook, or another social network should be emulating.</p>

<p>Honestly, I’m still not 100% sure about what they are up to at <a href="https://applymagicsauce.com/">the University of Cambridge with their Apply Magic Sauce API</a>–I am still getting going with my dive into their operations. However, <a href="http://apievangelist.com/2017/05/31/an-example-of-api-ethics-out-of-cambridge-university/">from the amount of work they’ve put into the ethics behind their API platform</a>, as well as the high bar for transparency being set, I’m willing to give them the benefit of the doubt that they are up to good things. I’ll keep diving into their API, and monitor the activity in the community to make sure they are standing behind their pledge, and see whether or not their API partners are respecting the pledge as well.</p>

<p>I am hoping that the University of Cambridge provides me with a solid ethical example of not just how an API provider can behave and communicate around the transparency of their API consumption, but also how they can set the same expectations within their API community. If I had my way this would be the standard operating procedure for EVERY company, organization, institution, and a government agency that possess any PII for ANY citizen–100% transparency of EVERY single partner, customer, and application developer who has access to any personal data.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/07/transparency-around-every-company-who-has-access-to-our-social-data-via-an-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/07/openapi-in-gov/">Examples Of The OpenAPI Specification Used For Government APIs</a></h3>
        <span class="post-date">07 Jun 2017</span>
        <p><a href="https://qpp.cms.gov/api/"><img src="https://s3.amazonaws.com/kinlane-productions/cms/cms-quality-payment-program.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I was answering some questions for <a href="http://apis.how/bgdteovduo">my partners over at DreamFactory</a> when it comes to APIs in government, and one of the questions they asked was about some examples of the <a href="https://github.com/OAI/OpenAPI-Specification">OpenAPI specification</a> being used in government. To help out, I started going through  my list of government API looking for any examples in the wild–here is what I found:</p>

<ul>
  <li>
    <p><a href="https://api.open.fec.gov/developers/">Federal Election Commission</a> (FEC) (<a href="https://api.open.fec.gov/swagger/">OpenAPI</a>)</p>
  </li>
  <li>
    <p><a href="http://gsa.github.io/sam_api/sam/console/">System for Award Management</a> (<a href="http://gsa.github.io/sam_api/static/api_docs/api_docs.json">SAM</a>) (OpenAPI)</p>
  </li>
  <li>
    <p><a href="https://usdigitalregistry.digitalgov.gov/">US Digital Registry</a> (<a href="https://api.gsa.gov/systems/digital-registry/v1/swagger_docs/api-docs.json">OpenAPI</a>)</p>
  </li>
  <li>
    <p><a href="https://micropurchase.18f.gov/api">18F Open Source Micro Purchasing API</a> (<a href="https://micropurchase.18f.gov/api/v0/swagger.json">OpenAPI</a>)</p>
  </li>
  <li>
    <p><a href="https://api.nasa.gov/api.html#NeoWS">NASA</a> (Couldn’t find OpenAPI in less than 30 seconds)</p>
  </li>
  <li>
    <p><a href="https://qpp.cms.gov/api/">Centers for Medicare &amp; Medicaid Services (CMS) API for Quality Payment Program Measures</a> (<a href="https://qpp.cms.gov/api/api-docs.json">OpenAPI</a>)</p>
  </li>
  <li>
    <p><a href="https://developer.nrel.gov/docs/transportation/transportation-incentives-laws-v1/">National Renewal Energy Labratory Transportation Laws and Incentives API</a> (<a href="https://developer.nrel.gov/docs/transportation/transportation-incentives-laws-v1/api-docs.json">OpenAPI</a>)</p>
  </li>
</ul>

<p>I am sure there are more OpenAPI in use across government, but this is what I could find in a five-minute search of my API database. It provides us with seven quality examples of OpenAPI being used for documenting government APIs. I don’t see the OpenAPI used for much beyond documentation, but it is still a good start.</p>

<p>If you know of any government APIs that use OpenAPI feel free to let me know. I’d love to keep adding examples to my research so I can pull up quickly when I am asked questions like this in the future, and be able to highlight best practices for API operations in city, county, state, and federal levels of government.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/07/openapi-in-gov/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/06/documentation-research/">The Effect of Visual Design and Information Content on Readers’ Assessments of API Reference Topics</a></h3>
        <span class="post-date">06 Jun 2017</span>
        <p><a href="https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/33466/Watson_washington_0250E_14776.pdf?sequence=1&amp;isAllowed=y"><img src="https://s3.amazonaws.com/kinlane-productions/documentation/api-documentation-research-visualization.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I have seen a number of research projects looking at API documentation, but this is the most detailed study into how people are seeing, or not seeing the API documentation and other resources we are providing. It is a dissertation for Robert Bennett Watson out of the University of Washington on <a href="https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/33466/Watson_washington_0250E_14776.pdf?sequence=1&amp;isAllowed=y">the Effect of Visual Design and Information Content on Readers’ Assessments of API Reference Topics</a>.</p>

<p>I gave the research paper a read through and it is some lofty academic stuff, but it touches on a number of the things I write about on API Evangelist when it comes to the cognitive load associated with understanding what an API does. I found the resulting conversation from the research to be the most interesting part, discussing how we can improve the flow with our API documentation and reduce interruption time, or as I often call it, “friction”. There are a wealth of ideas in there for helping us think more critically about our API documentation, which has been repeatedly identified as the number one problem area for our developers.</p>

<p>If you are in the business of creating any new API documentation startup your team should be digesting Mr. Watson’s work. This is the first official academic work I’ve seen on the subject of API documentation and is something I’ll be revisiting regularly, attempting to distil down any words of wisdom for my readers. I feel like this work is a sign of larger movements towards the API space beginning to get more coherent in how we approach our API operations. I’m hoping it is something that will lay the groundwork for some more useful API documentation services and tooling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/06/documentation-research/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/06/patent-api-descriptions/">Patent US 8997069: API Descriptions</a></h3>
        <span class="post-date">06 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-definition.png" align="right" width="25%" style="padding: 15px;" /></p>
<p>There are so many API patents out there, I’m going to have to start posting one a day just to keep up. Lucky for you I begin to get really depressed by all the API patents I lose interest in reading them and begin to work harder looking for positive examples of API in the world, but until then here is today’s depressing as fuck API patent.</p>

<p>Title: <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=/netahtml/PTO/search-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN/8997069">API descriptions</a>
Number: US 8997069
Owner: Microsoft Technology Licensing, LLC
Abstract: API description techniques are described for consumption by dynamically-typed languages. In one or more implementations, machine-readable data is parsed to locate descriptions of one or more application programming interfaces (APIs). The descriptions of the one or more application programming interfaces are projected into an alternate form that is different than a form of the machine-readable data.</p>

<p>I don’t mean to be a complete dick here, but why would you think this is a good idea? I get that companies want their employees to develop a patent portfolio, but this one is patenting an essential ingredient that makes APIs work. If you enforce this patent it will be worthless because this whole API thing won’t work, and if you don’t enforce it, it will be worthless because it does nothing–money well spent on the filing fee.</p>

<p>I just need to file my patent on patenting APIs and end all of this nonsense. I know y’all think I’m crazy for my beliefs that APIs shouldn’t be patented, but every time I dive into my patent research I can’t help but think y’all are the crazy ones, and I’m actually sane. I just do not understand how this patent is going to help anyone and represents any of the value that APIs and even a patent can bring to the table.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/06/patent-api-descriptions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/06/expanding-on-api-acronym/">Expanding On The API Acronym</a></h3>
        <span class="post-date">06 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/server-racks-clouds_dark_dali.jpg" align="right" width="40%" style="padding: 15px;" /></p>
<p>I really dislike acronyms, so the irony surrounding me being the API Evangelist is always present for me. API isn’t just about RESTful APIs to me. API is much more than just the technical, it is also the business and politics of our digital world–something that doesn’t come across in three letters.</p>

<p>As part of my storytelling, I enjoy unpacking the complexity that acronyms are often used to shadow, hopefully making the world of technology a little less intimidating for folks. While space out at lunch the other day I unpacked API and wrote this:</p>

<ul>
  <li>A - application - the action of putting something into operation.</li>
  <li>P - programming - the action or process of writing computer programs.</li>
  <li>I - interface - interact with another system, person, or organization.</li>
</ul>

<p>I feel like this has helped unpack not just the acronym, but also the words behind them, helping better speak to what APIs actually do in my opinion. I feel like mobile applications always take the lion share of meaning when it comes to the meaning behind the word application. I also feel like humans are left out of the interface discussion. Storytelling around the acronym helps me provide a little more depth regarding what is API, giving me some easy definitions I can recall throughout my storytelling and API conversations.</p>

<p>Telling stories as allowed me to evolve as a technologist. I used to never see the problem with using acronyms as shorthand for technical complexity, but after telling thousands of stories about a single acronym, I’ve come very acquainted with how they are used to exclude and obfuscate not just technical complexity, but the business and political undertow that exist in technological circles. I really have come to dislike acronyms, and being the API Evangelist keeps this dislike front and center for me, helping me to remember to unpack the complexity whenever I can.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/06/expanding-on-api-acronym/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/06/apis-are-how-our-digital-selves-are-learning-to-speak-with-each-other/">APIs Are How Our Digital Selves are Learning To Speak With Each Other</a></h3>
        <span class="post-date">06 Jun 2017</span>
        <p>I know this will sound funny to many folks, but when I see APIs, I see language and communication, and humans learning to speak with each other in this new digital world we are creating for ourselves. My friend Erik Wilde (<a href="https://twitter.com/dret">@dret</a>) tweeted a reminder for me that APIs are indeed a language.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">APIs are languages. show me one <a href="https://twitter.com/hashtag/API?src=hash">#API</a> aspect that cannot be adequately framed in the context of language design practices and challenges.</p>&mdash; Erik Wilde (@dret) <a href="https://twitter.com/dret/status/871429314876645376">June 4, 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Every second on our laptops and mobile phone we are communicating with many different companies and individuals. With each wall post, Tweet, photo push, or video stream we are communicating with our friends, family, and the public. Each of these interactions is being defined and facilitated using an API. An API call just for saying something in text, in an image, or video. API is the digital language we use to communicate online and via our mobile devices.</p>

<p>Uber geeks like me spend their days trying to map out and understand these direct interactions, as well as the growing number of indirect interactions. For every direct communication, there are usually numerous other indirect communications with advertisers, platform providers, or maybe even law enforcement, researchers, or anyone else with access to the communication channels. We aren’t just learning to directly communicate, we are also being conditioned to participate indirectly in conversations we can’t see–unless you are tuned into the bigger picture of the API economy.</p>

<p><img src="https://s3.amazonaws.com/kinlane-productions/xmen/xavier-internet.jpg" align="right" width="40%" style="padding: 15px;" /></p>

<p>When we post that photo, companies are whispering about what is in the photo, where it was taken, and what meaning it has. When we share that news link of Facebook, companies have a discussion about the truthfulness and impact of the link, maybe the psychological profile behind the link and where we fit into their psychological profile database. In some scenarios, they are talking directly about us personally like we are sitting in the room, other times they are talking about us like we are just a number in a larger demographic pool.</p>

<p>In alignment with the real world, the majority of these conversations being held between men, behind closed doors. Publicly the conversations are usually directed by people with a bullhorn, talking over others, as well as whispering behind, and around people while they completely unaware that these conversations about them are even occurring. The average person is completely unaware these conversations are happening. They can’t hear the whispering, or just do not speak the language that is being used around them, about them, each moment of each day.</p>

<p>Those of us in the know are scrambling to understand, control, and direct the conversations that are occuring. There is a lot of money to be made when you are part of these conversations. Or at least have a whole bunch of people on your platform to have a conversation about, or around. People don’t realize that for every direct conversation you have online, there are probably 20 conversations going on about this conversation. What will they buy next? Who do they know? What is in that photo they just shared? Is this related post interesting to them? API-driven echoes of conversation upon conversations into infinity.</p>

<p>Sometimes I feel like Dr. Xavier from the X-men in that vault room connected to the machine when I am on the Internet studying APIs. I’m seeing millions of conversations going on–it is deafening. I don’t just see or hear the direct conversations, I hear the deafening sounds of advertisers, hackers, researchers, police, government, and everyone having a conversation around us. Many folks feel like the average person shouldn’t be included in the conversation–they do not have the interest or awareness to even engage. To me, it just feels like a new secretive world augmenting our physical worlds, where our digital selves are learning to speak with each other. What troubles me though, is that not everyone is actually engaged in the conversations they are included in, and are often asleep or sedated while their personal digital self is being manipulated, exploited, and p0wn3d.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/06/apis-are-how-our-digital-selves-are-learning-to-speak-with-each-other/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/05/extending-your-apps-using-embeddable-serverless-webhooks/">Extending Your Apps Using Embeddable Serverless Webhooks</a></h3>
        <span class="post-date">05 Jun 2017</span>
        <p><a href="https://auth0.com/blog/introducing-auth0-extend-the-new-way-to-extend-your-saas/"><img src="https://s3.amazonaws.com/kinlane-productions/auth0/auth0-extensions-screenshot-editor.png" align="right" width="35%" style="padding: 15px;" /></a></p>
<p><a href="https://auth0.com/blog/introducing-auth0-extend-the-new-way-to-extend-your-saas/">Auth0 has released a pretty interesting way to extend your web applications using what is an embeddable, serverless, webhooks environment</a>–for lack of a better description.  It’s a pretty interesting way to extend applications in a scrappy, hackable, scriptable, webhooky kind of way. The extensions are definitely not for non-developers, but provide a kind of scriptable view source that any brave user could use to get some interesting things done within an existing web application interface.</p>

<p>Here are some of the selling features of Auth0 extensions:</p>

<ul>
  <li>They are deployed outside of your product and managed externally.</li>
  <li>They run securely and in isolation from your SaaS application. The SaaS will not go down due to a faulty Webhook.</li>
  <li>They are generally easy for a developer to create, whether it’s your own engineers, customers, or partners.</li>
  <li>They can be authored in a number of programming languages.</li>
  <li>They can use whatever third-party dependencies they need.</li>
</ul>

<p>I think it is an interesting approach to extending existing applications using Webhooks. I’m guessing some users might be intimidated by it, but I could see it be something that developers and tech savvy users could hack together some pretty interesting implementations. Then when you start saving these interesting scripts, making them available to power users via a catalog–I could see some useful things emerge. I remember several jobs I’ve had that had some sort of universal SQL text area within a system, allowing power users to craft and reuse useful SQL scripts–this seems like a similar approach, but for the API age.</p>

<p>I’m curious to see where this kind of solution goes. It is a quick way to extend SaaS functionality, allowing users to get more from an application without expensive developer cycles, and offloading the compute to external services. I think it is a creative convergence of what I see as embeddable, serverless, and webhooks–all part of an effective API strategy. I’m hoping it injects some creativity and extensibility into existing apps, allowing them to better serve the long tail of users needs in an API serverless webhook way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/05/extending-your-apps-using-embeddable-serverless-webhooks/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/05/algorithmia-invests-more-resources-into-machine-learning-apis-for-working-with-video/">Algorithmia Invests More Resources Into Machine Learning APIs For Working With Video</a></h3>
        <span class="post-date">05 Jun 2017</span>
        <p><a href="http://blog.algorithmia.com/deep-dive-into-parallelized-video-processing/"><img src="https://s3.amazonaws.com/kinlane-productions/algorithmia/algorithmia-cube2-png-1.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I got my regular email from Algorithmia this last week and I like where they are going with some of their machine learning APIs. They have been heavily investing in machine learning applied to video, allowing for the extraction of information from video, as well as applying interesting transformations to your videos.</p>

<p>Here are some of the video tools they have been working on:</p>

<ul>
  <li><a href="http://blog.algorithmia.com/introduction-to-video-transform/">Introduction to Video Transform</a>: apply image transformations to every frame of a video automatically.</li>
  <li><a href="http://blog.algorithmia.com/introduction-video-metadata/">Introduction to Video Meta-Data Extraction</a>: apply any image recognition algorithms to every frame of a video automatically.</li>
  <li><a href="http://blog.algorithmia.com/deep-dive-into-parallelized-video-processing/">Deep Dive into Parallelized Video Processing</a>: Check out how we built a highly parallelized video processing pipeline.</li>
</ul>

<p>These are all things I’m interested in using as part of my drone and other video work that I’ve been working on as a hobby. <a href="http://apievangelist.com/2017/01/03/learning-about-machine-learning-apis-with-my-algorithmic-rotoscope-work/">I’m interested in the video pipeline aspect because it’s fun to work with the video I capture</a>, but I also see the potential when it comes to drones in agriculture and mining, and I am also curious <a href="http://apievangelist.com/2017/01/03/exploring-the-economics-of-wholesale-and-retail-algorithmic-apis/">the business models associated with this type of a video pipeline</a>. I think video, images, plus APIs, coupled with the API monetization strategy Algorithmia already has in place is their formula for success.</p>

<p>I’m keeping an eye on what Amazon, Google, and Microsoft are up to, but I think Algorithmia has a first mover advantage when it comes to the economic of all of this. I’m glad they are investing more into their video resources. I think there are endless uses for API-driven pipelines that process images and video and apply machine learning models using APIs, then metered, and made <a href="https://algorithmia.com/algorithms">available via an algorithmic catalog like Algorithmia offers</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/05/algorithmia-invests-more-resources-into-machine-learning-apis-for-working-with-video/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/05/patent-determining-trustworthiness-of-api-requests/">Patent US9462011: Determining trustworthiness of API requests</a></h3>
        <span class="post-date">05 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-patent-algorithms.png" align="right" width="20%" style="padding: 20px;" /></p>
<p>I’m always fascinated by the patents that get filed related to APIs. Most just have an API that is part of the equation, but some of the patents are directly for an API process. It’s no secret that I’m a patent skeptic. I’m not anti-patent, I just think the process is broken when it comes to the digital world, and specifically when it comes to APIs and interoperability. Here is one of those API patents that show just how broken things are:</p>

<p>Title: <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=/netahtml/PTO/search-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN/9462011">Determining trustworthiness of API requests based on source computer applications’ responses to attack messages</a>
Number: US9462011
Owner: CA, Inc.</p>

<p>Abstract: A method includes receiving an application programming interface (API) request from a source computer application that is directed to a destination computer application. An attack response message that is configured to trigger operation of a defined action by the source computer application is sent to the source computer application. Deliverability of the API request to the destination computer application is controlled based on whether the attack response message triggered operation of the defined action. Related operations by API request risk assessment systems are disclosed.</p>

<p>I get that you might want to patent some of the secret sauce behind this process, but when it comes to APIs, and API security I’m thinking we need to keep thinks open, reusable, and interoperable. Obviously, this is just my not so the business savvy view of the world, but from my tech savvy view of how we secure APIs, patented process help nobody.</p>

<p>When it comes to API security you gain an advantage by providing actual solutions and doing it better than anyone else. Then you do not need to defend anything, everyone will be standing in line to buy your services because securing your APIs is critical to doing business in 2017.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/05/patent-determining-trustworthiness-of-api-requests/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/05/the-number-one-api-example-you-should-be-following/">An API You Should Consider Emulating When Crafting Your SaaS / API Business</a></h3>
        <span class="post-date">05 Jun 2017</span>
        <p><a href="https://blog.pinboard.in/2017/06/pinboard_acquires_delicious/"><img src="https://s3.amazonaws.com/kinlane-productions/pinboard/pinboard-buys-delicious.png" align="right" width="35%" /></a></p>
<p>The <a href="https://pinboard.in/u:kinlane">social bookmarking API Pinboard</a> is my favorite API. I feel like it is a model we should all be considering crafting our API-focused businesses. I’ve used Pinboard to curate what I do as the API Evangelist ever since 2011, and it has been one of the most stable and versatile APIs in my stack, doing one thing, and doing it well, reflecting everything that is API from a business perspective.</p>

<p>I feel that Pinboard provides entrepreneurs with a positive model for not just a SaaS business, and API operations, but showing startups that you don’t always need to scale to achieve success. <a href="https://blog.pinboard.in/2017/06/pinboard_acquires_delicious/">Pinboard acquired their rival Delicious bookmarking site</a> this last week, which has been bought and sold five times now, demonstrating the volatility of startup culture, as well as the viability and potential stability a well-run API business can bring to the table. Providing a model that won’t necessary work in all business scenarios, but does provide us with plenty to consider for our API ideas that probably aren’t VC scale.</p>

<p>I know there will always be startups who are obsessed with the VC model for launching, scaling, and selling a business. I am fine with dealing with some of the volatility brought by these types of companies, but I feel like the lion share of the actual API business will be conducted on the shoulders of giants like Amazon, Google, and Microsoft, and via smaller operators like Pinboard. I’m going to make Pinboard into a textbook example of how to do APIs, helping entrepreneurs understand what healthy patterns already exist out there, providing them with something they can emulate when crafting their SaaS / API business.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/05/the-number-one-api-example-you-should-be-following/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/02/the-depth-and-dimensions-of-monitoring-api-operations/">The Depth And Dimensions Of Monitoring API Operations</a></h3>
        <span class="post-date">02 Jun 2017</span>
        <p><a href="https://www.hitchhq.com"><img src="https://s3.amazonaws.com/kinlane-productions/hitch/hitch-dashboard.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>When I play with <a href="https://www.hitchhq.com">my Hitch service</a> I am always left thinking about the many dimensions of API monitoring. When you talk about API monitoring in the tech sector conversations almost always start with the API providers and the technical details monitoring of individual APIs. Hopefully, these discussions also focus on API monitoring from the API consumers point of view, but I wanted to also shine a light on companies like Hitch who are adding an additional dimension from the API service provider view of things–which is closer to my vantage point as an analyst.</p>

<p>I am an advisor to Hitch because they are a different breed of API monitoring service, that isn’t just focused on the APIs. Hitch brings in the wider view of monitoring the entire operations of an API–if documentation changes, an SDK on Github, or update via Twitter, or a pricing change, you get alerted. As a developer I enjoy being made aware of what is going on across operations, keeping me in tune with not just the technical, but also the business and politics of API platform operations.</p>

<p>Another reason I like Hitch, and really the reason behind me writing this post, is that they are helping API providers think about the bigger picture of API monitoring. Helping them think deeply, as well as getting their shit together when it comes to regularly sending out the critical signals us API consumers are tuning into. When you are down in the trenches of operating an API at a large company, it is easy to get caught up in the internal vacuum, forgetting to properly communicate and support your community–Hitch helps keep this bubble from forming, assisting you in keeping an external focus on your community.</p>

<p>If you are just embarking on your API journey I recommend tuning into API Evangelist first. ;-) However, <a href="https://www.hitchhq.com">if you are unsure of how to properly communicate and support your community I recommend you talk to the Hitch team</a>. They’ll help get you up to speed on the best practices when it comes to API operations, and understand how to send the right signals to your community–something that will make or break your API efforts, so please don’t ignore it.</p>

<p>Disclosure: I am an advisor for Hitch, and they are my friends.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/02/the-depth-and-dimensions-of-monitoring-api-operations/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/02/api-documention-width-sdk-bridge/">API Documentation From SDK Bridge</a></h3>
        <span class="post-date">02 Jun 2017</span>
        <p>This post is a straight up copy and paste from an email newsletter I get from Peter Gruenbaum of <a href="http://sdkbridge.com/">SDK Bridge</a>. I am a big supporter of API service providers like SDK Bridge, who has been doing API documentation the entire time I’ve been the API Evangelist. Peter isn’t looking to be the next big startup, he’s just operating a successful API service that addresses one of the biggest problems API providers face–documentation. Some of my readers might not be aware these types of services exist, which is why I’m copy / pasting this, and helping spread the good word.</p>

<hr />

<p>People often ask me what the best tool for API documentation is. There is no simple answer to this question. It depends a lot on what your API looks like, who your developers are, and what kind of support you can give your content system. This is a quick newsletter to pass on a review of free and open source API documentation tools that you might consider using.</p>

<p>Also, there’s a 60% off sale on our Udemy courses for you newsletter readers for the first 10 students to sign up:</p>

<p><a href="http://sdkbridge.cmail20.com/t/r-l-yuhukiz-hdhyyhjli-r/">API Documentation 1: JSON and XML for Technical Writers: $10</a> (normally $25)
<a href="http://sdkbridge.cmail20.com/t/r-l-yuhukiz-hdhyyhjli-y/">API Documentation 2: REST for Technical Writers: $16</a> (normally $40)
<a href="http://sdkbridge.cmail20.com/t/r-l-yuhukiz-hdhyyhjli-j/">API Documentation 3: The Art of API Documentation: $10</a> (normally $25)
<a href="http://sdkbridge.cmail20.com/t/r-l-yuhukiz-hdhyyhjli-t/">Coding for Writers 1: Basic Programming: $18 (normally $45)</a></p>

<ul>
  <li>Peter Gruenbaum, President, SDK Bridge</li>
</ul>

<p><strong>Free and Open Source API Documentation Tools</strong>
Diána Lakatos has written an excellent description of several free and open source tools that can read the standard API definition formats OpenAPI, RAML, and API Blueprint. In addition, she covers API documentation tools that require non-standard formats, and general purpose open source documentation tools that can be used for API documentation that you may want to consider.</p>

<p>She provides screenshots and links to demos for each of these tools. If you want a quick overview of the tools, scroll to the bottom to read the summary table.
You can find the article here: <a href="http://sdkbridge.cmail20.com/t/r-l-yuhukiz-hdhyyhjli-i/">Free and Open Source API Documentation Tools</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/02/api-documention-width-sdk-bridge/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/02/the-github-repo-stripe-users-to-manage-their-openapi/">The Github Repo Stripe Uses To Manage Their OpenAPI</a></h3>
        <span class="post-date">02 Jun 2017</span>
        <p>I’m beating a drum every time I find a company managing their OpenAPI on Github, like we would the other code elements of our API operations. Today’s drumbeat comes from my friend Nicolas Grenié (<a href="https://twitter.com/picsoung">@picsoung</a>), who posted Stripe’s Github repository for their OpenAPI in our Slack channel for the super cool API Evangelists in the sector. ;-)</p>

<p>Along with the <a href="http://apievangelist.com/2017/03/01/new-york-times-manages-their-openapi-using-github/">New York Times</a>, <a href="http://apievangelist.com/2017/05/22/box-goes-all-in-on-openapi/">Box</a>, and other API providers, <a href="https://github.com/stripe/openapi">Stripe has a dedicated Github repo for managing their OpenAPI definition</a>. This opens up the Stripe API for easily loading in client tools <a href="https://restlet.com/modules/client/">like Restlet Client</a>, and <a href="https://www.getpostman.com/">Postman</a>, as we as generating code samples and SDKs using services like APIMATIC. Most importantly, it allows for developers to easily understand the surface area of the Stripe API, in a way that is machine-readable, and portable.</p>

<p>It makes me happy to see leading API providers manage their own OpenAPI using Github like this. The API sector will be able to reach new heights when every single API provider manages their API definitions like this. I know, I know hypermedia folks–everyone should just do hypermedia. Yes, they should. However, we need some initial steps to occur before that is possible, and API providers being able to effectively communicate their API surface area to API consumers in a way that scales and can be used across the API lifecycle is an important part of this evolution. With each OpenAPI I find like this, I get more optimistic that we are getting closer to the future that RESTafarians and hypermedia folks envision–providers are doing the hard work of thinking about the definitions used in their APIs in the context of the entire API lifecycle, and the API consumers who exist along the way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/02/the-github-repo-stripe-users-to-manage-their-openapi/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/06/02/centers-for-medicare-and-medicaid-services-api-for-quality-payment-program-measures/">Centers for Medicare & Medicaid Services API for Quality Payment Program Measures</a></h3>
        <span class="post-date">02 Jun 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/cms/cms-quality-payment-program.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I am regularly using APIs to slice and dice large datasets to help make sense of what is contained within the database behind in a way that other folks can then develop visualizations, reporting, and other applications for use by folks who are closest to the problem we are trying to solve–this opportunity is one of the reasons I have been evangelizing APIs at all level of government over the last seven years.</p>

<p>After many years of hard work in the federal government by <a href="https://18f.gsa.gov/">smart folks at 18F</a>, and at the agencies they serve, we are beginning to see some tools emerge that begin to help us make sense of the overwhelming amount of data that comes out of the government on a regular basis. You can see this in action with <a href="https://qpp.cms.gov/api/">the API for Quality Payment Program Measures, out of the Centers for Medicare &amp; Medicaid Services (CMS)</a>–helping make sense of how spending is working, or not working when it comes to healthcare.</p>

<p>It has taken years for projects like this to get approved and rolled out. It represents the future of how we make sense of big government, and begin to understand where the waste is, while still also understanding the good that it is occurring. Sadly, as I tell the story, and we see this first wave of APIs coming out of government, the current administration is slashing the budgets behind this type of work. In 2017 I am very concerned for projects like this, as well as future iterations of these API efforts, at a time where we need increased investment in important areas like APIs cracking open health care spending.</p>

<p>If you are in healthcare, make sure and spend some time playing with the API, providing CMS with feedback on what works and what doesn’t. If you have the skills, and the resources, maybe you can also invest in developing some visualizations, applications, or other storytelling around the CMA API for Quality Payment Program Measures, helping to demonstrate the value in understanding how our healthcare dollars are being spent, and the value of APIs helping us slice and dice what both the good and the bad of the impact government has in our world. If you do, make sure and reach out to me so I can tell the story along the way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/06/02/centers-for-medicare-and-medicaid-services-api-for-quality-payment-program-measures/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  

<p align="center"><a href="http://apievangelist.com/archive/"><strong>View Previous Posts Via Archives</strong></a></p>

  </div>
</section>

              
<footer>
  <hr>
  <div class="features">
    
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://www.getpostman.com/" target="_blank"><img src="https://apievangelist.com/images/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://apievangelist.com/images/tyk-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
  </div>
  <hr>
  <p align="center">
    relevant work:
    <a href="http://apievangelist.com">apievangelist.com</a> |
    <a href="http://adopta.agency">adopta.agency</a>
  </p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Homepage</a></li>
    <li><a href="http://101.apievangelist.com/">101</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="http://history.apievangelist.com/">History of APIs</a></li>
    <li><a href="/#api-lifecycle">API Lifecycle</a></li>
    <li><a href="/search/">Search</a></li>
    <li><a href="/newsletters/">Newsletters</a></li>
    <li><a href="/images/">Images</a></li>
    <li><a href="/archive/">Archive</a></li>
  </ul>
</nav>

              <section>
  <div class="mini-posts">
    <header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
    
    
      
        <article style="display: inline;">
          <a href="https://www.getpostman.com/" class="image"><img src="https://apievangelist.com/images/postman-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
      
        <article style="display: inline;">
          <a href="https://tyk.io/" class="image"><img src="https://apievangelist.com/images/tyk-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
  </div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
